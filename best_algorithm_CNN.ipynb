{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# COMP5318 - Machine Learning and Data Mining: Assignment 2 - Best Algorithm"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CONTENTS"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-  [0. Set up](#0)\n",
    "-  [1. Obtain data](#1)\n",
    "    -  [1.1. Data info](#1.1)\n",
    "    -  [1.2. Load data](#1.2)\n",
    "    -  [1.3. Set train/test data](#1.3)\n",
    "-  [2. Pre-process data](#2)\n",
    "    -  [2.1. Standardized data](#2.1)\n",
    "-  [3. Best Algorithms - CNN](#3)\n",
    "-  [4. Computer details](#4)\n",
    "-  [5. Easy to use](#5)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Set up <a id='0'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sklearn\r\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\r\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import layers\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import os\r\n",
    "import time\r\n",
    "import cv2\r\n",
    "\r\n",
    "%matplotlib inline\r\n",
    "import matplotlib as mpl\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Obtain data <a id='1'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1. Data info <a id='1.1'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is a \"Fnt\" folder including 62 main folders, each folder including 1016 png files as input data (which downloaded from http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/):\n",
    "\n",
    "    EnglishFnt.tgz (51.1 MB): characters from computer fonts with 4 variations (combinations of italic, bold and normal)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2. Load data <a id='1.2'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# read image and resize image\r\n",
    "def img_resizing(i_path):\r\n",
    "    img = cv2.imread(i_path, cv2.IMREAD_GRAYSCALE)\r\n",
    "    data = cv2.resize(img, (28, 28), interpolation=cv2.INTER_CUBIC)\r\n",
    "    return data\r\n",
    "\r\n",
    "# converting the images into sets of data\r\n",
    "data = []\r\n",
    "label = []\r\n",
    "\r\n",
    "for i in range(62):\r\n",
    "    path = 'English/Fnt/Sample%03d/' % (i+1)\r\n",
    "    for filename in os.listdir(path):\r\n",
    "        try:\r\n",
    "            img = img_resizing(path+filename)\r\n",
    "            tmp = img.reshape([1, img.shape[0]*img.shape[1]])\r\n",
    "            data.append(np.asarray(tmp, dtype = \"int32\"))\r\n",
    "            label.append(i)\r\n",
    "        except:\r\n",
    "            error_message = path + filename\r\n",
    "            print(\"failed: \", error_message)\r\n",
    "            pass\r\n",
    "\r\n",
    "# convert data type\r\n",
    "data_array = np.asarray(data)\r\n",
    "new_data = np.asarray(data_array).reshape(data_array.shape[0],-1)\r\n",
    "print(\"The data shape is: \", new_data.shape)\r\n",
    "new_label = np.asarray(label)\r\n",
    "print(\"The label shape is: \", new_label.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3. Set train / test data <a id='1.3'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "X = new_data\r\n",
    "y = new_label\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=500)\r\n",
    "\r\n",
    "# print train and test data set shape\r\n",
    "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\r\n",
    "print(\"X_test shape:\", X_test.shape, \"y_test shape:\", y_test.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Pre-process data <a id='2'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1. Standardized data <a id='2.1'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import StandardScaler\r\n",
    "scaler = StandardScaler()#creating an object\r\n",
    "scaler.fit(X_train)#calculate min and max value of the training data\r\n",
    "X_train_std = scaler.transform(X_train) #apply normalisation to the training set\r\n",
    "X_test_std = scaler.transform(X_test) #apply normalization to the test set"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Best Algorithms - CNN <a id='3'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\r\n",
    "from tensorflow.keras import layers\r\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "X_train_keras = X_train_std.reshape(X_train_std.shape[0], 28, 28)\r\n",
    "X_test_keras = X_test_std.reshape(X_test_std.shape[0], 28, 28)\r\n",
    "\r\n",
    "X_train_keras = np.expand_dims(X_train_keras, axis=3)\r\n",
    "X_test_keras = np.expand_dims(X_test_keras, axis=3)\r\n",
    "\r\n",
    "y_train_keras = keras.utils.to_categorical(y_train, 62).astype('int32')\r\n",
    "y_test_keras = keras.utils.to_categorical(y_test, 62).astype('int32')\r\n",
    "\r\n",
    "# print shape of data and label\r\n",
    "print(\"The shape of train data: \", X_train_keras.shape)\r\n",
    "print(\"The shape of test data: \", X_test_keras.shape)\r\n",
    "print(\"The shape of train label: \", y_train_keras.shape)\r\n",
    "print(\"The shape of test label: \", y_test_keras.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The shape of train data:  (50393, 28, 28, 1)\n",
      "The shape of test data:  (12599, 28, 28, 1)\n",
      "The shape of train label:  (50393, 62)\n",
      "The shape of test label:  (12599, 62)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Clear any existing TensorFlow graph from memory and set random seeds.\r\n",
    "keras.backend.clear_session()\r\n",
    "np.random.seed(42)\r\n",
    "tf.random.set_seed(42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Model \r\n",
    "def cnn_model():\r\n",
    "    # Clear any existing TensorFlow graph from memory and set random seeds.\r\n",
    "    keras.backend.clear_session()\r\n",
    "    np.random.seed(42)\r\n",
    "    tf.random.set_seed(42)\r\n",
    "    \r\n",
    "    model = Sequential()\r\n",
    "    model.add(layers.Conv2D(filters=64, kernel_size=(7,7),padding='same', \r\n",
    "                            input_shape=(28,28,1), activation='relu'))\r\n",
    "    model.add(layers.BatchNormalization(axis=-1))\r\n",
    "    model.add(layers.MaxPooling2D(pool_size=(3,3), strides=(2,2)))\r\n",
    "    model.add(layers.Conv2D(filters=128, kernel_size=(5,5), strides=(1,1), padding='same', activation='relu'))\r\n",
    "    model.add(layers.BatchNormalization(axis=-1))\r\n",
    "    model.add(layers.MaxPooling2D(pool_size=(3,3), strides=(2,2)))\r\n",
    "\r\n",
    "    model.add(layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\r\n",
    "    model.add(layers.BatchNormalization(axis=-1))\r\n",
    "    model.add(layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\r\n",
    "    model.add(layers.BatchNormalization(axis=-1))\r\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\r\n",
    "\r\n",
    "    model.add(layers.Flatten())\r\n",
    "    model.add(layers.Dropout(0.5))\r\n",
    "    model.add(layers.Dense(units=256, activation='relu'))\r\n",
    "    model.add(layers.BatchNormalization())\r\n",
    "    model.add(layers.Dropout(0.5))\r\n",
    "    model.add(layers.Dense(units=128, activation='relu'))\r\n",
    "    model.add(layers.BatchNormalization())\r\n",
    "    model.add(layers.Dropout(0.5))\r\n",
    "    model.add(layers.Dense(units=62, activation='softmax'))\r\n",
    "    return model\r\n",
    "print(cnn_model().summary())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 64)        3200      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 128)       204928    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 13, 13, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 6, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 6, 6, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 128)         295040    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 6, 6, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               295168    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 62)                7998      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,138,238\n",
      "Trainable params: 1,136,318\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# compile and fit model\r\n",
    "lr_adam = [0.0001, 0.001]\r\n",
    "epoch_adam = [50, 100]\r\n",
    "\r\n",
    "lr_sgd = [0.001, 0.01]\r\n",
    "epoch_sgd = [50, 100]\r\n",
    "\r\n",
    "count = 1\r\n",
    "cnn_res = {'tech': [], 'lr':[], 'epoch':[], 'accuracy_score':[], 'precision_score':[], 'recall_score':[], 'f1_score':[]}\r\n",
    "\r\n",
    "for i in lr_adam:\r\n",
    "    for j in epoch_adam:\r\n",
    "        print(\"Adam: %d / %d ###################################################\" % (count, len(lr_adam)*len(epoch_adam)))\r\n",
    "        count += 1\r\n",
    "        model = cnn_model()\r\n",
    "        model.compile(loss=\"categorical_crossentropy\", \r\n",
    "                      optimizer=keras.optimizers.Adam(learning_rate=i), \r\n",
    "                      metrics=[\"accuracy\"])\r\n",
    "        model.fit(X_train_keras, y_train_keras, epochs=j,\r\n",
    "                           validation_split=0.2) # set 20% as validation seet\r\n",
    "\r\n",
    "        y_prob = model.predict(X_test_keras)\r\n",
    "        y_pred = np.argmax(y_prob,axis=1)\r\n",
    "        ground_truth = np.argmax(y_test_keras,axis=1)\r\n",
    "        \r\n",
    "        cnn_res['tech'].append('Adam')\r\n",
    "        cnn_res['lr'].append(i)\r\n",
    "        cnn_res['epoch'].append(j)\r\n",
    "        cnn_res['accuracy_score'].append(accuracy_score(ground_truth, y_pred))\r\n",
    "        cnn_res['precision_score'].append(precision_score(ground_truth, y_pred, average='macro'))\r\n",
    "        cnn_res['recall_score'].append(recall_score(ground_truth, y_pred, average='macro'))\r\n",
    "        cnn_res['f1_score'].append(f1_score(ground_truth, y_pred, average='macro'))\r\n",
    "        print(\"Adam with learning rate = %f, epochs = %d, the accuracy is: %f\" % (i, j, accuracy_score(ground_truth, y_pred)))\r\n",
    "\r\n",
    "count = 1\r\n",
    "for i in lr_sgd:\r\n",
    "    for j in epoch_sgd:\r\n",
    "        print(\" SGD: %d / %d ###################################################\" % (count, len(lr_sgd)*len(epoch_sgd)))\r\n",
    "        count += 1\r\n",
    "        model = cnn_model()\r\n",
    "        decay_rate = i / j\r\n",
    "        sgd = keras.optimizers.SGD(learning_rate=i, momentum=0.8, decay=decay_rate, nesterov=False)\r\n",
    "        model.compile(loss=\"categorical_crossentropy\", \r\n",
    "                      optimizer=sgd, \r\n",
    "                      metrics=[\"accuracy\"])\r\n",
    "        model.fit(X_train_keras, y_train_keras, epochs=j,\r\n",
    "                           validation_split=0.2) # set 20% as validation seet\r\n",
    "        y_prob = model.predict(X_test_keras)\r\n",
    "        y_pred = np.argmax(y_prob,axis=1)\r\n",
    "        ground_truth = np.argmax(y_test_keras,axis=1)\r\n",
    "\r\n",
    "        cnn_res['tech'].append('SGD')\r\n",
    "        cnn_res['lr'].append(i)\r\n",
    "        cnn_res['epoch'].append(j)\r\n",
    "        cnn_res['accuracy_score'].append(accuracy_score(ground_truth, y_pred))\r\n",
    "        cnn_res['precision_score'].append(precision_score(ground_truth, y_pred, average='macro'))\r\n",
    "        cnn_res['recall_score'].append(recall_score(ground_truth, y_pred, average='macro'))\r\n",
    "        cnn_res['f1_score'].append(f1_score(ground_truth, y_pred, average='macro'))\r\n",
    "        print(\"SGD with learning rate = %f, epochs = %d, the accuracy is: %f\" % (i, j, accuracy_score(ground_truth, y_pred)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Adam: 1 / 4 ###################################################\n",
      "Epoch 1/50\n",
      "1260/1260 [==============================] - 16s 12ms/step - loss: 3.6511 - accuracy: 0.1608 - val_loss: 1.7134 - val_accuracy: 0.6671\n",
      "Epoch 2/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 1.9806 - accuracy: 0.4839 - val_loss: 0.9703 - val_accuracy: 0.7727\n",
      "Epoch 3/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 1.3629 - accuracy: 0.6340 - val_loss: 0.7029 - val_accuracy: 0.8060\n",
      "Epoch 4/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 1.0620 - accuracy: 0.7085 - val_loss: 0.5964 - val_accuracy: 0.8233\n",
      "Epoch 5/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.8882 - accuracy: 0.7475 - val_loss: 0.5258 - val_accuracy: 0.8419\n",
      "Epoch 6/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.7885 - accuracy: 0.7660 - val_loss: 0.4790 - val_accuracy: 0.8458\n",
      "Epoch 7/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.7086 - accuracy: 0.7834 - val_loss: 0.4614 - val_accuracy: 0.8498\n",
      "Epoch 8/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.6514 - accuracy: 0.7953 - val_loss: 0.4288 - val_accuracy: 0.8543\n",
      "Epoch 9/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.6001 - accuracy: 0.8065 - val_loss: 0.4166 - val_accuracy: 0.8571\n",
      "Epoch 10/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.5617 - accuracy: 0.8162 - val_loss: 0.4066 - val_accuracy: 0.8629\n",
      "Epoch 11/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.5325 - accuracy: 0.8245 - val_loss: 0.3870 - val_accuracy: 0.8649\n",
      "Epoch 12/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4968 - accuracy: 0.8333 - val_loss: 0.3678 - val_accuracy: 0.8738\n",
      "Epoch 13/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4742 - accuracy: 0.8389 - val_loss: 0.3609 - val_accuracy: 0.8739\n",
      "Epoch 14/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4456 - accuracy: 0.8469 - val_loss: 0.3445 - val_accuracy: 0.8795\n",
      "Epoch 15/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.4302 - accuracy: 0.8516 - val_loss: 0.3465 - val_accuracy: 0.8753\n",
      "Epoch 16/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4049 - accuracy: 0.8585 - val_loss: 0.3400 - val_accuracy: 0.8797\n",
      "Epoch 17/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3892 - accuracy: 0.8629 - val_loss: 0.3275 - val_accuracy: 0.8853\n",
      "Epoch 18/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3739 - accuracy: 0.8679 - val_loss: 0.3244 - val_accuracy: 0.8828\n",
      "Epoch 19/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3628 - accuracy: 0.8718 - val_loss: 0.3145 - val_accuracy: 0.8863\n",
      "Epoch 20/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.3443 - accuracy: 0.8763 - val_loss: 0.3175 - val_accuracy: 0.8875\n",
      "Epoch 21/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3330 - accuracy: 0.8829 - val_loss: 0.3077 - val_accuracy: 0.8912\n",
      "Epoch 22/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3219 - accuracy: 0.8848 - val_loss: 0.3149 - val_accuracy: 0.8905\n",
      "Epoch 23/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3075 - accuracy: 0.8895 - val_loss: 0.3056 - val_accuracy: 0.8898\n",
      "Epoch 24/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3002 - accuracy: 0.8924 - val_loss: 0.3088 - val_accuracy: 0.8890\n",
      "Epoch 25/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2947 - accuracy: 0.8930 - val_loss: 0.3002 - val_accuracy: 0.8955\n",
      "Epoch 26/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2834 - accuracy: 0.8974 - val_loss: 0.3017 - val_accuracy: 0.8901\n",
      "Epoch 27/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2664 - accuracy: 0.9027 - val_loss: 0.2932 - val_accuracy: 0.8949\n",
      "Epoch 28/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2601 - accuracy: 0.9055 - val_loss: 0.3049 - val_accuracy: 0.8932\n",
      "Epoch 29/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2558 - accuracy: 0.9087 - val_loss: 0.2922 - val_accuracy: 0.8949\n",
      "Epoch 30/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2488 - accuracy: 0.9101 - val_loss: 0.2985 - val_accuracy: 0.8979\n",
      "Epoch 31/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2425 - accuracy: 0.9124 - val_loss: 0.2972 - val_accuracy: 0.8977\n",
      "Epoch 32/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2371 - accuracy: 0.9142 - val_loss: 0.3110 - val_accuracy: 0.8897\n",
      "Epoch 33/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2330 - accuracy: 0.9165 - val_loss: 0.2992 - val_accuracy: 0.8927\n",
      "Epoch 34/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2239 - accuracy: 0.9199 - val_loss: 0.2893 - val_accuracy: 0.8981\n",
      "Epoch 35/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2188 - accuracy: 0.9212 - val_loss: 0.3001 - val_accuracy: 0.8965\n",
      "Epoch 36/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2144 - accuracy: 0.9241 - val_loss: 0.2892 - val_accuracy: 0.9000\n",
      "Epoch 37/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2098 - accuracy: 0.9247 - val_loss: 0.2992 - val_accuracy: 0.8954\n",
      "Epoch 38/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2048 - accuracy: 0.9263 - val_loss: 0.2960 - val_accuracy: 0.9010\n",
      "Epoch 39/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1994 - accuracy: 0.9279 - val_loss: 0.2946 - val_accuracy: 0.9001\n",
      "Epoch 40/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1963 - accuracy: 0.9300 - val_loss: 0.3030 - val_accuracy: 0.9007\n",
      "Epoch 41/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1893 - accuracy: 0.9330 - val_loss: 0.3034 - val_accuracy: 0.8973\n",
      "Epoch 42/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1824 - accuracy: 0.9344 - val_loss: 0.3142 - val_accuracy: 0.8922\n",
      "Epoch 43/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1746 - accuracy: 0.9371 - val_loss: 0.3325 - val_accuracy: 0.8943\n",
      "Epoch 44/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1800 - accuracy: 0.9352 - val_loss: 0.2945 - val_accuracy: 0.9042\n",
      "Epoch 45/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1745 - accuracy: 0.9371 - val_loss: 0.3228 - val_accuracy: 0.8986\n",
      "Epoch 46/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1689 - accuracy: 0.9404 - val_loss: 0.3196 - val_accuracy: 0.8981\n",
      "Epoch 47/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1671 - accuracy: 0.9416 - val_loss: 0.3112 - val_accuracy: 0.9021\n",
      "Epoch 48/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1633 - accuracy: 0.9420 - val_loss: 0.3252 - val_accuracy: 0.8940\n",
      "Epoch 49/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1613 - accuracy: 0.9442 - val_loss: 0.3335 - val_accuracy: 0.8947\n",
      "Epoch 50/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1566 - accuracy: 0.9448 - val_loss: 0.3234 - val_accuracy: 0.9012\n",
      "Adam with learning rate = 0.000100, epochs = 50, the accuracy is: 0.896023\n",
      "Adam: 2 / 4 ###################################################\n",
      "Epoch 1/100\n",
      "1260/1260 [==============================] - 14s 10ms/step - loss: 3.6574 - accuracy: 0.1588 - val_loss: 1.7330 - val_accuracy: 0.6608\n",
      "Epoch 2/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 1.9939 - accuracy: 0.4821 - val_loss: 0.9578 - val_accuracy: 0.7712\n",
      "Epoch 3/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 1.3619 - accuracy: 0.6361 - val_loss: 0.7006 - val_accuracy: 0.8024\n",
      "Epoch 4/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 1.0666 - accuracy: 0.7064 - val_loss: 0.6023 - val_accuracy: 0.8207\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.8908 - accuracy: 0.7461 - val_loss: 0.5297 - val_accuracy: 0.8353\n",
      "Epoch 6/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.7898 - accuracy: 0.7643 - val_loss: 0.4900 - val_accuracy: 0.8442\n",
      "Epoch 7/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.7137 - accuracy: 0.7828 - val_loss: 0.4568 - val_accuracy: 0.8500\n",
      "Epoch 8/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.6526 - accuracy: 0.7971 - val_loss: 0.4285 - val_accuracy: 0.8598\n",
      "Epoch 9/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.6016 - accuracy: 0.8065 - val_loss: 0.4180 - val_accuracy: 0.8560\n",
      "Epoch 10/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.5629 - accuracy: 0.8162 - val_loss: 0.4027 - val_accuracy: 0.8644\n",
      "Epoch 11/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.5255 - accuracy: 0.8276 - val_loss: 0.3807 - val_accuracy: 0.8696\n",
      "Epoch 12/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.5021 - accuracy: 0.8327 - val_loss: 0.3695 - val_accuracy: 0.8720\n",
      "Epoch 13/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4778 - accuracy: 0.8392 - val_loss: 0.3648 - val_accuracy: 0.8729\n",
      "Epoch 14/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4485 - accuracy: 0.8476 - val_loss: 0.3584 - val_accuracy: 0.8756\n",
      "Epoch 15/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4304 - accuracy: 0.8526 - val_loss: 0.3458 - val_accuracy: 0.8802\n",
      "Epoch 16/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4087 - accuracy: 0.8591 - val_loss: 0.3452 - val_accuracy: 0.8782\n",
      "Epoch 17/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3947 - accuracy: 0.8613 - val_loss: 0.3320 - val_accuracy: 0.8811\n",
      "Epoch 18/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3788 - accuracy: 0.8677 - val_loss: 0.3284 - val_accuracy: 0.8832\n",
      "Epoch 19/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3613 - accuracy: 0.8704 - val_loss: 0.3201 - val_accuracy: 0.8847\n",
      "Epoch 20/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3488 - accuracy: 0.8774 - val_loss: 0.3340 - val_accuracy: 0.8792\n",
      "Epoch 21/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3335 - accuracy: 0.8805 - val_loss: 0.3311 - val_accuracy: 0.8830\n",
      "Epoch 22/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.3197 - accuracy: 0.8864 - val_loss: 0.3060 - val_accuracy: 0.8911\n",
      "Epoch 23/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3105 - accuracy: 0.8899 - val_loss: 0.2996 - val_accuracy: 0.8923\n",
      "Epoch 24/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2983 - accuracy: 0.8938 - val_loss: 0.3087 - val_accuracy: 0.8923\n",
      "Epoch 25/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.2915 - accuracy: 0.8949 - val_loss: 0.2991 - val_accuracy: 0.8955\n",
      "Epoch 26/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2828 - accuracy: 0.8978 - val_loss: 0.2981 - val_accuracy: 0.8953\n",
      "Epoch 27/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2737 - accuracy: 0.9022 - val_loss: 0.2918 - val_accuracy: 0.8969\n",
      "Epoch 28/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2619 - accuracy: 0.9062 - val_loss: 0.3129 - val_accuracy: 0.8854\n",
      "Epoch 29/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2568 - accuracy: 0.9075 - val_loss: 0.2949 - val_accuracy: 0.8972\n",
      "Epoch 30/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.2506 - accuracy: 0.9094 - val_loss: 0.2974 - val_accuracy: 0.8935\n",
      "Epoch 31/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.2445 - accuracy: 0.9112 - val_loss: 0.2970 - val_accuracy: 0.8991\n",
      "Epoch 32/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2361 - accuracy: 0.9148 - val_loss: 0.3021 - val_accuracy: 0.8975\n",
      "Epoch 33/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2322 - accuracy: 0.9158 - val_loss: 0.2951 - val_accuracy: 0.8998\n",
      "Epoch 34/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2243 - accuracy: 0.9195 - val_loss: 0.3125 - val_accuracy: 0.8956\n",
      "Epoch 35/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2190 - accuracy: 0.9219 - val_loss: 0.2986 - val_accuracy: 0.8964\n",
      "Epoch 36/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2100 - accuracy: 0.9237 - val_loss: 0.3031 - val_accuracy: 0.8990\n",
      "Epoch 37/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2068 - accuracy: 0.9268 - val_loss: 0.3083 - val_accuracy: 0.8962\n",
      "Epoch 38/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.2026 - accuracy: 0.9267 - val_loss: 0.3000 - val_accuracy: 0.9020\n",
      "Epoch 39/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1964 - accuracy: 0.9294 - val_loss: 0.2936 - val_accuracy: 0.9012\n",
      "Epoch 40/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1961 - accuracy: 0.9297 - val_loss: 0.3037 - val_accuracy: 0.9015\n",
      "Epoch 41/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1856 - accuracy: 0.9342 - val_loss: 0.3434 - val_accuracy: 0.8854\n",
      "Epoch 42/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1870 - accuracy: 0.9339 - val_loss: 0.3064 - val_accuracy: 0.9005\n",
      "Epoch 43/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.1761 - accuracy: 0.9349 - val_loss: 0.3126 - val_accuracy: 0.9010\n",
      "Epoch 44/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1805 - accuracy: 0.9353 - val_loss: 0.3033 - val_accuracy: 0.9036\n",
      "Epoch 45/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1727 - accuracy: 0.9393 - val_loss: 0.3165 - val_accuracy: 0.9012\n",
      "Epoch 46/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.1713 - accuracy: 0.9403 - val_loss: 0.3107 - val_accuracy: 0.9033\n",
      "Epoch 47/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.1665 - accuracy: 0.9405 - val_loss: 0.3102 - val_accuracy: 0.9043\n",
      "Epoch 48/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.1611 - accuracy: 0.9424 - val_loss: 0.3198 - val_accuracy: 0.9005\n",
      "Epoch 49/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.1601 - accuracy: 0.9440 - val_loss: 0.3338 - val_accuracy: 0.8993\n",
      "Epoch 50/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1583 - accuracy: 0.9445 - val_loss: 0.3331 - val_accuracy: 0.8965\n",
      "Epoch 51/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1533 - accuracy: 0.9452 - val_loss: 0.3198 - val_accuracy: 0.9030\n",
      "Epoch 52/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1470 - accuracy: 0.9495 - val_loss: 0.3333 - val_accuracy: 0.9042\n",
      "Epoch 53/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.1493 - accuracy: 0.9484 - val_loss: 0.3178 - val_accuracy: 0.9028\n",
      "Epoch 54/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.1432 - accuracy: 0.9500 - val_loss: 0.3218 - val_accuracy: 0.9029\n",
      "Epoch 55/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.1439 - accuracy: 0.9496 - val_loss: 0.3296 - val_accuracy: 0.9053\n",
      "Epoch 56/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1374 - accuracy: 0.9526 - val_loss: 0.3318 - val_accuracy: 0.9034\n",
      "Epoch 57/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1315 - accuracy: 0.9542 - val_loss: 0.3466 - val_accuracy: 0.9014\n",
      "Epoch 58/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1341 - accuracy: 0.9545 - val_loss: 0.3343 - val_accuracy: 0.9050\n",
      "Epoch 59/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1316 - accuracy: 0.9547 - val_loss: 0.3417 - val_accuracy: 0.9018\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1219 - accuracy: 0.9579 - val_loss: 0.3427 - val_accuracy: 0.9045\n",
      "Epoch 61/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1264 - accuracy: 0.9565 - val_loss: 0.3640 - val_accuracy: 0.9041\n",
      "Epoch 62/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1230 - accuracy: 0.9577 - val_loss: 0.3466 - val_accuracy: 0.9051\n",
      "Epoch 63/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1197 - accuracy: 0.9589 - val_loss: 0.3549 - val_accuracy: 0.9031\n",
      "Epoch 64/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1161 - accuracy: 0.9589 - val_loss: 0.3550 - val_accuracy: 0.9016\n",
      "Epoch 65/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1176 - accuracy: 0.9604 - val_loss: 0.3482 - val_accuracy: 0.9052\n",
      "Epoch 66/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1172 - accuracy: 0.9600 - val_loss: 0.3569 - val_accuracy: 0.9013\n",
      "Epoch 67/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1135 - accuracy: 0.9626 - val_loss: 0.3863 - val_accuracy: 0.8980\n",
      "Epoch 68/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1107 - accuracy: 0.9627 - val_loss: 0.3907 - val_accuracy: 0.8984\n",
      "Epoch 69/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1122 - accuracy: 0.9627 - val_loss: 0.3698 - val_accuracy: 0.9028\n",
      "Epoch 70/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1080 - accuracy: 0.9628 - val_loss: 0.3705 - val_accuracy: 0.9016\n",
      "Epoch 71/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1062 - accuracy: 0.9642 - val_loss: 0.3589 - val_accuracy: 0.9040\n",
      "Epoch 72/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1092 - accuracy: 0.9633 - val_loss: 0.3667 - val_accuracy: 0.9022\n",
      "Epoch 73/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1018 - accuracy: 0.9652 - val_loss: 0.3846 - val_accuracy: 0.8980\n",
      "Epoch 74/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1010 - accuracy: 0.9661 - val_loss: 0.3672 - val_accuracy: 0.9033\n",
      "Epoch 75/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1004 - accuracy: 0.9669 - val_loss: 0.3692 - val_accuracy: 0.9022\n",
      "Epoch 76/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0972 - accuracy: 0.9669 - val_loss: 0.3662 - val_accuracy: 0.9080\n",
      "Epoch 77/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0999 - accuracy: 0.9670 - val_loss: 0.3884 - val_accuracy: 0.9027\n",
      "Epoch 78/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0994 - accuracy: 0.9659 - val_loss: 0.3697 - val_accuracy: 0.9069\n",
      "Epoch 79/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0936 - accuracy: 0.9677 - val_loss: 0.3856 - val_accuracy: 0.9033\n",
      "Epoch 80/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0947 - accuracy: 0.9678 - val_loss: 0.3880 - val_accuracy: 0.9027\n",
      "Epoch 81/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0934 - accuracy: 0.9684 - val_loss: 0.3895 - val_accuracy: 0.9017\n",
      "Epoch 82/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0907 - accuracy: 0.9694 - val_loss: 0.3768 - val_accuracy: 0.9053\n",
      "Epoch 83/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0900 - accuracy: 0.9697 - val_loss: 0.3879 - val_accuracy: 0.9050\n",
      "Epoch 84/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0905 - accuracy: 0.9691 - val_loss: 0.4065 - val_accuracy: 0.9034\n",
      "Epoch 85/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0887 - accuracy: 0.9702 - val_loss: 0.3904 - val_accuracy: 0.9046\n",
      "Epoch 86/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.0840 - accuracy: 0.9719 - val_loss: 0.3964 - val_accuracy: 0.9030\n",
      "Epoch 87/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.0881 - accuracy: 0.9703 - val_loss: 0.3909 - val_accuracy: 0.9058\n",
      "Epoch 88/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0886 - accuracy: 0.9706 - val_loss: 0.3911 - val_accuracy: 0.9055\n",
      "Epoch 89/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0836 - accuracy: 0.9719 - val_loss: 0.4206 - val_accuracy: 0.8999\n",
      "Epoch 90/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0822 - accuracy: 0.9721 - val_loss: 0.4085 - val_accuracy: 0.9020\n",
      "Epoch 91/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.0819 - accuracy: 0.9729 - val_loss: 0.3983 - val_accuracy: 0.9047\n",
      "Epoch 92/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0864 - accuracy: 0.9717 - val_loss: 0.4028 - val_accuracy: 0.9041\n",
      "Epoch 93/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0791 - accuracy: 0.9735 - val_loss: 0.4101 - val_accuracy: 0.9017\n",
      "Epoch 94/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0769 - accuracy: 0.9743 - val_loss: 0.4368 - val_accuracy: 0.8973\n",
      "Epoch 95/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0837 - accuracy: 0.9720 - val_loss: 0.4304 - val_accuracy: 0.9017\n",
      "Epoch 96/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0756 - accuracy: 0.9752 - val_loss: 0.3914 - val_accuracy: 0.9053\n",
      "Epoch 97/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0826 - accuracy: 0.9720 - val_loss: 0.4013 - val_accuracy: 0.9059\n",
      "Epoch 98/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0776 - accuracy: 0.9736 - val_loss: 0.3998 - val_accuracy: 0.9065\n",
      "Epoch 99/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.0759 - accuracy: 0.9741 - val_loss: 0.4071 - val_accuracy: 0.9060\n",
      "Epoch 100/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0759 - accuracy: 0.9752 - val_loss: 0.4181 - val_accuracy: 0.9055\n",
      "Adam with learning rate = 0.000100, epochs = 100, the accuracy is: 0.900230\n",
      "Adam: 3 / 4 ###################################################\n",
      "Epoch 1/50\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 1.9606 - accuracy: 0.4856 - val_loss: 0.6663 - val_accuracy: 0.7840\n",
      "Epoch 2/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.8142 - accuracy: 0.7461 - val_loss: 0.5381 - val_accuracy: 0.8075\n",
      "Epoch 3/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.6679 - accuracy: 0.7775 - val_loss: 0.4587 - val_accuracy: 0.8362\n",
      "Epoch 4/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.5888 - accuracy: 0.7965 - val_loss: 0.4341 - val_accuracy: 0.8437\n",
      "Epoch 5/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.5431 - accuracy: 0.8119 - val_loss: 0.4044 - val_accuracy: 0.8525\n",
      "Epoch 6/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.5012 - accuracy: 0.8266 - val_loss: 0.3704 - val_accuracy: 0.8625\n",
      "Epoch 7/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4719 - accuracy: 0.8326 - val_loss: 0.3643 - val_accuracy: 0.8593\n",
      "Epoch 8/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.4425 - accuracy: 0.8422 - val_loss: 0.3553 - val_accuracy: 0.8638\n",
      "Epoch 9/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4216 - accuracy: 0.8493 - val_loss: 0.3476 - val_accuracy: 0.8738\n",
      "Epoch 10/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.3953 - accuracy: 0.8581 - val_loss: 0.3655 - val_accuracy: 0.8681\n",
      "Epoch 11/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3756 - accuracy: 0.8622 - val_loss: 0.3247 - val_accuracy: 0.8803\n",
      "Epoch 12/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3617 - accuracy: 0.8677 - val_loss: 0.3445 - val_accuracy: 0.8762\n",
      "Epoch 13/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3433 - accuracy: 0.8742 - val_loss: 0.3065 - val_accuracy: 0.8864\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.3338 - accuracy: 0.8796 - val_loss: 0.3205 - val_accuracy: 0.8825\n",
      "Epoch 15/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3228 - accuracy: 0.8823 - val_loss: 0.3243 - val_accuracy: 0.8826\n",
      "Epoch 16/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3070 - accuracy: 0.8868 - val_loss: 0.3097 - val_accuracy: 0.8913\n",
      "Epoch 17/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3054 - accuracy: 0.8884 - val_loss: 0.3022 - val_accuracy: 0.8924\n",
      "Epoch 18/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2853 - accuracy: 0.8950 - val_loss: 0.3003 - val_accuracy: 0.8928\n",
      "Epoch 19/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2824 - accuracy: 0.8955 - val_loss: 0.3024 - val_accuracy: 0.8931\n",
      "Epoch 20/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2699 - accuracy: 0.9018 - val_loss: 0.3380 - val_accuracy: 0.8878\n",
      "Epoch 21/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2643 - accuracy: 0.9031 - val_loss: 0.3297 - val_accuracy: 0.8861\n",
      "Epoch 22/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2526 - accuracy: 0.9068 - val_loss: 0.3192 - val_accuracy: 0.8920\n",
      "Epoch 23/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2507 - accuracy: 0.9100 - val_loss: 0.2965 - val_accuracy: 0.8975\n",
      "Epoch 24/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2406 - accuracy: 0.9122 - val_loss: 0.3012 - val_accuracy: 0.8946\n",
      "Epoch 25/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2372 - accuracy: 0.9117 - val_loss: 0.2920 - val_accuracy: 0.8973\n",
      "Epoch 26/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.2323 - accuracy: 0.9154 - val_loss: 0.3082 - val_accuracy: 0.8941\n",
      "Epoch 27/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.2249 - accuracy: 0.9184 - val_loss: 0.2868 - val_accuracy: 0.8999\n",
      "Epoch 28/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.2167 - accuracy: 0.9210 - val_loss: 0.2963 - val_accuracy: 0.8957\n",
      "Epoch 29/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2121 - accuracy: 0.9222 - val_loss: 0.2990 - val_accuracy: 0.9005\n",
      "Epoch 30/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.2052 - accuracy: 0.9253 - val_loss: 0.2952 - val_accuracy: 0.8983\n",
      "Epoch 31/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2021 - accuracy: 0.9265 - val_loss: 0.3106 - val_accuracy: 0.8974\n",
      "Epoch 32/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.2014 - accuracy: 0.9260 - val_loss: 0.3254 - val_accuracy: 0.8986\n",
      "Epoch 33/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1941 - accuracy: 0.9286 - val_loss: 0.2970 - val_accuracy: 0.9024\n",
      "Epoch 34/50\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.1879 - accuracy: 0.9321 - val_loss: 0.3100 - val_accuracy: 0.9001\n",
      "Epoch 35/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1816 - accuracy: 0.9347 - val_loss: 0.2957 - val_accuracy: 0.8989\n",
      "Epoch 36/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1801 - accuracy: 0.9357 - val_loss: 0.3174 - val_accuracy: 0.8968\n",
      "Epoch 37/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1782 - accuracy: 0.9355 - val_loss: 0.3066 - val_accuracy: 0.9010\n",
      "Epoch 38/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1775 - accuracy: 0.9368 - val_loss: 0.2996 - val_accuracy: 0.9041\n",
      "Epoch 39/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1704 - accuracy: 0.9367 - val_loss: 0.3440 - val_accuracy: 0.9037\n",
      "Epoch 40/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1629 - accuracy: 0.9414 - val_loss: 0.3316 - val_accuracy: 0.8948\n",
      "Epoch 41/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1641 - accuracy: 0.9417 - val_loss: 0.3283 - val_accuracy: 0.9002\n",
      "Epoch 42/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1612 - accuracy: 0.9432 - val_loss: 0.3095 - val_accuracy: 0.9033\n",
      "Epoch 43/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1537 - accuracy: 0.9459 - val_loss: 0.3312 - val_accuracy: 0.9031\n",
      "Epoch 44/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1530 - accuracy: 0.9451 - val_loss: 0.3279 - val_accuracy: 0.8982\n",
      "Epoch 45/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1524 - accuracy: 0.9471 - val_loss: 0.3362 - val_accuracy: 0.9024\n",
      "Epoch 46/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1453 - accuracy: 0.9502 - val_loss: 0.3310 - val_accuracy: 0.9064\n",
      "Epoch 47/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1439 - accuracy: 0.9503 - val_loss: 0.3216 - val_accuracy: 0.9063\n",
      "Epoch 48/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1398 - accuracy: 0.9504 - val_loss: 0.3412 - val_accuracy: 0.9005\n",
      "Epoch 49/50\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.1355 - accuracy: 0.9532 - val_loss: 0.4109 - val_accuracy: 0.8896\n",
      "Epoch 50/50\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.1333 - accuracy: 0.9528 - val_loss: 0.3377 - val_accuracy: 0.9054\n",
      "Adam with learning rate = 0.001000, epochs = 50, the accuracy is: 0.906104\n",
      "Adam: 4 / 4 ###################################################\n",
      "Epoch 1/100\n",
      "1260/1260 [==============================] - 14s 10ms/step - loss: 1.9129 - accuracy: 0.4929 - val_loss: 0.6661 - val_accuracy: 0.7748\n",
      "Epoch 2/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.8073 - accuracy: 0.7457 - val_loss: 0.5186 - val_accuracy: 0.8144\n",
      "Epoch 3/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.6588 - accuracy: 0.7819 - val_loss: 0.4739 - val_accuracy: 0.8284\n",
      "Epoch 4/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.5830 - accuracy: 0.7986 - val_loss: 0.4420 - val_accuracy: 0.8419\n",
      "Epoch 5/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.5348 - accuracy: 0.8146 - val_loss: 0.3916 - val_accuracy: 0.8545\n",
      "Epoch 6/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4965 - accuracy: 0.8279 - val_loss: 0.3661 - val_accuracy: 0.8615\n",
      "Epoch 7/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4639 - accuracy: 0.8367 - val_loss: 0.3685 - val_accuracy: 0.8675\n",
      "Epoch 8/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4366 - accuracy: 0.8450 - val_loss: 0.3519 - val_accuracy: 0.8698\n",
      "Epoch 9/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4126 - accuracy: 0.8526 - val_loss: 0.3908 - val_accuracy: 0.8691\n",
      "Epoch 10/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.3921 - accuracy: 0.8584 - val_loss: 0.3532 - val_accuracy: 0.8676\n",
      "Epoch 11/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.3747 - accuracy: 0.8650 - val_loss: 0.3439 - val_accuracy: 0.8798\n",
      "Epoch 12/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.3642 - accuracy: 0.8679 - val_loss: 0.3227 - val_accuracy: 0.8858\n",
      "Epoch 13/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.3495 - accuracy: 0.8717 - val_loss: 0.3328 - val_accuracy: 0.8835\n",
      "Epoch 14/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.3344 - accuracy: 0.8804 - val_loss: 0.3152 - val_accuracy: 0.8822\n",
      "Epoch 15/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3153 - accuracy: 0.8853 - val_loss: 0.3221 - val_accuracy: 0.8844\n",
      "Epoch 16/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3091 - accuracy: 0.8868 - val_loss: 0.3017 - val_accuracy: 0.8903\n",
      "Epoch 17/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.2954 - accuracy: 0.8925 - val_loss: 0.3071 - val_accuracy: 0.8925\n",
      "Epoch 18/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2917 - accuracy: 0.8923 - val_loss: 0.2946 - val_accuracy: 0.8949\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 19/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2808 - accuracy: 0.8974 - val_loss: 0.2990 - val_accuracy: 0.8915\n",
      "Epoch 20/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2692 - accuracy: 0.9029 - val_loss: 0.4213 - val_accuracy: 0.8802\n",
      "Epoch 21/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2626 - accuracy: 0.9037 - val_loss: 0.3169 - val_accuracy: 0.8906\n",
      "Epoch 22/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.2593 - accuracy: 0.9064 - val_loss: 0.2983 - val_accuracy: 0.8951\n",
      "Epoch 23/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2480 - accuracy: 0.9093 - val_loss: 0.2980 - val_accuracy: 0.8946\n",
      "Epoch 24/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2400 - accuracy: 0.9114 - val_loss: 0.2877 - val_accuracy: 0.8982\n",
      "Epoch 25/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2415 - accuracy: 0.9115 - val_loss: 0.3036 - val_accuracy: 0.8968\n",
      "Epoch 26/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.2289 - accuracy: 0.9159 - val_loss: 0.3051 - val_accuracy: 0.8951\n",
      "Epoch 27/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2250 - accuracy: 0.9183 - val_loss: 0.2957 - val_accuracy: 0.9024\n",
      "Epoch 28/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2189 - accuracy: 0.9211 - val_loss: 0.2823 - val_accuracy: 0.9010\n",
      "Epoch 29/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2120 - accuracy: 0.9229 - val_loss: 0.2975 - val_accuracy: 0.9021\n",
      "Epoch 30/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2072 - accuracy: 0.9250 - val_loss: 0.3141 - val_accuracy: 0.8978\n",
      "Epoch 31/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.2052 - accuracy: 0.9273 - val_loss: 0.2866 - val_accuracy: 0.9044\n",
      "Epoch 32/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1986 - accuracy: 0.9275 - val_loss: 0.3042 - val_accuracy: 0.9005\n",
      "Epoch 33/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1902 - accuracy: 0.9304 - val_loss: 0.3233 - val_accuracy: 0.9009\n",
      "Epoch 34/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1938 - accuracy: 0.9312 - val_loss: 0.3133 - val_accuracy: 0.8972\n",
      "Epoch 35/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1854 - accuracy: 0.9340 - val_loss: 0.2992 - val_accuracy: 0.9022\n",
      "Epoch 36/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1764 - accuracy: 0.9363 - val_loss: 0.3080 - val_accuracy: 0.9035\n",
      "Epoch 37/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1761 - accuracy: 0.9369 - val_loss: 0.3041 - val_accuracy: 0.9037\n",
      "Epoch 38/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1742 - accuracy: 0.9386 - val_loss: 0.3038 - val_accuracy: 0.9047\n",
      "Epoch 39/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1662 - accuracy: 0.9408 - val_loss: 0.3047 - val_accuracy: 0.9051\n",
      "Epoch 40/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.1647 - accuracy: 0.9410 - val_loss: 0.3244 - val_accuracy: 0.9006\n",
      "Epoch 41/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1634 - accuracy: 0.9415 - val_loss: 0.3155 - val_accuracy: 0.9035\n",
      "Epoch 42/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.1589 - accuracy: 0.9421 - val_loss: 0.3236 - val_accuracy: 0.9031\n",
      "Epoch 43/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.1538 - accuracy: 0.9444 - val_loss: 0.3364 - val_accuracy: 0.8989\n",
      "Epoch 44/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1534 - accuracy: 0.9463 - val_loss: 0.3136 - val_accuracy: 0.9056\n",
      "Epoch 45/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1489 - accuracy: 0.9482 - val_loss: 0.3341 - val_accuracy: 0.9020\n",
      "Epoch 46/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1485 - accuracy: 0.9488 - val_loss: 0.3296 - val_accuracy: 0.9089\n",
      "Epoch 47/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1430 - accuracy: 0.9492 - val_loss: 0.3242 - val_accuracy: 0.9030\n",
      "Epoch 48/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1399 - accuracy: 0.9516 - val_loss: 0.3273 - val_accuracy: 0.9043\n",
      "Epoch 49/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1421 - accuracy: 0.9516 - val_loss: 0.3843 - val_accuracy: 0.8970\n",
      "Epoch 50/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1376 - accuracy: 0.9513 - val_loss: 0.3510 - val_accuracy: 0.9005\n",
      "Epoch 51/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1339 - accuracy: 0.9535 - val_loss: 0.3402 - val_accuracy: 0.9044\n",
      "Epoch 52/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1310 - accuracy: 0.9541 - val_loss: 0.3477 - val_accuracy: 0.9037\n",
      "Epoch 53/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1263 - accuracy: 0.9560 - val_loss: 0.3344 - val_accuracy: 0.9038\n",
      "Epoch 54/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1250 - accuracy: 0.9563 - val_loss: 0.3343 - val_accuracy: 0.9021\n",
      "Epoch 55/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1273 - accuracy: 0.9572 - val_loss: 0.3493 - val_accuracy: 0.9044\n",
      "Epoch 56/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1194 - accuracy: 0.9583 - val_loss: 0.3435 - val_accuracy: 0.9058\n",
      "Epoch 57/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1140 - accuracy: 0.9595 - val_loss: 0.3671 - val_accuracy: 0.8986\n",
      "Epoch 58/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1196 - accuracy: 0.9586 - val_loss: 0.3955 - val_accuracy: 0.8984\n",
      "Epoch 59/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1205 - accuracy: 0.9580 - val_loss: 0.3582 - val_accuracy: 0.9027\n",
      "Epoch 60/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1126 - accuracy: 0.9607 - val_loss: 0.3527 - val_accuracy: 0.9099\n",
      "Epoch 61/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1138 - accuracy: 0.9614 - val_loss: 0.3892 - val_accuracy: 0.9012\n",
      "Epoch 62/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1091 - accuracy: 0.9620 - val_loss: 0.3607 - val_accuracy: 0.9065\n",
      "Epoch 63/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1082 - accuracy: 0.9609 - val_loss: 0.3743 - val_accuracy: 0.9039\n",
      "Epoch 64/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1087 - accuracy: 0.9632 - val_loss: 0.3635 - val_accuracy: 0.9077\n",
      "Epoch 65/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1081 - accuracy: 0.9627 - val_loss: 0.3825 - val_accuracy: 0.9011\n",
      "Epoch 66/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1019 - accuracy: 0.9638 - val_loss: 0.3961 - val_accuracy: 0.9024\n",
      "Epoch 67/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0987 - accuracy: 0.9655 - val_loss: 0.3847 - val_accuracy: 0.9052\n",
      "Epoch 68/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1024 - accuracy: 0.9642 - val_loss: 0.3961 - val_accuracy: 0.9014\n",
      "Epoch 69/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1003 - accuracy: 0.9658 - val_loss: 0.3729 - val_accuracy: 0.9046\n",
      "Epoch 70/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0981 - accuracy: 0.9670 - val_loss: 0.4212 - val_accuracy: 0.8999\n",
      "Epoch 71/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0977 - accuracy: 0.9665 - val_loss: 0.3880 - val_accuracy: 0.9037\n",
      "Epoch 72/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.0943 - accuracy: 0.9677 - val_loss: 0.3915 - val_accuracy: 0.9044\n",
      "Epoch 73/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0974 - accuracy: 0.9670 - val_loss: 0.3915 - val_accuracy: 0.9050\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0927 - accuracy: 0.9686 - val_loss: 0.3804 - val_accuracy: 0.9093\n",
      "Epoch 75/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0936 - accuracy: 0.9679 - val_loss: 0.4034 - val_accuracy: 0.9076\n",
      "Epoch 76/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0925 - accuracy: 0.9680 - val_loss: 0.4124 - val_accuracy: 0.9034\n",
      "Epoch 77/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0884 - accuracy: 0.9697 - val_loss: 0.4112 - val_accuracy: 0.9048\n",
      "Epoch 78/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0858 - accuracy: 0.9704 - val_loss: 0.3736 - val_accuracy: 0.9085\n",
      "Epoch 79/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0885 - accuracy: 0.9692 - val_loss: 0.4046 - val_accuracy: 0.9040\n",
      "Epoch 80/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0847 - accuracy: 0.9705 - val_loss: 0.4016 - val_accuracy: 0.9048\n",
      "Epoch 81/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0878 - accuracy: 0.9704 - val_loss: 0.3831 - val_accuracy: 0.9086\n",
      "Epoch 82/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0858 - accuracy: 0.9702 - val_loss: 0.4267 - val_accuracy: 0.9003\n",
      "Epoch 83/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0888 - accuracy: 0.9685 - val_loss: 0.3801 - val_accuracy: 0.9066\n",
      "Epoch 84/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0811 - accuracy: 0.9720 - val_loss: 0.3964 - val_accuracy: 0.9061\n",
      "Epoch 85/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0831 - accuracy: 0.9700 - val_loss: 0.3973 - val_accuracy: 0.9042\n",
      "Epoch 86/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.0818 - accuracy: 0.9715 - val_loss: 0.3967 - val_accuracy: 0.9079\n",
      "Epoch 87/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0778 - accuracy: 0.9734 - val_loss: 0.4284 - val_accuracy: 0.9020\n",
      "Epoch 88/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0804 - accuracy: 0.9717 - val_loss: 0.4036 - val_accuracy: 0.9091\n",
      "Epoch 89/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0768 - accuracy: 0.9734 - val_loss: 0.4004 - val_accuracy: 0.9052\n",
      "Epoch 90/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.0745 - accuracy: 0.9744 - val_loss: 0.4081 - val_accuracy: 0.9080\n",
      "Epoch 91/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0754 - accuracy: 0.9733 - val_loss: 0.4551 - val_accuracy: 0.9029\n",
      "Epoch 92/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.0796 - accuracy: 0.9727 - val_loss: 0.4413 - val_accuracy: 0.9031\n",
      "Epoch 93/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0752 - accuracy: 0.9740 - val_loss: 0.4239 - val_accuracy: 0.9025\n",
      "Epoch 94/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.0762 - accuracy: 0.9735 - val_loss: 0.4471 - val_accuracy: 0.8985\n",
      "Epoch 95/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.0778 - accuracy: 0.9728 - val_loss: 0.4771 - val_accuracy: 0.9004\n",
      "Epoch 96/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.0704 - accuracy: 0.9748 - val_loss: 0.4593 - val_accuracy: 0.9054\n",
      "Epoch 97/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0727 - accuracy: 0.9745 - val_loss: 0.4349 - val_accuracy: 0.9057\n",
      "Epoch 98/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.0760 - accuracy: 0.9732 - val_loss: 0.4314 - val_accuracy: 0.9071\n",
      "Epoch 99/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.0713 - accuracy: 0.9746 - val_loss: 0.4514 - val_accuracy: 0.9048\n",
      "Epoch 100/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.0718 - accuracy: 0.9746 - val_loss: 0.4699 - val_accuracy: 0.9051\n",
      "Adam with learning rate = 0.001000, epochs = 100, the accuracy is: 0.904119\n",
      " SGD: 5 / 4 ###################################################\n",
      "Epoch 1/50\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 3.3328 - accuracy: 0.2139 - val_loss: 1.4316 - val_accuracy: 0.6940\n",
      "Epoch 2/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 1.7405 - accuracy: 0.5329 - val_loss: 0.8544 - val_accuracy: 0.7684\n",
      "Epoch 3/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 1.2678 - accuracy: 0.6512 - val_loss: 0.6558 - val_accuracy: 0.8123\n",
      "Epoch 4/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 1.0576 - accuracy: 0.6988 - val_loss: 0.5992 - val_accuracy: 0.8127\n",
      "Epoch 5/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.9180 - accuracy: 0.7321 - val_loss: 0.5394 - val_accuracy: 0.8321\n",
      "Epoch 6/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.8407 - accuracy: 0.7488 - val_loss: 0.5143 - val_accuracy: 0.8373\n",
      "Epoch 7/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.7813 - accuracy: 0.7625 - val_loss: 0.4807 - val_accuracy: 0.8434\n",
      "Epoch 8/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.7294 - accuracy: 0.7754 - val_loss: 0.4657 - val_accuracy: 0.8483\n",
      "Epoch 9/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.6933 - accuracy: 0.7811 - val_loss: 0.4509 - val_accuracy: 0.8512\n",
      "Epoch 10/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.6675 - accuracy: 0.7882 - val_loss: 0.4410 - val_accuracy: 0.8547\n",
      "Epoch 11/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.6363 - accuracy: 0.7978 - val_loss: 0.4215 - val_accuracy: 0.8575\n",
      "Epoch 12/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.6161 - accuracy: 0.8004 - val_loss: 0.4147 - val_accuracy: 0.8576\n",
      "Epoch 13/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.5894 - accuracy: 0.8046 - val_loss: 0.4063 - val_accuracy: 0.8568\n",
      "Epoch 14/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.5701 - accuracy: 0.8097 - val_loss: 0.3974 - val_accuracy: 0.8652\n",
      "Epoch 15/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.5528 - accuracy: 0.8175 - val_loss: 0.4036 - val_accuracy: 0.8610\n",
      "Epoch 16/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.5369 - accuracy: 0.8213 - val_loss: 0.3947 - val_accuracy: 0.8646\n",
      "Epoch 17/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.5233 - accuracy: 0.8235 - val_loss: 0.3794 - val_accuracy: 0.8686\n",
      "Epoch 18/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.5106 - accuracy: 0.8284 - val_loss: 0.3704 - val_accuracy: 0.8717\n",
      "Epoch 19/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4965 - accuracy: 0.8296 - val_loss: 0.3639 - val_accuracy: 0.8762\n",
      "Epoch 20/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4873 - accuracy: 0.8334 - val_loss: 0.3735 - val_accuracy: 0.8710\n",
      "Epoch 21/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4720 - accuracy: 0.8385 - val_loss: 0.3742 - val_accuracy: 0.8702\n",
      "Epoch 22/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4595 - accuracy: 0.8397 - val_loss: 0.3580 - val_accuracy: 0.8748\n",
      "Epoch 23/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4515 - accuracy: 0.8439 - val_loss: 0.3548 - val_accuracy: 0.8763\n",
      "Epoch 24/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4415 - accuracy: 0.8469 - val_loss: 0.3474 - val_accuracy: 0.8741\n",
      "Epoch 25/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.4334 - accuracy: 0.8505 - val_loss: 0.3457 - val_accuracy: 0.8775\n",
      "Epoch 26/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4318 - accuracy: 0.8511 - val_loss: 0.3415 - val_accuracy: 0.8793\n",
      "Epoch 27/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4133 - accuracy: 0.8550 - val_loss: 0.3407 - val_accuracy: 0.8779\n",
      "Epoch 28/50\n",
      "1260/1260 [==============================] - 12s 10ms/step - loss: 0.4082 - accuracy: 0.8565 - val_loss: 0.3340 - val_accuracy: 0.8826\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 29/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4019 - accuracy: 0.8613 - val_loss: 0.3329 - val_accuracy: 0.8807\n",
      "Epoch 30/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3898 - accuracy: 0.8621 - val_loss: 0.3291 - val_accuracy: 0.8825\n",
      "Epoch 31/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3810 - accuracy: 0.8632 - val_loss: 0.3276 - val_accuracy: 0.8840\n",
      "Epoch 32/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3774 - accuracy: 0.8654 - val_loss: 0.3386 - val_accuracy: 0.8820\n",
      "Epoch 33/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3815 - accuracy: 0.8639 - val_loss: 0.3292 - val_accuracy: 0.8836\n",
      "Epoch 34/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3668 - accuracy: 0.8687 - val_loss: 0.3232 - val_accuracy: 0.8874\n",
      "Epoch 35/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3642 - accuracy: 0.8691 - val_loss: 0.3245 - val_accuracy: 0.8855\n",
      "Epoch 36/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3582 - accuracy: 0.8719 - val_loss: 0.3265 - val_accuracy: 0.8864\n",
      "Epoch 37/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3491 - accuracy: 0.8745 - val_loss: 0.3170 - val_accuracy: 0.8872\n",
      "Epoch 38/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3470 - accuracy: 0.8756 - val_loss: 0.3147 - val_accuracy: 0.8894\n",
      "Epoch 39/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3358 - accuracy: 0.8794 - val_loss: 0.3122 - val_accuracy: 0.8886\n",
      "Epoch 40/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.3347 - accuracy: 0.8805 - val_loss: 0.3273 - val_accuracy: 0.8879\n",
      "Epoch 41/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.3295 - accuracy: 0.8819 - val_loss: 0.3097 - val_accuracy: 0.8899\n",
      "Epoch 42/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3251 - accuracy: 0.8837 - val_loss: 0.3070 - val_accuracy: 0.8912\n",
      "Epoch 43/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.3211 - accuracy: 0.8835 - val_loss: 0.3126 - val_accuracy: 0.8903\n",
      "Epoch 44/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3178 - accuracy: 0.8852 - val_loss: 0.3098 - val_accuracy: 0.8918\n",
      "Epoch 45/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.3106 - accuracy: 0.8887 - val_loss: 0.3126 - val_accuracy: 0.8904\n",
      "Epoch 46/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3101 - accuracy: 0.8885 - val_loss: 0.3083 - val_accuracy: 0.8906\n",
      "Epoch 47/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3041 - accuracy: 0.8902 - val_loss: 0.3073 - val_accuracy: 0.8910\n",
      "Epoch 48/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2987 - accuracy: 0.8924 - val_loss: 0.3141 - val_accuracy: 0.8911\n",
      "Epoch 49/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2930 - accuracy: 0.8946 - val_loss: 0.3079 - val_accuracy: 0.8935\n",
      "Epoch 50/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2938 - accuracy: 0.8950 - val_loss: 0.3077 - val_accuracy: 0.8943\n",
      "SGD with learning rate = 0.001000, epochs = 50, the accuracy is: 0.892690\n",
      " SGD: 6 / 4 ###################################################\n",
      "Epoch 1/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 3.2919 - accuracy: 0.2164 - val_loss: 1.3920 - val_accuracy: 0.7008\n",
      "Epoch 2/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 1.7336 - accuracy: 0.5347 - val_loss: 0.8433 - val_accuracy: 0.7844\n",
      "Epoch 3/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 1.2697 - accuracy: 0.6490 - val_loss: 0.6533 - val_accuracy: 0.8132\n",
      "Epoch 4/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 1.0411 - accuracy: 0.7034 - val_loss: 0.5896 - val_accuracy: 0.8166\n",
      "Epoch 5/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.9138 - accuracy: 0.7332 - val_loss: 0.5407 - val_accuracy: 0.8329\n",
      "Epoch 6/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.8299 - accuracy: 0.7518 - val_loss: 0.5084 - val_accuracy: 0.8371\n",
      "Epoch 7/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.7713 - accuracy: 0.7672 - val_loss: 0.4946 - val_accuracy: 0.8383\n",
      "Epoch 8/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.7310 - accuracy: 0.7725 - val_loss: 0.4745 - val_accuracy: 0.8402\n",
      "Epoch 9/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.6896 - accuracy: 0.7832 - val_loss: 0.4528 - val_accuracy: 0.8468\n",
      "Epoch 10/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.6568 - accuracy: 0.7907 - val_loss: 0.4482 - val_accuracy: 0.8520\n",
      "Epoch 11/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.6275 - accuracy: 0.7970 - val_loss: 0.4202 - val_accuracy: 0.8596\n",
      "Epoch 12/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.6051 - accuracy: 0.8030 - val_loss: 0.4101 - val_accuracy: 0.8639\n",
      "Epoch 13/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.5838 - accuracy: 0.8074 - val_loss: 0.4073 - val_accuracy: 0.8602\n",
      "Epoch 14/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.5650 - accuracy: 0.8126 - val_loss: 0.4058 - val_accuracy: 0.8613\n",
      "Epoch 15/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.5428 - accuracy: 0.8186 - val_loss: 0.3959 - val_accuracy: 0.8612\n",
      "Epoch 16/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.5296 - accuracy: 0.8216 - val_loss: 0.3856 - val_accuracy: 0.8663\n",
      "Epoch 17/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.5153 - accuracy: 0.8270 - val_loss: 0.3796 - val_accuracy: 0.8685\n",
      "Epoch 18/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.5019 - accuracy: 0.8297 - val_loss: 0.3667 - val_accuracy: 0.8698\n",
      "Epoch 19/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4852 - accuracy: 0.8365 - val_loss: 0.3629 - val_accuracy: 0.8732\n",
      "Epoch 20/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4741 - accuracy: 0.8385 - val_loss: 0.3673 - val_accuracy: 0.8707\n",
      "Epoch 21/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4625 - accuracy: 0.8392 - val_loss: 0.3609 - val_accuracy: 0.8740\n",
      "Epoch 22/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4509 - accuracy: 0.8435 - val_loss: 0.3541 - val_accuracy: 0.8761\n",
      "Epoch 23/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4404 - accuracy: 0.8494 - val_loss: 0.3485 - val_accuracy: 0.8771\n",
      "Epoch 24/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4335 - accuracy: 0.8511 - val_loss: 0.3421 - val_accuracy: 0.8814\n",
      "Epoch 25/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4200 - accuracy: 0.8516 - val_loss: 0.3422 - val_accuracy: 0.8818\n",
      "Epoch 26/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4160 - accuracy: 0.8539 - val_loss: 0.3373 - val_accuracy: 0.8797\n",
      "Epoch 27/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4067 - accuracy: 0.8582 - val_loss: 0.3339 - val_accuracy: 0.8808\n",
      "Epoch 28/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3960 - accuracy: 0.8604 - val_loss: 0.3270 - val_accuracy: 0.8805\n",
      "Epoch 29/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3858 - accuracy: 0.8631 - val_loss: 0.3282 - val_accuracy: 0.8847\n",
      "Epoch 30/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.3724 - accuracy: 0.8664 - val_loss: 0.3311 - val_accuracy: 0.8855\n",
      "Epoch 31/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3700 - accuracy: 0.8674 - val_loss: 0.3244 - val_accuracy: 0.8846\n",
      "Epoch 32/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3628 - accuracy: 0.8704 - val_loss: 0.3262 - val_accuracy: 0.8849\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3598 - accuracy: 0.8721 - val_loss: 0.3196 - val_accuracy: 0.8852\n",
      "Epoch 34/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3542 - accuracy: 0.8750 - val_loss: 0.3119 - val_accuracy: 0.8886\n",
      "Epoch 35/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3446 - accuracy: 0.8760 - val_loss: 0.3125 - val_accuracy: 0.8877\n",
      "Epoch 36/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3392 - accuracy: 0.8796 - val_loss: 0.3101 - val_accuracy: 0.8924\n",
      "Epoch 37/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3348 - accuracy: 0.8789 - val_loss: 0.3076 - val_accuracy: 0.8917\n",
      "Epoch 38/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3306 - accuracy: 0.8801 - val_loss: 0.3087 - val_accuracy: 0.8916\n",
      "Epoch 39/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3196 - accuracy: 0.8840 - val_loss: 0.3104 - val_accuracy: 0.8893\n",
      "Epoch 40/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3154 - accuracy: 0.8888 - val_loss: 0.3155 - val_accuracy: 0.8892\n",
      "Epoch 41/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3079 - accuracy: 0.8891 - val_loss: 0.3099 - val_accuracy: 0.8917\n",
      "Epoch 42/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3041 - accuracy: 0.8896 - val_loss: 0.2994 - val_accuracy: 0.8927\n",
      "Epoch 43/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2975 - accuracy: 0.8909 - val_loss: 0.3017 - val_accuracy: 0.8916\n",
      "Epoch 44/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2986 - accuracy: 0.8916 - val_loss: 0.2972 - val_accuracy: 0.8955\n",
      "Epoch 45/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2909 - accuracy: 0.8939 - val_loss: 0.3040 - val_accuracy: 0.8924\n",
      "Epoch 46/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2896 - accuracy: 0.8953 - val_loss: 0.2955 - val_accuracy: 0.8953\n",
      "Epoch 47/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2840 - accuracy: 0.8973 - val_loss: 0.3017 - val_accuracy: 0.8954\n",
      "Epoch 48/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2836 - accuracy: 0.8967 - val_loss: 0.3051 - val_accuracy: 0.8957\n",
      "Epoch 49/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2763 - accuracy: 0.9015 - val_loss: 0.2997 - val_accuracy: 0.8944\n",
      "Epoch 50/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2706 - accuracy: 0.9019 - val_loss: 0.2977 - val_accuracy: 0.8957\n",
      "Epoch 51/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2662 - accuracy: 0.9034 - val_loss: 0.2951 - val_accuracy: 0.8947\n",
      "Epoch 52/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2670 - accuracy: 0.9018 - val_loss: 0.2954 - val_accuracy: 0.8975\n",
      "Epoch 53/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2602 - accuracy: 0.9054 - val_loss: 0.2955 - val_accuracy: 0.8960\n",
      "Epoch 54/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2562 - accuracy: 0.9069 - val_loss: 0.2972 - val_accuracy: 0.8953\n",
      "Epoch 55/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2593 - accuracy: 0.9078 - val_loss: 0.3113 - val_accuracy: 0.8926\n",
      "Epoch 56/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2522 - accuracy: 0.9083 - val_loss: 0.2968 - val_accuracy: 0.8972\n",
      "Epoch 57/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2429 - accuracy: 0.9117 - val_loss: 0.3015 - val_accuracy: 0.8937\n",
      "Epoch 58/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2478 - accuracy: 0.9094 - val_loss: 0.2923 - val_accuracy: 0.8970\n",
      "Epoch 59/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2453 - accuracy: 0.9108 - val_loss: 0.2874 - val_accuracy: 0.9012\n",
      "Epoch 60/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2384 - accuracy: 0.9137 - val_loss: 0.3010 - val_accuracy: 0.8966\n",
      "Epoch 61/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2334 - accuracy: 0.9156 - val_loss: 0.2938 - val_accuracy: 0.8992\n",
      "Epoch 62/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2337 - accuracy: 0.9159 - val_loss: 0.2839 - val_accuracy: 0.9017\n",
      "Epoch 63/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2325 - accuracy: 0.9176 - val_loss: 0.2962 - val_accuracy: 0.8996\n",
      "Epoch 64/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2244 - accuracy: 0.9186 - val_loss: 0.2927 - val_accuracy: 0.8996\n",
      "Epoch 65/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2241 - accuracy: 0.9194 - val_loss: 0.2944 - val_accuracy: 0.8983\n",
      "Epoch 66/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2188 - accuracy: 0.9210 - val_loss: 0.2956 - val_accuracy: 0.9017\n",
      "Epoch 67/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2176 - accuracy: 0.9228 - val_loss: 0.2957 - val_accuracy: 0.9011\n",
      "Epoch 68/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2162 - accuracy: 0.9232 - val_loss: 0.3014 - val_accuracy: 0.9004\n",
      "Epoch 69/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2111 - accuracy: 0.9245 - val_loss: 0.2959 - val_accuracy: 0.8995\n",
      "Epoch 70/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2116 - accuracy: 0.9241 - val_loss: 0.2989 - val_accuracy: 0.8978\n",
      "Epoch 71/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2069 - accuracy: 0.9247 - val_loss: 0.3029 - val_accuracy: 0.9000\n",
      "Epoch 72/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2052 - accuracy: 0.9272 - val_loss: 0.2963 - val_accuracy: 0.8991\n",
      "Epoch 73/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1996 - accuracy: 0.9291 - val_loss: 0.2947 - val_accuracy: 0.9006\n",
      "Epoch 74/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2042 - accuracy: 0.9264 - val_loss: 0.2968 - val_accuracy: 0.9003\n",
      "Epoch 75/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2007 - accuracy: 0.9282 - val_loss: 0.3006 - val_accuracy: 0.9002\n",
      "Epoch 76/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1996 - accuracy: 0.9297 - val_loss: 0.3092 - val_accuracy: 0.8989\n",
      "Epoch 77/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1967 - accuracy: 0.9308 - val_loss: 0.3022 - val_accuracy: 0.8996\n",
      "Epoch 78/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1929 - accuracy: 0.9332 - val_loss: 0.2961 - val_accuracy: 0.9052\n",
      "Epoch 79/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1920 - accuracy: 0.9334 - val_loss: 0.3003 - val_accuracy: 0.9018\n",
      "Epoch 80/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1844 - accuracy: 0.9356 - val_loss: 0.3020 - val_accuracy: 0.9016\n",
      "Epoch 81/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1833 - accuracy: 0.9352 - val_loss: 0.3011 - val_accuracy: 0.9010\n",
      "Epoch 82/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1845 - accuracy: 0.9349 - val_loss: 0.3056 - val_accuracy: 0.9010\n",
      "Epoch 83/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1816 - accuracy: 0.9360 - val_loss: 0.2987 - val_accuracy: 0.9029\n",
      "Epoch 84/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1791 - accuracy: 0.9370 - val_loss: 0.2996 - val_accuracy: 0.9038\n",
      "Epoch 85/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.1755 - accuracy: 0.9375 - val_loss: 0.3077 - val_accuracy: 0.9005\n",
      "Epoch 86/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1732 - accuracy: 0.9409 - val_loss: 0.3102 - val_accuracy: 0.9004\n",
      "Epoch 87/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1745 - accuracy: 0.9393 - val_loss: 0.3173 - val_accuracy: 0.8997\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1728 - accuracy: 0.9405 - val_loss: 0.3079 - val_accuracy: 0.9018\n",
      "Epoch 89/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1698 - accuracy: 0.9418 - val_loss: 0.3117 - val_accuracy: 0.8999\n",
      "Epoch 90/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1638 - accuracy: 0.9433 - val_loss: 0.3160 - val_accuracy: 0.9007\n",
      "Epoch 91/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1670 - accuracy: 0.9423 - val_loss: 0.3142 - val_accuracy: 0.9040\n",
      "Epoch 92/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1643 - accuracy: 0.9440 - val_loss: 0.3119 - val_accuracy: 0.9033\n",
      "Epoch 93/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.1622 - accuracy: 0.9443 - val_loss: 0.3211 - val_accuracy: 0.8996\n",
      "Epoch 94/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1599 - accuracy: 0.9448 - val_loss: 0.3209 - val_accuracy: 0.9005\n",
      "Epoch 95/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1612 - accuracy: 0.9443 - val_loss: 0.3107 - val_accuracy: 0.9024\n",
      "Epoch 96/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1581 - accuracy: 0.9465 - val_loss: 0.3173 - val_accuracy: 0.9030\n",
      "Epoch 97/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1563 - accuracy: 0.9462 - val_loss: 0.3140 - val_accuracy: 0.9016\n",
      "Epoch 98/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1549 - accuracy: 0.9469 - val_loss: 0.3177 - val_accuracy: 0.9040\n",
      "Epoch 99/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1543 - accuracy: 0.9476 - val_loss: 0.3100 - val_accuracy: 0.9047\n",
      "Epoch 100/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1467 - accuracy: 0.9507 - val_loss: 0.3107 - val_accuracy: 0.9051\n",
      "SGD with learning rate = 0.001000, epochs = 100, the accuracy is: 0.902849\n",
      " SGD: 7 / 4 ###################################################\n",
      "Epoch 1/50\n",
      "1260/1260 [==============================] - 14s 10ms/step - loss: 2.0267 - accuracy: 0.4584 - val_loss: 0.7417 - val_accuracy: 0.7678\n",
      "Epoch 2/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.9089 - accuracy: 0.7210 - val_loss: 0.5449 - val_accuracy: 0.8089\n",
      "Epoch 3/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.7364 - accuracy: 0.7644 - val_loss: 0.4807 - val_accuracy: 0.8380\n",
      "Epoch 4/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.6619 - accuracy: 0.7837 - val_loss: 0.4470 - val_accuracy: 0.8464\n",
      "Epoch 5/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.5986 - accuracy: 0.8026 - val_loss: 0.4222 - val_accuracy: 0.8470\n",
      "Epoch 6/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.5480 - accuracy: 0.8139 - val_loss: 0.4031 - val_accuracy: 0.8570\n",
      "Epoch 7/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.5269 - accuracy: 0.8210 - val_loss: 0.3785 - val_accuracy: 0.8653\n",
      "Epoch 8/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4916 - accuracy: 0.8304 - val_loss: 0.3693 - val_accuracy: 0.8634\n",
      "Epoch 9/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4652 - accuracy: 0.8373 - val_loss: 0.3630 - val_accuracy: 0.8722\n",
      "Epoch 10/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4480 - accuracy: 0.8440 - val_loss: 0.3524 - val_accuracy: 0.8689\n",
      "Epoch 11/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.4252 - accuracy: 0.8513 - val_loss: 0.3392 - val_accuracy: 0.8798\n",
      "Epoch 12/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4088 - accuracy: 0.8565 - val_loss: 0.3438 - val_accuracy: 0.8785\n",
      "Epoch 13/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3997 - accuracy: 0.8577 - val_loss: 0.3274 - val_accuracy: 0.8810\n",
      "Epoch 14/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3838 - accuracy: 0.8626 - val_loss: 0.3220 - val_accuracy: 0.8806\n",
      "Epoch 15/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3635 - accuracy: 0.8684 - val_loss: 0.3235 - val_accuracy: 0.8815\n",
      "Epoch 16/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3616 - accuracy: 0.8731 - val_loss: 0.3211 - val_accuracy: 0.8834\n",
      "Epoch 17/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3479 - accuracy: 0.8733 - val_loss: 0.3229 - val_accuracy: 0.8847\n",
      "Epoch 18/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3383 - accuracy: 0.8763 - val_loss: 0.3075 - val_accuracy: 0.8904\n",
      "Epoch 19/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3288 - accuracy: 0.8816 - val_loss: 0.3072 - val_accuracy: 0.8877\n",
      "Epoch 20/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3194 - accuracy: 0.8822 - val_loss: 0.3144 - val_accuracy: 0.8877\n",
      "Epoch 21/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3097 - accuracy: 0.8868 - val_loss: 0.3186 - val_accuracy: 0.8856\n",
      "Epoch 22/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3060 - accuracy: 0.8882 - val_loss: 0.2977 - val_accuracy: 0.8896\n",
      "Epoch 23/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2968 - accuracy: 0.8937 - val_loss: 0.2952 - val_accuracy: 0.8940\n",
      "Epoch 24/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2902 - accuracy: 0.8943 - val_loss: 0.3038 - val_accuracy: 0.8916\n",
      "Epoch 25/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2846 - accuracy: 0.8964 - val_loss: 0.2986 - val_accuracy: 0.8922\n",
      "Epoch 26/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2772 - accuracy: 0.8991 - val_loss: 0.2983 - val_accuracy: 0.8910\n",
      "Epoch 27/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2742 - accuracy: 0.8989 - val_loss: 0.2921 - val_accuracy: 0.8976\n",
      "Epoch 28/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2666 - accuracy: 0.9017 - val_loss: 0.2976 - val_accuracy: 0.8934\n",
      "Epoch 29/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2594 - accuracy: 0.9053 - val_loss: 0.2941 - val_accuracy: 0.8959\n",
      "Epoch 30/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2551 - accuracy: 0.9085 - val_loss: 0.2917 - val_accuracy: 0.8974\n",
      "Epoch 31/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2498 - accuracy: 0.9077 - val_loss: 0.2964 - val_accuracy: 0.8945\n",
      "Epoch 32/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2468 - accuracy: 0.9099 - val_loss: 0.3042 - val_accuracy: 0.8939\n",
      "Epoch 33/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2427 - accuracy: 0.9118 - val_loss: 0.2926 - val_accuracy: 0.8970\n",
      "Epoch 34/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2376 - accuracy: 0.9141 - val_loss: 0.2953 - val_accuracy: 0.8971\n",
      "Epoch 35/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2327 - accuracy: 0.9157 - val_loss: 0.2858 - val_accuracy: 0.8991\n",
      "Epoch 36/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2256 - accuracy: 0.9185 - val_loss: 0.2929 - val_accuracy: 0.9009\n",
      "Epoch 37/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2266 - accuracy: 0.9178 - val_loss: 0.2981 - val_accuracy: 0.8978\n",
      "Epoch 38/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2281 - accuracy: 0.9166 - val_loss: 0.2961 - val_accuracy: 0.8996\n",
      "Epoch 39/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2162 - accuracy: 0.9211 - val_loss: 0.3004 - val_accuracy: 0.8992\n",
      "Epoch 40/50\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.2157 - accuracy: 0.9209 - val_loss: 0.3092 - val_accuracy: 0.8956\n",
      "Epoch 41/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2148 - accuracy: 0.9224 - val_loss: 0.2954 - val_accuracy: 0.8989\n",
      "Epoch 42/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2103 - accuracy: 0.9223 - val_loss: 0.2990 - val_accuracy: 0.8977\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 43/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2058 - accuracy: 0.9260 - val_loss: 0.2994 - val_accuracy: 0.9005\n",
      "Epoch 44/50\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.2061 - accuracy: 0.9249 - val_loss: 0.2905 - val_accuracy: 0.8996\n",
      "Epoch 45/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2042 - accuracy: 0.9284 - val_loss: 0.2980 - val_accuracy: 0.8980\n",
      "Epoch 46/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1989 - accuracy: 0.9289 - val_loss: 0.2943 - val_accuracy: 0.9001\n",
      "Epoch 47/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1938 - accuracy: 0.9299 - val_loss: 0.2979 - val_accuracy: 0.8996\n",
      "Epoch 48/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1943 - accuracy: 0.9303 - val_loss: 0.2978 - val_accuracy: 0.9008\n",
      "Epoch 49/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1920 - accuracy: 0.9305 - val_loss: 0.3077 - val_accuracy: 0.8978\n",
      "Epoch 50/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1901 - accuracy: 0.9314 - val_loss: 0.2995 - val_accuracy: 0.8994\n",
      "SGD with learning rate = 0.010000, epochs = 50, the accuracy is: 0.901024\n",
      " SGD: 8 / 4 ###################################################\n",
      "Epoch 1/100\n",
      "1260/1260 [==============================] - 15s 11ms/step - loss: 1.9238 - accuracy: 0.4788 - val_loss: 0.7068 - val_accuracy: 0.7753\n",
      "Epoch 2/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.8880 - accuracy: 0.7256 - val_loss: 0.5449 - val_accuracy: 0.8150\n",
      "Epoch 3/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.7234 - accuracy: 0.7645 - val_loss: 0.4756 - val_accuracy: 0.8324\n",
      "Epoch 4/100\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.6346 - accuracy: 0.7900 - val_loss: 0.4450 - val_accuracy: 0.8477\n",
      "Epoch 5/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.5820 - accuracy: 0.8030 - val_loss: 0.4216 - val_accuracy: 0.8424\n",
      "Epoch 6/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.5390 - accuracy: 0.8159 - val_loss: 0.3951 - val_accuracy: 0.8605\n",
      "Epoch 7/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.5088 - accuracy: 0.8251 - val_loss: 0.3878 - val_accuracy: 0.8633\n",
      "Epoch 8/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4777 - accuracy: 0.8322 - val_loss: 0.3610 - val_accuracy: 0.8671\n",
      "Epoch 9/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4510 - accuracy: 0.8386 - val_loss: 0.3632 - val_accuracy: 0.8708\n",
      "Epoch 10/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4337 - accuracy: 0.8460 - val_loss: 0.3605 - val_accuracy: 0.8706\n",
      "Epoch 11/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4043 - accuracy: 0.8569 - val_loss: 0.3346 - val_accuracy: 0.8804\n",
      "Epoch 12/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3946 - accuracy: 0.8594 - val_loss: 0.3344 - val_accuracy: 0.8785\n",
      "Epoch 13/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3778 - accuracy: 0.8620 - val_loss: 0.3215 - val_accuracy: 0.8853\n",
      "Epoch 14/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3643 - accuracy: 0.8677 - val_loss: 0.3209 - val_accuracy: 0.8846\n",
      "Epoch 15/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3500 - accuracy: 0.8722 - val_loss: 0.3203 - val_accuracy: 0.8836\n",
      "Epoch 16/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3349 - accuracy: 0.8785 - val_loss: 0.3174 - val_accuracy: 0.8858\n",
      "Epoch 17/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3277 - accuracy: 0.8792 - val_loss: 0.3150 - val_accuracy: 0.8868\n",
      "Epoch 18/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3166 - accuracy: 0.8830 - val_loss: 0.2986 - val_accuracy: 0.8935\n",
      "Epoch 19/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3085 - accuracy: 0.8861 - val_loss: 0.3013 - val_accuracy: 0.8928\n",
      "Epoch 20/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2924 - accuracy: 0.8909 - val_loss: 0.3040 - val_accuracy: 0.8924\n",
      "Epoch 21/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2918 - accuracy: 0.8916 - val_loss: 0.3026 - val_accuracy: 0.8927\n",
      "Epoch 22/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2836 - accuracy: 0.8955 - val_loss: 0.2920 - val_accuracy: 0.8933\n",
      "Epoch 23/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2675 - accuracy: 0.9011 - val_loss: 0.3070 - val_accuracy: 0.8907\n",
      "Epoch 24/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2659 - accuracy: 0.9020 - val_loss: 0.2958 - val_accuracy: 0.8943\n",
      "Epoch 25/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2618 - accuracy: 0.9024 - val_loss: 0.2900 - val_accuracy: 0.8989\n",
      "Epoch 26/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2545 - accuracy: 0.9063 - val_loss: 0.3032 - val_accuracy: 0.8935\n",
      "Epoch 27/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2531 - accuracy: 0.9069 - val_loss: 0.3065 - val_accuracy: 0.8934\n",
      "Epoch 28/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2441 - accuracy: 0.9091 - val_loss: 0.2922 - val_accuracy: 0.8998\n",
      "Epoch 29/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2400 - accuracy: 0.9107 - val_loss: 0.2879 - val_accuracy: 0.8993\n",
      "Epoch 30/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2295 - accuracy: 0.9153 - val_loss: 0.2971 - val_accuracy: 0.8983\n",
      "Epoch 31/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2277 - accuracy: 0.9154 - val_loss: 0.2899 - val_accuracy: 0.8996\n",
      "Epoch 32/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2222 - accuracy: 0.9177 - val_loss: 0.2951 - val_accuracy: 0.8998\n",
      "Epoch 33/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2187 - accuracy: 0.9198 - val_loss: 0.2975 - val_accuracy: 0.8971\n",
      "Epoch 34/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2134 - accuracy: 0.9225 - val_loss: 0.3031 - val_accuracy: 0.8994\n",
      "Epoch 35/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2126 - accuracy: 0.9203 - val_loss: 0.2908 - val_accuracy: 0.8977\n",
      "Epoch 36/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2083 - accuracy: 0.9237 - val_loss: 0.2950 - val_accuracy: 0.8998\n",
      "Epoch 37/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2033 - accuracy: 0.9246 - val_loss: 0.3020 - val_accuracy: 0.8973\n",
      "Epoch 38/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2016 - accuracy: 0.9244 - val_loss: 0.2919 - val_accuracy: 0.9018\n",
      "Epoch 39/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1952 - accuracy: 0.9277 - val_loss: 0.2914 - val_accuracy: 0.9033\n",
      "Epoch 40/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1933 - accuracy: 0.9301 - val_loss: 0.3098 - val_accuracy: 0.8990\n",
      "Epoch 41/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1891 - accuracy: 0.9299 - val_loss: 0.2945 - val_accuracy: 0.9000\n",
      "Epoch 42/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1852 - accuracy: 0.9324 - val_loss: 0.2951 - val_accuracy: 0.8986\n",
      "Epoch 43/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1777 - accuracy: 0.9347 - val_loss: 0.3087 - val_accuracy: 0.8993\n",
      "Epoch 44/100\n",
      "1260/1260 [==============================] - 12s 10ms/step - loss: 0.1785 - accuracy: 0.9348 - val_loss: 0.2971 - val_accuracy: 0.8979\n",
      "Epoch 45/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1750 - accuracy: 0.9366 - val_loss: 0.3011 - val_accuracy: 0.8993\n",
      "Epoch 46/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1758 - accuracy: 0.9378 - val_loss: 0.2984 - val_accuracy: 0.9019\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1684 - accuracy: 0.9392 - val_loss: 0.3072 - val_accuracy: 0.9014\n",
      "Epoch 48/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1687 - accuracy: 0.9396 - val_loss: 0.3167 - val_accuracy: 0.8993\n",
      "Epoch 49/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1624 - accuracy: 0.9419 - val_loss: 0.3050 - val_accuracy: 0.9018\n",
      "Epoch 50/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1652 - accuracy: 0.9409 - val_loss: 0.3142 - val_accuracy: 0.9019\n",
      "Epoch 51/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1573 - accuracy: 0.9432 - val_loss: 0.3008 - val_accuracy: 0.9047\n",
      "Epoch 52/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1555 - accuracy: 0.9439 - val_loss: 0.3120 - val_accuracy: 0.9057\n",
      "Epoch 53/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1559 - accuracy: 0.9429 - val_loss: 0.3106 - val_accuracy: 0.9027\n",
      "Epoch 54/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1512 - accuracy: 0.9447 - val_loss: 0.3071 - val_accuracy: 0.9041\n",
      "Epoch 55/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1491 - accuracy: 0.9471 - val_loss: 0.3143 - val_accuracy: 0.9037\n",
      "Epoch 56/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1446 - accuracy: 0.9497 - val_loss: 0.3181 - val_accuracy: 0.9051\n",
      "Epoch 57/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1442 - accuracy: 0.9490 - val_loss: 0.3259 - val_accuracy: 0.9019\n",
      "Epoch 58/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1469 - accuracy: 0.9479 - val_loss: 0.3328 - val_accuracy: 0.9018\n",
      "Epoch 59/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1435 - accuracy: 0.9512 - val_loss: 0.3177 - val_accuracy: 0.9054\n",
      "Epoch 60/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1398 - accuracy: 0.9513 - val_loss: 0.3219 - val_accuracy: 0.9046\n",
      "Epoch 61/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1363 - accuracy: 0.9519 - val_loss: 0.3240 - val_accuracy: 0.9039\n",
      "Epoch 62/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1361 - accuracy: 0.9519 - val_loss: 0.3453 - val_accuracy: 0.9011\n",
      "Epoch 63/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1335 - accuracy: 0.9530 - val_loss: 0.3263 - val_accuracy: 0.9026\n",
      "Epoch 64/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1294 - accuracy: 0.9541 - val_loss: 0.3292 - val_accuracy: 0.9033\n",
      "Epoch 65/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1315 - accuracy: 0.9538 - val_loss: 0.3240 - val_accuracy: 0.9021\n",
      "Epoch 66/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1251 - accuracy: 0.9565 - val_loss: 0.3422 - val_accuracy: 0.9014\n",
      "Epoch 67/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1248 - accuracy: 0.9563 - val_loss: 0.3350 - val_accuracy: 0.9044\n",
      "Epoch 68/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1228 - accuracy: 0.9570 - val_loss: 0.3430 - val_accuracy: 0.9044\n",
      "Epoch 69/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1201 - accuracy: 0.9574 - val_loss: 0.3379 - val_accuracy: 0.9029\n",
      "Epoch 70/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1186 - accuracy: 0.9582 - val_loss: 0.3392 - val_accuracy: 0.9042\n",
      "Epoch 71/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1188 - accuracy: 0.9582 - val_loss: 0.3342 - val_accuracy: 0.9054\n",
      "Epoch 72/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1188 - accuracy: 0.9590 - val_loss: 0.3507 - val_accuracy: 0.9022\n",
      "Epoch 73/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1153 - accuracy: 0.9600 - val_loss: 0.3633 - val_accuracy: 0.9007\n",
      "Epoch 74/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1172 - accuracy: 0.9591 - val_loss: 0.3468 - val_accuracy: 0.9023\n",
      "Epoch 75/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1135 - accuracy: 0.9606 - val_loss: 0.3674 - val_accuracy: 0.9027\n",
      "Epoch 76/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1122 - accuracy: 0.9611 - val_loss: 0.3496 - val_accuracy: 0.9020\n",
      "Epoch 77/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1121 - accuracy: 0.9614 - val_loss: 0.3425 - val_accuracy: 0.9051\n",
      "Epoch 78/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1089 - accuracy: 0.9616 - val_loss: 0.3565 - val_accuracy: 0.9044\n",
      "Epoch 79/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1090 - accuracy: 0.9634 - val_loss: 0.3573 - val_accuracy: 0.9038\n",
      "Epoch 80/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1047 - accuracy: 0.9639 - val_loss: 0.3542 - val_accuracy: 0.9029\n",
      "Epoch 81/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1019 - accuracy: 0.9641 - val_loss: 0.3575 - val_accuracy: 0.9039\n",
      "Epoch 82/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1048 - accuracy: 0.9654 - val_loss: 0.3531 - val_accuracy: 0.9052\n",
      "Epoch 83/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1046 - accuracy: 0.9644 - val_loss: 0.3742 - val_accuracy: 0.9012\n",
      "Epoch 84/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1034 - accuracy: 0.9647 - val_loss: 0.3585 - val_accuracy: 0.9043\n",
      "Epoch 85/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0983 - accuracy: 0.9663 - val_loss: 0.3667 - val_accuracy: 0.9035\n",
      "Epoch 86/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0996 - accuracy: 0.9657 - val_loss: 0.3690 - val_accuracy: 0.9017\n",
      "Epoch 87/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0985 - accuracy: 0.9662 - val_loss: 0.3743 - val_accuracy: 0.9032\n",
      "Epoch 88/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0957 - accuracy: 0.9673 - val_loss: 0.3750 - val_accuracy: 0.9037\n",
      "Epoch 89/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0951 - accuracy: 0.9673 - val_loss: 0.3612 - val_accuracy: 0.9050\n",
      "Epoch 90/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0948 - accuracy: 0.9677 - val_loss: 0.3776 - val_accuracy: 0.9057\n",
      "Epoch 91/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0932 - accuracy: 0.9692 - val_loss: 0.3743 - val_accuracy: 0.9046\n",
      "Epoch 92/100\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.0916 - accuracy: 0.9696 - val_loss: 0.3805 - val_accuracy: 0.9025\n",
      "Epoch 93/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0918 - accuracy: 0.9688 - val_loss: 0.4009 - val_accuracy: 0.9019\n",
      "Epoch 94/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0908 - accuracy: 0.9688 - val_loss: 0.3766 - val_accuracy: 0.9009\n",
      "Epoch 95/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0949 - accuracy: 0.9684 - val_loss: 0.3874 - val_accuracy: 0.9044\n",
      "Epoch 96/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0906 - accuracy: 0.9698 - val_loss: 0.3856 - val_accuracy: 0.9052\n",
      "Epoch 97/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0905 - accuracy: 0.9700 - val_loss: 0.3777 - val_accuracy: 0.9031\n",
      "Epoch 98/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0895 - accuracy: 0.9703 - val_loss: 0.3828 - val_accuracy: 0.9056\n",
      "Epoch 99/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0881 - accuracy: 0.9703 - val_loss: 0.3937 - val_accuracy: 0.9039\n",
      "Epoch 100/100\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.0890 - accuracy: 0.9705 - val_loss: 0.3783 - val_accuracy: 0.9047\n",
      "SGD with learning rate = 0.010000, epochs = 100, the accuracy is: 0.906659\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# print result\r\n",
    "new_cnn_res = pd.DataFrame(cnn_res)\r\n",
    "new_cnn_res"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   tech      lr  epoch  accuracy_score  precision_score  recall_score  \\\n",
       "0  Adam  0.0001     50        0.896023         0.898168      0.895615   \n",
       "1  Adam  0.0001    100        0.900230         0.900808      0.900084   \n",
       "2  Adam  0.0010     50        0.906104         0.907161      0.905342   \n",
       "3  Adam  0.0010    100        0.904119         0.905419      0.903803   \n",
       "4   SGD  0.0010     50        0.892690         0.892944      0.892368   \n",
       "5   SGD  0.0010    100        0.902849         0.903077      0.902451   \n",
       "6   SGD  0.0100     50        0.901024         0.901407      0.900569   \n",
       "7   SGD  0.0100    100        0.906659         0.907120      0.906179   \n",
       "\n",
       "   f1_score  \n",
       "0  0.894763  \n",
       "1  0.899572  \n",
       "2  0.905588  \n",
       "3  0.903309  \n",
       "4  0.891547  \n",
       "5  0.902198  \n",
       "6  0.900407  \n",
       "7  0.906228  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tech</th>\n",
       "      <th>lr</th>\n",
       "      <th>epoch</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>0.896023</td>\n",
       "      <td>0.898168</td>\n",
       "      <td>0.895615</td>\n",
       "      <td>0.894763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>0.900230</td>\n",
       "      <td>0.900808</td>\n",
       "      <td>0.900084</td>\n",
       "      <td>0.899572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>50</td>\n",
       "      <td>0.906104</td>\n",
       "      <td>0.907161</td>\n",
       "      <td>0.905342</td>\n",
       "      <td>0.905588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>100</td>\n",
       "      <td>0.904119</td>\n",
       "      <td>0.905419</td>\n",
       "      <td>0.903803</td>\n",
       "      <td>0.903309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>50</td>\n",
       "      <td>0.892690</td>\n",
       "      <td>0.892944</td>\n",
       "      <td>0.892368</td>\n",
       "      <td>0.891547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>100</td>\n",
       "      <td>0.902849</td>\n",
       "      <td>0.903077</td>\n",
       "      <td>0.902451</td>\n",
       "      <td>0.902198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.901024</td>\n",
       "      <td>0.901407</td>\n",
       "      <td>0.900569</td>\n",
       "      <td>0.900407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.906659</td>\n",
       "      <td>0.907120</td>\n",
       "      <td>0.906179</td>\n",
       "      <td>0.906228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# best model\r\n",
    "model = cnn_model()\r\n",
    "model.compile(loss=\"categorical_crossentropy\", \r\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.001), \r\n",
    "              metrics=[\"accuracy\"])\r\n",
    "model.fit(X_train_keras, y_train_keras, epochs=50,\r\n",
    "                   validation_split=0.2) # set 20% as validation seet\r\n",
    "\r\n",
    "y_prob = model.predict(X_test_keras)\r\n",
    "y_pred = np.argmax(y_prob,axis=1)\r\n",
    "ground_truth = np.argmax(y_test_keras,axis=1)\r\n",
    "\r\n",
    "print(\"MLP - accuracy score on test set: {:.3f}\".format(accuracy_score(ground_truth, y_pred)))\r\n",
    "print(\"MLP - precision score on test set: {:.3f}\".format(precision_score(ground_truth, y_pred, average='macro')))\r\n",
    "print(\"MLP - recall score on test set: {:.3f}\".format(recall_score(ground_truth, y_pred, average='macro')))\r\n",
    "print(\"MLP - f1 score on test set: {:.3f}\".format(f1_score(ground_truth, y_pred, average='macro')))\r\n",
    "print(\"MLP - confusion matrix on test set: \\n\", confusion_matrix(ground_truth, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 1.9023 - accuracy: 0.4972 - val_loss: 0.6358 - val_accuracy: 0.7909\n",
      "Epoch 2/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.7945 - accuracy: 0.7544 - val_loss: 0.5412 - val_accuracy: 0.8101\n",
      "Epoch 3/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.6625 - accuracy: 0.7823 - val_loss: 0.4719 - val_accuracy: 0.8285\n",
      "Epoch 4/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.5808 - accuracy: 0.8011 - val_loss: 0.4347 - val_accuracy: 0.8392\n",
      "Epoch 5/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.5416 - accuracy: 0.8148 - val_loss: 0.4065 - val_accuracy: 0.8515\n",
      "Epoch 6/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4949 - accuracy: 0.8278 - val_loss: 0.3693 - val_accuracy: 0.8633\n",
      "Epoch 7/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4691 - accuracy: 0.8344 - val_loss: 0.3660 - val_accuracy: 0.8633\n",
      "Epoch 8/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4384 - accuracy: 0.8468 - val_loss: 0.3635 - val_accuracy: 0.8654\n",
      "Epoch 9/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.4171 - accuracy: 0.8520 - val_loss: 0.3489 - val_accuracy: 0.8706\n",
      "Epoch 10/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3956 - accuracy: 0.8566 - val_loss: 0.3430 - val_accuracy: 0.8721\n",
      "Epoch 11/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3711 - accuracy: 0.8661 - val_loss: 0.3458 - val_accuracy: 0.8726\n",
      "Epoch 12/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3610 - accuracy: 0.8695 - val_loss: 0.3181 - val_accuracy: 0.8835\n",
      "Epoch 13/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.3420 - accuracy: 0.8757 - val_loss: 0.3157 - val_accuracy: 0.8857\n",
      "Epoch 14/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.3313 - accuracy: 0.8779 - val_loss: 0.3105 - val_accuracy: 0.8870\n",
      "Epoch 15/50\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.3196 - accuracy: 0.8834 - val_loss: 0.3012 - val_accuracy: 0.8901\n",
      "Epoch 16/50\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.3088 - accuracy: 0.8871 - val_loss: 0.3020 - val_accuracy: 0.8929\n",
      "Epoch 17/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2953 - accuracy: 0.8913 - val_loss: 0.3020 - val_accuracy: 0.8909\n",
      "Epoch 18/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2873 - accuracy: 0.8949 - val_loss: 0.3060 - val_accuracy: 0.8911\n",
      "Epoch 19/50\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.2771 - accuracy: 0.8988 - val_loss: 0.3195 - val_accuracy: 0.8879\n",
      "Epoch 20/50\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.2679 - accuracy: 0.9013 - val_loss: 0.3077 - val_accuracy: 0.8916\n",
      "Epoch 21/50\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.2634 - accuracy: 0.9031 - val_loss: 0.3185 - val_accuracy: 0.8890\n",
      "Epoch 22/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.2542 - accuracy: 0.9057 - val_loss: 0.2982 - val_accuracy: 0.8963\n",
      "Epoch 23/50\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.2450 - accuracy: 0.9103 - val_loss: 0.2842 - val_accuracy: 0.9026\n",
      "Epoch 24/50\n",
      "1260/1260 [==============================] - 14s 11ms/step - loss: 0.2401 - accuracy: 0.9125 - val_loss: 0.3001 - val_accuracy: 0.8986\n",
      "Epoch 25/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.2368 - accuracy: 0.9130 - val_loss: 0.2980 - val_accuracy: 0.8920\n",
      "Epoch 26/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2298 - accuracy: 0.9159 - val_loss: 0.3040 - val_accuracy: 0.8966\n",
      "Epoch 27/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.2299 - accuracy: 0.9166 - val_loss: 0.3086 - val_accuracy: 0.8974\n",
      "Epoch 28/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2157 - accuracy: 0.9215 - val_loss: 0.3254 - val_accuracy: 0.8942\n",
      "Epoch 29/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2143 - accuracy: 0.9234 - val_loss: 0.2966 - val_accuracy: 0.9063\n",
      "Epoch 30/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2068 - accuracy: 0.9250 - val_loss: 0.3027 - val_accuracy: 0.9000\n",
      "Epoch 31/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.2032 - accuracy: 0.9261 - val_loss: 0.2938 - val_accuracy: 0.9016\n",
      "Epoch 32/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1995 - accuracy: 0.9267 - val_loss: 0.2973 - val_accuracy: 0.9028\n",
      "Epoch 33/50\n",
      "1260/1260 [==============================] - 15s 12ms/step - loss: 0.1960 - accuracy: 0.9295 - val_loss: 0.3075 - val_accuracy: 0.8976\n",
      "Epoch 34/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1888 - accuracy: 0.9326 - val_loss: 0.3151 - val_accuracy: 0.9026\n",
      "Epoch 35/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1829 - accuracy: 0.9331 - val_loss: 0.3006 - val_accuracy: 0.9002\n",
      "Epoch 36/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1773 - accuracy: 0.9361 - val_loss: 0.3106 - val_accuracy: 0.9036\n",
      "Epoch 37/50\n",
      "1260/1260 [==============================] - 13s 11ms/step - loss: 0.1748 - accuracy: 0.9376 - val_loss: 0.3035 - val_accuracy: 0.9036\n",
      "Epoch 38/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1756 - accuracy: 0.9384 - val_loss: 0.3271 - val_accuracy: 0.8970\n",
      "Epoch 39/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1648 - accuracy: 0.9415 - val_loss: 0.3236 - val_accuracy: 0.9015\n",
      "Epoch 40/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1652 - accuracy: 0.9396 - val_loss: 0.3472 - val_accuracy: 0.8980\n",
      "Epoch 41/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1585 - accuracy: 0.9435 - val_loss: 0.3035 - val_accuracy: 0.9026\n",
      "Epoch 42/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1583 - accuracy: 0.9453 - val_loss: 0.3312 - val_accuracy: 0.9003\n",
      "Epoch 43/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1546 - accuracy: 0.9461 - val_loss: 0.3290 - val_accuracy: 0.9028\n",
      "Epoch 44/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1517 - accuracy: 0.9466 - val_loss: 0.3181 - val_accuracy: 0.9056\n",
      "Epoch 45/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1470 - accuracy: 0.9487 - val_loss: 0.3239 - val_accuracy: 0.9030\n",
      "Epoch 46/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1445 - accuracy: 0.9505 - val_loss: 0.3199 - val_accuracy: 0.9090\n",
      "Epoch 47/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1384 - accuracy: 0.9513 - val_loss: 0.3377 - val_accuracy: 0.9046\n",
      "Epoch 48/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1421 - accuracy: 0.9500 - val_loss: 0.3340 - val_accuracy: 0.9034\n",
      "Epoch 49/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1342 - accuracy: 0.9523 - val_loss: 0.3373 - val_accuracy: 0.9029\n",
      "Epoch 50/50\n",
      "1260/1260 [==============================] - 13s 10ms/step - loss: 0.1379 - accuracy: 0.9521 - val_loss: 0.3202 - val_accuracy: 0.9051\n",
      "MLP - accuracy score on test set: 0.904\n",
      "MLP - precision score on test set: 0.905\n",
      "MLP - recall score on test set: 0.903\n",
      "MLP - f1 score on test set: 0.903\n",
      "MLP - confusion matrix on test set: \n",
      " [[164   0   0 ...   0   0   0]\n",
      " [  0 173   0 ...   0   0   0]\n",
      " [  0   0 211 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ... 162   0   0]\n",
      " [  0   0   0 ...   0 191   0]\n",
      " [  0   0   0 ...   0   0 142]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# save model\r\n",
    "# model.save('best_algorithm.h5')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# pd.DataFrame(history.history).plot(figsize=(8,5))\r\n",
    "# plt.grid(True)\r\n",
    "# plt.gca().set_ylim(0,1)\r\n",
    "# plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Computer details <a id='4'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Hardware\n",
    "    - OS System: Windows 10 64-bit operating system\n",
    "    - CPU: Intel(R) Core(TM) i7-9700KF\n",
    "    - GPU: NVIDIA GeForce RTX 2070\n",
    "    - RAM: 16.0 GB\n",
    "    \n",
    "- Software\n",
    "    - Python 3.8.3\n",
    "    - notebook 6.0.3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Easy to use <a id='5'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import sklearn\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import layers\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import os\r\n",
    "import time\r\n",
    "import cv2\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from tensorflow.keras.models import Sequential, load_model\r\n",
    "from tensorflow.keras import layers\r\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
    "\r\n",
    "\r\n",
    "%matplotlib inline\r\n",
    "import matplotlib as mpl\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "# read image and resize image\r\n",
    "def img_resizing(i_path):\r\n",
    "    img = cv2.imread(i_path, cv2.IMREAD_GRAYSCALE)\r\n",
    "    data = cv2.resize(img, (28, 28), interpolation=cv2.INTER_CUBIC)\r\n",
    "    return data\r\n",
    "\r\n",
    "# converting the images into sets of data\r\n",
    "data = []\r\n",
    "label = []\r\n",
    "\r\n",
    "data_path = 'English/Fnt/'\r\n",
    "for i in range(62):\r\n",
    "    path = data_path + 'Sample%03d/' % (i+1)\r\n",
    "    for filename in os.listdir(path):\r\n",
    "        img = img_resizing(path+filename)\r\n",
    "        tmp = img.reshape([1, img.shape[0]*img.shape[1]])\r\n",
    "        data.append(np.asarray(tmp, dtype = \"int32\"))\r\n",
    "        label.append(i)\r\n",
    "\r\n",
    "print(\"############### Data Loaded ###############\")\r\n",
    "\r\n",
    "# convert data type\r\n",
    "data_array = np.asarray(data)\r\n",
    "new_data = np.asarray(data_array).reshape(data_array.shape[0],-1)\r\n",
    "new_label = np.asarray(label)\r\n",
    "\r\n",
    "# set train/test data\r\n",
    "X = new_data\r\n",
    "y = new_label\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=500)\r\n",
    "\r\n",
    "# standardize data\r\n",
    "scaler = StandardScaler()#creating an object\r\n",
    "scaler.fit(X_train)#calculate min and max value of the training data\r\n",
    "X_train_std = scaler.transform(X_train) #apply normalisation to the training set\r\n",
    "X_test_std = scaler.transform(X_test) #apply normalization to the test set\r\n",
    "\r\n",
    "\r\n",
    "X_train_keras = X_train_std.reshape(X_train_std.shape[0], 28, 28)\r\n",
    "X_test_keras = X_test_std.reshape(X_test_std.shape[0], 28, 28)\r\n",
    "\r\n",
    "X_train_keras = np.expand_dims(X_train_keras, axis=3)\r\n",
    "X_test_keras = np.expand_dims(X_test_keras, axis=3)\r\n",
    "\r\n",
    "y_train_keras = keras.utils.to_categorical(y_train, 62).astype('int32')\r\n",
    "y_test_keras = keras.utils.to_categorical(y_test, 62).astype('int32')\r\n",
    "\r\n",
    "# load model\r\n",
    "print(\"############### Model Path Input ###############\")\r\n",
    "\r\n",
    "model_path = 'best_algorithm.h5'\r\n",
    "model = load_model(model_path)\r\n",
    "print(\"############### model loaded ###############\")\r\n",
    "\r\n",
    "# evaluate model\r\n",
    "print(\"############### Model Evaluation ###############\")\r\n",
    "# Check pretrained model performance on test set\r\n",
    "y_prob = model.predict(X_test_keras)\r\n",
    "y_pred = np.argmax(y_prob,axis=1)\r\n",
    "ground_truth = np.argmax(y_test_keras,axis=1)\r\n",
    "\r\n",
    "print(\"CNN - accuracy score on test set: {:.3f}\".format(accuracy_score(ground_truth, y_pred)))\r\n",
    "print(\"CNN - precision score on test set: {:.3f}\".format(precision_score(ground_truth, y_pred, average='macro')))\r\n",
    "print(\"CNN - recall score on test set: {:.3f}\".format(recall_score(ground_truth, y_pred, average='macro')))\r\n",
    "print(\"CNN - f1 score on test set: {:.3f}\".format(f1_score(ground_truth, y_pred, average='macro')))\r\n",
    "print(\"CNN - confusion matrix on test set: \\n\", confusion_matrix(ground_truth, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "############### Data Path Input ###############\n",
      "Default path is: 'English/Fnt/'\n",
      "*** DO NOT ENTER anything if using the above path ***\n",
      "Windows Path Example: C:/Users/xxx/Downloads/5318/English/Fnt/\n",
      "MacOS Path Example: /Users/xxx/Downloads/5318/English/Fnt/\n",
      "Please input the data path (before Samplexxx folders) end with '/'\n",
      "############### Data Loaded ###############\n",
      "############### Model Path Input ###############\n",
      "############### model loaded ###############\n",
      "############### Model Evaluation ###############\n",
      "CNN - accuracy score on test set: 0.904\n",
      "CNN - precision score on test set: 0.905\n",
      "CNN - recall score on test set: 0.903\n",
      "CNN - f1 score on test set: 0.903\n",
      "CNN - confusion matrix on test set: \n",
      " [[164   0   0 ...   0   0   0]\n",
      " [  0 173   0 ...   0   0   0]\n",
      " [  0   0 211 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ... 162   0   0]\n",
      " [  0   0   0 ...   0 191   0]\n",
      " [  0   0   0 ...   0   0 142]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}