{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# COMP5318 - Machine Learning and Data Mining: Assignment 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CONTENTS"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-  [0. Set up](#0)\n",
    "-  [1. Obtain data](#1)\n",
    "    -  [1.1. Data info](#1.1)\n",
    "    -  [1.2. Load data](#1.2)\n",
    "    -  [1.3. Set train/test data](#1.3)\n",
    "-  [2. Pre-process data](#2)\n",
    "    -  [2.1. Standardized data](#2.1)\n",
    "    -  [2.2. PCA](#2.2)\n",
    "-  [3. Algorithms](#3)\n",
    "    -  [3.1. Nearest Neighbor](#3.1)\n",
    "    -  [3.2. MLP](#3.2)\n",
    "    -  [3.3. CNN](#3.3)\n",
    "-  [4. Classifier comparisons](#4)\n",
    "-  [5. Computer details](#5)\n",
    "-  [6. Easy to use](#6)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Set up <a id='0'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sklearn\r\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "from keras import layers\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import os\r\n",
    "import time\r\n",
    "import cv2\r\n",
    "\r\n",
    "%matplotlib inline\r\n",
    "import matplotlib as mpl\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "# used to compare result of all models\r\n",
    "all_res = {'algorithms': ['knn', 'MLP', 'cnn'],\r\n",
    "           'accuracy_score':[],\r\n",
    "           'accuracy_score':[],\r\n",
    "           'precision_score':[],\r\n",
    "           'recall_score':[], \r\n",
    "           'f1_score':[]}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Obtain data <a id='1'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1. Data info <a id='1.1'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is a \"Fnt\" folder including 62 main folders, each folder including 1016 png files as input data (which downloaded from http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/):\n",
    "\n",
    "    EnglishFnt.tgz (51.1 MB): characters from computer fonts with 4 variations (combinations of italic, bold and normal)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2. Load data <a id='1.2'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# read image and resize image\r\n",
    "def img_resizing(i_path):\r\n",
    "    img = cv2.imread(i_path, cv2.IMREAD_GRAYSCALE)\r\n",
    "    data = cv2.resize(img, (28, 28), interpolation=cv2.INTER_CUBIC)\r\n",
    "    return data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# converting the images into sets of data\r\n",
    "data = []\r\n",
    "label = []\r\n",
    "\r\n",
    "for i in range(62):\r\n",
    "    path = 'English/Fnt/Sample%03d/' % (i+1)\r\n",
    "    for filename in os.listdir(path):\r\n",
    "        img = img_resizing(path+filename)\r\n",
    "        tmp = img.reshape([1, img.shape[0]*img.shape[1]])\r\n",
    "        data.append(np.asarray(tmp, dtype = \"int32\"))\r\n",
    "        label.append(i)\r\n",
    "\r\n",
    "\r\n",
    "data_img = []\r\n",
    "label_img = []\r\n",
    "\r\n",
    "for i in range(62):\r\n",
    "    path = 'English/Img/GoodImg/Bmp/Sample%03d/' % (i+1)\r\n",
    "    for filename in os.listdir(path):\r\n",
    "        img = img_resizing(path+filename)\r\n",
    "        tmp = img.reshape([1, img.shape[0]*img.shape[1]])\r\n",
    "        data_img.append(np.asarray(tmp, dtype = \"int32\"))\r\n",
    "        label_img.append(i)\r\n",
    "        \r\n",
    "for i in range(62):\r\n",
    "    path = 'English/Img/BadImag/Bmp/Sample%03d/' % (i+1)\r\n",
    "    for filename in os.listdir(path):\r\n",
    "        img = img_resizing(path+filename)\r\n",
    "        tmp = img.reshape([1, img.shape[0]*img.shape[1]])\r\n",
    "        data_img.append(np.asarray(tmp, dtype = \"int32\"))\r\n",
    "        label_img.append(i)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# convert data type\r\n",
    "data_array = np.asarray(data)\r\n",
    "new_data = np.asarray(data_array).reshape(data_array.shape[0],-1)\r\n",
    "print(\"The data shape is: \", new_data.shape)\r\n",
    "new_label = np.asarray(label)\r\n",
    "print(\"The label shape is: \", new_label.shape)\r\n",
    "\r\n",
    "# this is for img data, check the data shape\r\n",
    "data_array_img = np.asarray(data_img)\r\n",
    "new_data_img = data_array_img.reshape(data_array_img.shape[0],-1)\r\n",
    "print(\"The IMG data shape is: \", new_data_img.shape)\r\n",
    "new_label_img = np.asarray(label_img)\r\n",
    "print(\"The IMG label shape is: \", new_label_img.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The data shape is:  (62992, 784)\n",
      "The label shape is:  (62992,)\n",
      "The IMG data shape is:  (12503, 784)\n",
      "The IMG label shape is:  (12503,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3. Set train / test data <a id='1.3'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "X = new_data\r\n",
    "y = new_label\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=500)\r\n",
    "\r\n",
    "# print train and test data set shape\r\n",
    "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\r\n",
    "print(\"X_test shape:\", X_test.shape, \"y_test shape:\", y_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_train shape: (50393, 784) y_train shape: (50393,)\n",
      "X_test shape: (12599, 784) y_test shape: (12599,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Pre-process data <a id='2'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1. Standardized data <a id='2.1'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from sklearn.preprocessing import StandardScaler\r\n",
    "scaler = StandardScaler()#creating an object\r\n",
    "scaler.fit(X_train)\r\n",
    "X_train_std = scaler.transform(X_train)\r\n",
    "X_test_std = scaler.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2. PCA <a id='2.2'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from sklearn.decomposition import PCA\r\n",
    "pca=PCA(n_components=0.9)\r\n",
    "X_train_reduced = pca.fit_transform(X_train_std)\r\n",
    "X_test_reduced = pca.transform(X_test_std)\r\n",
    "print(\"Original shape of training data: {}\".format(str(X_train_std.shape)))\r\n",
    "print(\"Reduced shape of training data: {}\".format(str(X_train_reduced.shape)))\r\n",
    "print(\"Original shape of testing data: {}\".format(str(X_test_std.shape)))\r\n",
    "print(\"Reduced shape of testing data: {}\".format(str(X_test_reduced.shape)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original shape of training data: (50393, 784)\n",
      "Reduced shape of training data: (50393, 162)\n",
      "Original shape of testing data: (12599, 784)\n",
      "Reduced shape of testing data: (12599, 162)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Algorithms<a id='3'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1. Nearest Neighbor<a id='3.1'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# No Parameter Tuning\r\n",
    "knn_start = time.time()\r\n",
    "\r\n",
    "knn = KNeighborsClassifier(n_neighbors=1,p=1)\r\n",
    "knn.fit(X_train_reduced, y_train)\r\n",
    "y_pred = knn.predict(X_test_reduced)\r\n",
    "print(\"Knn - accuracy on test set: {:.3f}\".format(accuracy_score(y_test, y_pred)))\r\n",
    "\r\n",
    "print('################ time used ##############')\r\n",
    "knn_end = time.time()\r\n",
    "print(\"knn no parameter tuning time used: \", knn_end - knn_start)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Knn - accuracy on test set: 0.872\n",
      "################ time used ##############\n",
      "knn no parameter tuning time used:  270.1841676235199\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Parameter Tuning\r\n",
    "pknn_start = time.time()\r\n",
    "\r\n",
    "# set parameters that we want to tunning\r\n",
    "param_grid = {'n_neighbors': [1, 5, 10, 15], 'p':[1,2]}\r\n",
    "print(\"Parameter grid:\\n{}\".format(param_grid))\r\n",
    "\r\n",
    "# use GridSearchCV with cv=10\r\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=10)\r\n",
    "\r\n",
    "grid_search.fit(X_train_reduced, y_train)\r\n",
    "\r\n",
    "print(\"Test set score: {:.2f}\".format(grid_search.score(X_test_reduced, y_test)))\r\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\r\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\r\n",
    "print(\"Best estimator:\\n{}\".format(grid_search.best_estimator_))\r\n",
    "\r\n",
    "print('################ time used ##############')\r\n",
    "pknn_end = time.time()\r\n",
    "print(\"knn with parameter tuning time used: \", pknn_end - pknn_start)\r\n",
    "y_pred = grid_search.predict(X_test_reduced)\r\n",
    "\r\n",
    "print(\"Knn - accuracy score on test set: {:.3f}\".format(accuracy_score(y_test, y_pred)))\r\n",
    "print(\"Knn - precision score on test set: {:.3f}\".format(precision_score(y_test, y_pred,average='macro')))\r\n",
    "print(\"Knn - recall score on test set: {:.3f}\".format(recall_score(y_test, y_pred,average='macro')))\r\n",
    "print(\"Knn - f1 score on test set: {:.3f}\".format(f1_score(y_test, y_pred,average='macro')))\r\n",
    "print(\"Knn - confusion matrix on test set: \\n\",confusion_matrix(y_test, y_pred))\r\n",
    "all_res['accuracy_score'].append(accuracy_score(y_test, y_pred))\r\n",
    "all_res['precision_score'].append(precision_score(y_test, y_pred,average='macro'))\r\n",
    "all_res['recall_score'].append(recall_score(y_test, y_pred,average='macro'))\r\n",
    "all_res['f1_score'].append(f1_score(y_test, y_pred,average='macro'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter grid:\n",
      "{'n_neighbors': [1, 5, 10, 15], 'p': [1, 2]}\n",
      "Test set score: 0.87\n",
      "Best parameters: {'n_neighbors': 1, 'p': 1}\n",
      "Best cross-validation score: 0.87\n",
      "Best estimator:\n",
      "KNeighborsClassifier(n_neighbors=1, p=1)\n",
      "################ time used ##############\n",
      "knn with parameter tuning time used:  1852.4000704288483\n",
      "Knn - accuracy score on test set: 0.872\n",
      "Knn - precision score on test set: 0.873\n",
      "Knn - recall score on test set: 0.872\n",
      "Knn - f1 score on test set: 0.872\n",
      "Knn - confusion matrix on test set: \n",
      " [[154   0   0 ...   0   0   0]\n",
      " [  0 172   0 ...   0   0   0]\n",
      " [  0   0 211 ...   0   0   0]\n",
      " ...\n",
      " [  0   1   0 ... 153   0   1]\n",
      " [  0   0   0 ...   0 183   0]\n",
      " [  0   0   0 ...   0   0 155]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2. MLP<a id='3.2'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\r\n",
    "from tensorflow.keras import layers\r\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# we set two functions to compare the difference between mlp with dropout and without dropout\r\n",
    "def mlp():\r\n",
    "    # Clear any existing TensorFlow graph from memory and set random seeds.\r\n",
    "    keras.backend.clear_session()\r\n",
    "    np.random.seed(42)\r\n",
    "    tf.random.set_seed(42)\r\n",
    "\r\n",
    "    # set model\r\n",
    "    model= keras.models.Sequential([\r\n",
    "        keras.layers.Flatten(input_shape=X_train_std.shape[1:]),\r\n",
    "        keras.layers.Dense(400, activation=\"relu\"),\r\n",
    "        keras.layers.Dense(200, activation=\"relu\"),\r\n",
    "        keras.layers.Dense(100, activation=\"relu\"),\r\n",
    "        keras.layers.Dense(62, activation=\"softmax\")\r\n",
    "    ])\r\n",
    "\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# we would like to try different learning rate and epochs\r\n",
    "optimizer = ['Adam', 'SGD']\r\n",
    "\r\n",
    "lr_adam = [0.0001, 0.001]\r\n",
    "epoch_adam = [50, 150]\r\n",
    "\r\n",
    "lr_sgd = [0.001, 0.01]\r\n",
    "epoch_sgd = [50, 150]\r\n",
    "\r\n",
    "\r\n",
    "count = 1\r\n",
    "mlp_res = {'tech': [], 'lr':[], 'epoch':[], 'accuracy_score':[], 'precision_score':[], 'recall_score':[], 'f1_score':[]}\r\n",
    "for i in lr_adam:\r\n",
    "    for j in epoch_adam:\r\n",
    "        print(\"Adam: %d / %d ###################################################\" % (count, len(lr_adam)*len(epoch_adam)))\r\n",
    "        count += 1\r\n",
    "        model = mlp()\r\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\", \r\n",
    "                      optimizer=keras.optimizers.Adam(learning_rate=i), \r\n",
    "                      metrics=[\"accuracy\"])\r\n",
    "        model.fit(X_train_std, y_train, epochs=j,\r\n",
    "                           validation_split=0.2) # set 20% as validation seet\r\n",
    "        y_prob = model.predict(X_test_std)\r\n",
    "        y_pred = np.argmax(y_prob,axis=1)\r\n",
    "        mlp_res['tech'].append('Adam')\r\n",
    "        mlp_res['lr'].append(i)\r\n",
    "        mlp_res['epoch'].append(j)\r\n",
    "        mlp_res['accuracy_score'].append(accuracy_score(y_test, y_pred))\r\n",
    "        mlp_res['precision_score'].append(precision_score(y_test, y_pred, average='macro'))\r\n",
    "        mlp_res['recall_score'].append(recall_score(y_test, y_pred, average='macro'))\r\n",
    "        mlp_res['f1_score'].append(f1_score(y_test, y_pred, average='macro'))\r\n",
    "\r\n",
    "\r\n",
    "for i in lr_sgd:\r\n",
    "    for j in epoch_sgd:\r\n",
    "        print(\" SGD: %d / %d ###################################################\" % (count, len(lr_sgd)*len(epoch_sgd)))\r\n",
    "        count += 1\r\n",
    "        model = mlp()\r\n",
    "        decay_rate = i / j\r\n",
    "        sgd = keras.optimizers.SGD(learning_rate=i, momentum=0.8, decay=decay_rate, nesterov=False)\r\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\", \r\n",
    "                      optimizer=sgd, \r\n",
    "                      metrics=[\"accuracy\"])\r\n",
    "        model.fit(X_train_std, y_train, epochs=j,\r\n",
    "                           validation_split=0.2) # set 20% as validation seet\r\n",
    "        y_prob = model.predict(X_test_std)\r\n",
    "        y_pred = np.argmax(y_prob,axis=1)\r\n",
    "        mlp_res['tech'].append('SGD')\r\n",
    "        mlp_res['lr'].append(i)\r\n",
    "        mlp_res['epoch'].append(j)\r\n",
    "        mlp_res['accuracy_score'].append(accuracy_score(y_test, y_pred))\r\n",
    "        mlp_res['precision_score'].append(precision_score(y_test, y_pred, average='macro'))\r\n",
    "        mlp_res['recall_score'].append(recall_score(y_test, y_pred, average='macro'))\r\n",
    "        mlp_res['f1_score'].append(f1_score(y_test, y_pred, average='macro'))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Adam: 1 / 4 ###################################################\n",
      "Epoch 1/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 1.6905 - accuracy: 0.6046 - val_loss: 0.9288 - val_accuracy: 0.7539\n",
      "Epoch 2/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.7719 - accuracy: 0.7879 - val_loss: 0.7433 - val_accuracy: 0.7928\n",
      "Epoch 3/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.6199 - accuracy: 0.8219 - val_loss: 0.6605 - val_accuracy: 0.8146\n",
      "Epoch 4/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.5305 - accuracy: 0.8432 - val_loss: 0.6042 - val_accuracy: 0.8208\n",
      "Epoch 5/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.4632 - accuracy: 0.8604 - val_loss: 0.5798 - val_accuracy: 0.8259\n",
      "Epoch 6/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.4106 - accuracy: 0.8747 - val_loss: 0.5554 - val_accuracy: 0.8330\n",
      "Epoch 7/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3658 - accuracy: 0.8866 - val_loss: 0.5330 - val_accuracy: 0.8406\n",
      "Epoch 8/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3283 - accuracy: 0.8976 - val_loss: 0.5156 - val_accuracy: 0.8432\n",
      "Epoch 9/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2963 - accuracy: 0.9064 - val_loss: 0.5232 - val_accuracy: 0.8407\n",
      "Epoch 10/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2680 - accuracy: 0.9153 - val_loss: 0.5174 - val_accuracy: 0.8447\n",
      "Epoch 11/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2452 - accuracy: 0.9221 - val_loss: 0.5091 - val_accuracy: 0.8434\n",
      "Epoch 12/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2250 - accuracy: 0.9269 - val_loss: 0.4983 - val_accuracy: 0.8484\n",
      "Epoch 13/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2062 - accuracy: 0.9329 - val_loss: 0.4904 - val_accuracy: 0.8503\n",
      "Epoch 14/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1917 - accuracy: 0.9372 - val_loss: 0.4860 - val_accuracy: 0.8572\n",
      "Epoch 15/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1776 - accuracy: 0.9410 - val_loss: 0.4952 - val_accuracy: 0.8520\n",
      "Epoch 16/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1638 - accuracy: 0.9457 - val_loss: 0.4937 - val_accuracy: 0.8574\n",
      "Epoch 17/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1533 - accuracy: 0.9489 - val_loss: 0.5000 - val_accuracy: 0.8563\n",
      "Epoch 18/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1447 - accuracy: 0.9524 - val_loss: 0.5055 - val_accuracy: 0.8564\n",
      "Epoch 19/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1362 - accuracy: 0.9538 - val_loss: 0.5106 - val_accuracy: 0.8532\n",
      "Epoch 20/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1286 - accuracy: 0.9568 - val_loss: 0.5124 - val_accuracy: 0.8544\n",
      "Epoch 21/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1240 - accuracy: 0.9574 - val_loss: 0.5222 - val_accuracy: 0.8516\n",
      "Epoch 22/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1168 - accuracy: 0.9601 - val_loss: 0.5359 - val_accuracy: 0.8568\n",
      "Epoch 23/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1120 - accuracy: 0.9621 - val_loss: 0.5370 - val_accuracy: 0.8556\n",
      "Epoch 24/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1083 - accuracy: 0.9632 - val_loss: 0.5420 - val_accuracy: 0.8553\n",
      "Epoch 25/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1048 - accuracy: 0.9647 - val_loss: 0.5510 - val_accuracy: 0.8601\n",
      "Epoch 26/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0994 - accuracy: 0.9655 - val_loss: 0.5573 - val_accuracy: 0.8563\n",
      "Epoch 27/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0986 - accuracy: 0.9652 - val_loss: 0.5906 - val_accuracy: 0.8549\n",
      "Epoch 28/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0945 - accuracy: 0.9676 - val_loss: 0.5730 - val_accuracy: 0.8575\n",
      "Epoch 29/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0913 - accuracy: 0.9678 - val_loss: 0.5846 - val_accuracy: 0.8573\n",
      "Epoch 30/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0890 - accuracy: 0.9695 - val_loss: 0.6018 - val_accuracy: 0.8559\n",
      "Epoch 31/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0918 - accuracy: 0.9692 - val_loss: 0.6807 - val_accuracy: 0.8573\n",
      "Epoch 32/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0834 - accuracy: 0.9722 - val_loss: 0.6505 - val_accuracy: 0.8599\n",
      "Epoch 33/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0808 - accuracy: 0.9718 - val_loss: 0.6570 - val_accuracy: 0.8587\n",
      "Epoch 34/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0789 - accuracy: 0.9735 - val_loss: 0.6630 - val_accuracy: 0.8614\n",
      "Epoch 35/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0789 - accuracy: 0.9726 - val_loss: 0.6714 - val_accuracy: 0.8602\n",
      "Epoch 36/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0768 - accuracy: 0.9736 - val_loss: 0.6798 - val_accuracy: 0.8615\n",
      "Epoch 37/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0799 - accuracy: 0.9733 - val_loss: 0.6868 - val_accuracy: 0.8593\n",
      "Epoch 38/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0740 - accuracy: 0.9744 - val_loss: 0.6886 - val_accuracy: 0.8585\n",
      "Epoch 39/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0712 - accuracy: 0.9756 - val_loss: 0.6899 - val_accuracy: 0.8605\n",
      "Epoch 40/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0716 - accuracy: 0.9753 - val_loss: 0.6897 - val_accuracy: 0.8563\n",
      "Epoch 41/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0703 - accuracy: 0.9758 - val_loss: 0.6973 - val_accuracy: 0.8604\n",
      "Epoch 42/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0686 - accuracy: 0.9762 - val_loss: 0.7145 - val_accuracy: 0.8593\n",
      "Epoch 43/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0673 - accuracy: 0.9767 - val_loss: 0.7296 - val_accuracy: 0.8568\n",
      "Epoch 44/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0667 - accuracy: 0.9769 - val_loss: 0.7275 - val_accuracy: 0.8584\n",
      "Epoch 45/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0655 - accuracy: 0.9775 - val_loss: 0.7740 - val_accuracy: 0.8574\n",
      "Epoch 46/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0714 - accuracy: 0.9773 - val_loss: 0.7769 - val_accuracy: 0.8582\n",
      "Epoch 47/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0658 - accuracy: 0.9789 - val_loss: 0.7538 - val_accuracy: 0.8567\n",
      "Epoch 48/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0601 - accuracy: 0.9787 - val_loss: 0.7375 - val_accuracy: 0.8588\n",
      "Epoch 49/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0612 - accuracy: 0.9783 - val_loss: 0.7863 - val_accuracy: 0.8566\n",
      "Epoch 50/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0614 - accuracy: 0.9789 - val_loss: 0.7537 - val_accuracy: 0.8543\n",
      "Adam: 2 / 4 ###################################################\n",
      "Epoch 1/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 1.6905 - accuracy: 0.6046 - val_loss: 0.9288 - val_accuracy: 0.7539\n",
      "Epoch 2/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.7719 - accuracy: 0.7879 - val_loss: 0.7433 - val_accuracy: 0.7928\n",
      "Epoch 3/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.6199 - accuracy: 0.8219 - val_loss: 0.6605 - val_accuracy: 0.8146\n",
      "Epoch 4/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.5305 - accuracy: 0.8432 - val_loss: 0.6042 - val_accuracy: 0.8208\n",
      "Epoch 5/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.4632 - accuracy: 0.8604 - val_loss: 0.5798 - val_accuracy: 0.8259\n",
      "Epoch 6/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.4106 - accuracy: 0.8747 - val_loss: 0.5554 - val_accuracy: 0.8330\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 7/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3658 - accuracy: 0.8866 - val_loss: 0.5330 - val_accuracy: 0.8406\n",
      "Epoch 8/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3283 - accuracy: 0.8976 - val_loss: 0.5156 - val_accuracy: 0.8432\n",
      "Epoch 9/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2963 - accuracy: 0.9064 - val_loss: 0.5232 - val_accuracy: 0.8407\n",
      "Epoch 10/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2680 - accuracy: 0.9153 - val_loss: 0.5174 - val_accuracy: 0.8447\n",
      "Epoch 11/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2452 - accuracy: 0.9221 - val_loss: 0.5091 - val_accuracy: 0.8434\n",
      "Epoch 12/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2250 - accuracy: 0.9269 - val_loss: 0.4983 - val_accuracy: 0.8484\n",
      "Epoch 13/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2062 - accuracy: 0.9329 - val_loss: 0.4904 - val_accuracy: 0.8503\n",
      "Epoch 14/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1917 - accuracy: 0.9372 - val_loss: 0.4860 - val_accuracy: 0.8572\n",
      "Epoch 15/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1776 - accuracy: 0.9410 - val_loss: 0.4952 - val_accuracy: 0.8520\n",
      "Epoch 16/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1638 - accuracy: 0.9457 - val_loss: 0.4937 - val_accuracy: 0.8574\n",
      "Epoch 17/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1533 - accuracy: 0.9489 - val_loss: 0.5000 - val_accuracy: 0.8563\n",
      "Epoch 18/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1447 - accuracy: 0.9524 - val_loss: 0.5055 - val_accuracy: 0.8564\n",
      "Epoch 19/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1362 - accuracy: 0.9538 - val_loss: 0.5106 - val_accuracy: 0.8532\n",
      "Epoch 20/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1286 - accuracy: 0.9568 - val_loss: 0.5124 - val_accuracy: 0.8544\n",
      "Epoch 21/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1240 - accuracy: 0.9574 - val_loss: 0.5222 - val_accuracy: 0.8516\n",
      "Epoch 22/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1168 - accuracy: 0.9601 - val_loss: 0.5359 - val_accuracy: 0.8568\n",
      "Epoch 23/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1120 - accuracy: 0.9621 - val_loss: 0.5370 - val_accuracy: 0.8556\n",
      "Epoch 24/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1083 - accuracy: 0.9632 - val_loss: 0.5420 - val_accuracy: 0.8553\n",
      "Epoch 25/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1048 - accuracy: 0.9647 - val_loss: 0.5510 - val_accuracy: 0.8601\n",
      "Epoch 26/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0994 - accuracy: 0.9655 - val_loss: 0.5573 - val_accuracy: 0.8563\n",
      "Epoch 27/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0986 - accuracy: 0.9652 - val_loss: 0.5906 - val_accuracy: 0.8549\n",
      "Epoch 28/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0945 - accuracy: 0.9676 - val_loss: 0.5730 - val_accuracy: 0.8575\n",
      "Epoch 29/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0913 - accuracy: 0.9678 - val_loss: 0.5846 - val_accuracy: 0.8573\n",
      "Epoch 30/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0890 - accuracy: 0.9695 - val_loss: 0.6018 - val_accuracy: 0.8559\n",
      "Epoch 31/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0918 - accuracy: 0.9692 - val_loss: 0.6807 - val_accuracy: 0.8573\n",
      "Epoch 32/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0834 - accuracy: 0.9722 - val_loss: 0.6505 - val_accuracy: 0.8599\n",
      "Epoch 33/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0808 - accuracy: 0.9718 - val_loss: 0.6570 - val_accuracy: 0.8587\n",
      "Epoch 34/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0789 - accuracy: 0.9735 - val_loss: 0.6630 - val_accuracy: 0.8614\n",
      "Epoch 35/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0789 - accuracy: 0.9726 - val_loss: 0.6714 - val_accuracy: 0.8602\n",
      "Epoch 36/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0768 - accuracy: 0.9736 - val_loss: 0.6798 - val_accuracy: 0.8615\n",
      "Epoch 37/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0799 - accuracy: 0.9733 - val_loss: 0.6868 - val_accuracy: 0.8593\n",
      "Epoch 38/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0740 - accuracy: 0.9744 - val_loss: 0.6886 - val_accuracy: 0.8585\n",
      "Epoch 39/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0712 - accuracy: 0.9756 - val_loss: 0.6899 - val_accuracy: 0.8605\n",
      "Epoch 40/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0716 - accuracy: 0.9753 - val_loss: 0.6897 - val_accuracy: 0.8563\n",
      "Epoch 41/150\n",
      "1260/1260 [==============================] - 3s 2ms/step - loss: 0.0703 - accuracy: 0.9758 - val_loss: 0.6973 - val_accuracy: 0.8604\n",
      "Epoch 42/150\n",
      "1260/1260 [==============================] - 3s 2ms/step - loss: 0.0686 - accuracy: 0.9762 - val_loss: 0.7145 - val_accuracy: 0.8593\n",
      "Epoch 43/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0673 - accuracy: 0.9767 - val_loss: 0.7296 - val_accuracy: 0.8568\n",
      "Epoch 44/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0667 - accuracy: 0.9769 - val_loss: 0.7275 - val_accuracy: 0.8584\n",
      "Epoch 45/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0655 - accuracy: 0.9775 - val_loss: 0.7740 - val_accuracy: 0.8574\n",
      "Epoch 46/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0714 - accuracy: 0.9773 - val_loss: 0.7769 - val_accuracy: 0.8582\n",
      "Epoch 47/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0658 - accuracy: 0.9789 - val_loss: 0.7538 - val_accuracy: 0.8567\n",
      "Epoch 48/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0601 - accuracy: 0.9787 - val_loss: 0.7375 - val_accuracy: 0.8588\n",
      "Epoch 49/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0612 - accuracy: 0.9783 - val_loss: 0.7863 - val_accuracy: 0.8566\n",
      "Epoch 50/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0614 - accuracy: 0.9789 - val_loss: 0.7537 - val_accuracy: 0.8543\n",
      "Epoch 51/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0604 - accuracy: 0.9794 - val_loss: 0.7559 - val_accuracy: 0.8620\n",
      "Epoch 52/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0608 - accuracy: 0.9789 - val_loss: 0.7716 - val_accuracy: 0.8593\n",
      "Epoch 53/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0586 - accuracy: 0.9795 - val_loss: 0.7982 - val_accuracy: 0.8560\n",
      "Epoch 54/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0598 - accuracy: 0.9791 - val_loss: 0.7789 - val_accuracy: 0.8559\n",
      "Epoch 55/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0561 - accuracy: 0.9800 - val_loss: 0.7791 - val_accuracy: 0.8596\n",
      "Epoch 56/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0575 - accuracy: 0.9794 - val_loss: 0.7842 - val_accuracy: 0.8569\n",
      "Epoch 57/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0574 - accuracy: 0.9799 - val_loss: 0.7993 - val_accuracy: 0.8578\n",
      "Epoch 58/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0569 - accuracy: 0.9807 - val_loss: 0.7980 - val_accuracy: 0.8578\n",
      "Epoch 59/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0530 - accuracy: 0.9813 - val_loss: 0.8202 - val_accuracy: 0.8546\n",
      "Epoch 60/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0561 - accuracy: 0.9802 - val_loss: 0.7977 - val_accuracy: 0.8622\n",
      "Epoch 61/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0552 - accuracy: 0.9807 - val_loss: 0.8194 - val_accuracy: 0.8569\n",
      "Epoch 62/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0553 - accuracy: 0.9799 - val_loss: 0.8260 - val_accuracy: 0.8543\n",
      "Epoch 63/150\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0545 - accuracy: 0.9804 - val_loss: 0.8280 - val_accuracy: 0.8596\n",
      "Epoch 64/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0526 - accuracy: 0.9808 - val_loss: 0.8335 - val_accuracy: 0.8573\n",
      "Epoch 65/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0540 - accuracy: 0.9807 - val_loss: 0.8329 - val_accuracy: 0.8557\n",
      "Epoch 66/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0536 - accuracy: 0.9813 - val_loss: 0.8384 - val_accuracy: 0.8546\n",
      "Epoch 67/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0513 - accuracy: 0.9823 - val_loss: 0.8613 - val_accuracy: 0.8531\n",
      "Epoch 68/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0535 - accuracy: 0.9804 - val_loss: 0.8690 - val_accuracy: 0.8558\n",
      "Epoch 69/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0504 - accuracy: 0.9819 - val_loss: 0.8646 - val_accuracy: 0.8563\n",
      "Epoch 70/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0519 - accuracy: 0.9823 - val_loss: 0.8897 - val_accuracy: 0.8541\n",
      "Epoch 71/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0510 - accuracy: 0.9818 - val_loss: 0.8707 - val_accuracy: 0.8595\n",
      "Epoch 72/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0506 - accuracy: 0.9818 - val_loss: 0.9000 - val_accuracy: 0.8574\n",
      "Epoch 73/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0564 - accuracy: 0.9812 - val_loss: 0.9567 - val_accuracy: 0.8551\n",
      "Epoch 74/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0837 - accuracy: 0.9813 - val_loss: 0.9373 - val_accuracy: 0.8578\n",
      "Epoch 75/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0621 - accuracy: 0.9830 - val_loss: 0.8764 - val_accuracy: 0.8520\n",
      "Epoch 76/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0529 - accuracy: 0.9834 - val_loss: 0.8409 - val_accuracy: 0.8597\n",
      "Epoch 77/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0459 - accuracy: 0.9828 - val_loss: 0.8708 - val_accuracy: 0.8572\n",
      "Epoch 78/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0462 - accuracy: 0.9825 - val_loss: 0.8744 - val_accuracy: 0.8574\n",
      "Epoch 79/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0488 - accuracy: 0.9821 - val_loss: 0.8661 - val_accuracy: 0.8558\n",
      "Epoch 80/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0475 - accuracy: 0.9827 - val_loss: 0.8750 - val_accuracy: 0.8537\n",
      "Epoch 81/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0493 - accuracy: 0.9820 - val_loss: 0.8597 - val_accuracy: 0.8551\n",
      "Epoch 82/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0467 - accuracy: 0.9828 - val_loss: 0.8777 - val_accuracy: 0.8591\n",
      "Epoch 83/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0490 - accuracy: 0.9823 - val_loss: 0.8584 - val_accuracy: 0.8549\n",
      "Epoch 84/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0475 - accuracy: 0.9820 - val_loss: 0.8682 - val_accuracy: 0.8563\n",
      "Epoch 85/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0482 - accuracy: 0.9818 - val_loss: 0.8631 - val_accuracy: 0.8569\n",
      "Epoch 86/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0449 - accuracy: 0.9832 - val_loss: 0.8451 - val_accuracy: 0.8628\n",
      "Epoch 87/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0461 - accuracy: 0.9837 - val_loss: 0.8657 - val_accuracy: 0.8592\n",
      "Epoch 88/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0471 - accuracy: 0.9826 - val_loss: 0.8769 - val_accuracy: 0.8588\n",
      "Epoch 89/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0453 - accuracy: 0.9827 - val_loss: 0.8491 - val_accuracy: 0.8589\n",
      "Epoch 90/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0442 - accuracy: 0.9837 - val_loss: 0.8800 - val_accuracy: 0.8583\n",
      "Epoch 91/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0457 - accuracy: 0.9829 - val_loss: 0.9078 - val_accuracy: 0.8578\n",
      "Epoch 92/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0465 - accuracy: 0.9825 - val_loss: 0.8775 - val_accuracy: 0.8543\n",
      "Epoch 93/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0446 - accuracy: 0.9832 - val_loss: 0.8983 - val_accuracy: 0.8577\n",
      "Epoch 94/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0456 - accuracy: 0.9829 - val_loss: 0.9251 - val_accuracy: 0.8539\n",
      "Epoch 95/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0445 - accuracy: 0.9831 - val_loss: 0.9297 - val_accuracy: 0.8561\n",
      "Epoch 96/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0436 - accuracy: 0.9841 - val_loss: 0.9218 - val_accuracy: 0.8540\n",
      "Epoch 97/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0440 - accuracy: 0.9837 - val_loss: 0.9171 - val_accuracy: 0.8598\n",
      "Epoch 98/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0432 - accuracy: 0.9831 - val_loss: 0.9071 - val_accuracy: 0.8579\n",
      "Epoch 99/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0425 - accuracy: 0.9841 - val_loss: 0.9259 - val_accuracy: 0.8536\n",
      "Epoch 100/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0431 - accuracy: 0.9840 - val_loss: 0.9192 - val_accuracy: 0.8582\n",
      "Epoch 101/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0430 - accuracy: 0.9838 - val_loss: 0.9263 - val_accuracy: 0.8561\n",
      "Epoch 102/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0453 - accuracy: 0.9838 - val_loss: 0.9524 - val_accuracy: 0.8569\n",
      "Epoch 103/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0625 - accuracy: 0.9820 - val_loss: 1.0666 - val_accuracy: 0.8481\n",
      "Epoch 104/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1100 - accuracy: 0.9816 - val_loss: 1.1047 - val_accuracy: 0.8508\n",
      "Epoch 105/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0501 - accuracy: 0.9848 - val_loss: 1.0188 - val_accuracy: 0.8560\n",
      "Epoch 106/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0424 - accuracy: 0.9851 - val_loss: 0.9966 - val_accuracy: 0.8586\n",
      "Epoch 107/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0375 - accuracy: 0.9848 - val_loss: 0.9913 - val_accuracy: 0.8579\n",
      "Epoch 108/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0383 - accuracy: 0.9845 - val_loss: 1.0263 - val_accuracy: 0.8559\n",
      "Epoch 109/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0407 - accuracy: 0.9840 - val_loss: 0.9928 - val_accuracy: 0.8535\n",
      "Epoch 110/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0405 - accuracy: 0.9838 - val_loss: 1.0129 - val_accuracy: 0.8550\n",
      "Epoch 111/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0412 - accuracy: 0.9833 - val_loss: 0.9919 - val_accuracy: 0.8574\n",
      "Epoch 112/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0407 - accuracy: 0.9844 - val_loss: 1.0068 - val_accuracy: 0.8562\n",
      "Epoch 113/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0413 - accuracy: 0.9839 - val_loss: 1.0186 - val_accuracy: 0.8577\n",
      "Epoch 114/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0411 - accuracy: 0.9841 - val_loss: 1.0382 - val_accuracy: 0.8563\n",
      "Epoch 115/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0416 - accuracy: 0.9839 - val_loss: 1.0806 - val_accuracy: 0.8485\n",
      "Epoch 116/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0414 - accuracy: 0.9841 - val_loss: 1.0226 - val_accuracy: 0.8556\n",
      "Epoch 117/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0399 - accuracy: 0.9841 - val_loss: 1.0197 - val_accuracy: 0.8543\n",
      "Epoch 118/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0387 - accuracy: 0.9847 - val_loss: 1.0053 - val_accuracy: 0.8544\n",
      "Epoch 119/150\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0385 - accuracy: 0.9850 - val_loss: 1.0315 - val_accuracy: 0.8553\n",
      "Epoch 120/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0392 - accuracy: 0.9848 - val_loss: 1.0715 - val_accuracy: 0.8569\n",
      "Epoch 121/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0396 - accuracy: 0.9835 - val_loss: 1.0399 - val_accuracy: 0.8544\n",
      "Epoch 122/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0387 - accuracy: 0.9847 - val_loss: 1.0529 - val_accuracy: 0.8587\n",
      "Epoch 123/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0388 - accuracy: 0.9843 - val_loss: 1.0605 - val_accuracy: 0.8564\n",
      "Epoch 124/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0401 - accuracy: 0.9839 - val_loss: 1.0604 - val_accuracy: 0.8529\n",
      "Epoch 125/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0392 - accuracy: 0.9842 - val_loss: 1.0771 - val_accuracy: 0.8561\n",
      "Epoch 126/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0388 - accuracy: 0.9839 - val_loss: 1.0805 - val_accuracy: 0.8553\n",
      "Epoch 127/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0376 - accuracy: 0.9845 - val_loss: 1.0465 - val_accuracy: 0.8578\n",
      "Epoch 128/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0396 - accuracy: 0.9843 - val_loss: 1.1783 - val_accuracy: 0.8562\n",
      "Epoch 129/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0361 - accuracy: 0.9853 - val_loss: 1.1319 - val_accuracy: 0.8601\n",
      "Epoch 130/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0389 - accuracy: 0.9839 - val_loss: 1.1183 - val_accuracy: 0.8565\n",
      "Epoch 131/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0409 - accuracy: 0.9854 - val_loss: 1.1677 - val_accuracy: 0.8585\n",
      "Epoch 132/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0391 - accuracy: 0.9839 - val_loss: 1.2026 - val_accuracy: 0.8565\n",
      "Epoch 133/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0378 - accuracy: 0.9847 - val_loss: 1.1993 - val_accuracy: 0.8562\n",
      "Epoch 134/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0380 - accuracy: 0.9847 - val_loss: 1.1670 - val_accuracy: 0.8566\n",
      "Epoch 135/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0374 - accuracy: 0.9845 - val_loss: 1.1202 - val_accuracy: 0.8576\n",
      "Epoch 136/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0362 - accuracy: 0.9849 - val_loss: 1.1401 - val_accuracy: 0.8563\n",
      "Epoch 137/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0372 - accuracy: 0.9838 - val_loss: 1.1367 - val_accuracy: 0.8590\n",
      "Epoch 138/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0372 - accuracy: 0.9849 - val_loss: 1.1799 - val_accuracy: 0.8552\n",
      "Epoch 139/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0370 - accuracy: 0.9845 - val_loss: 1.1660 - val_accuracy: 0.8534\n",
      "Epoch 140/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0366 - accuracy: 0.9847 - val_loss: 1.1467 - val_accuracy: 0.8548\n",
      "Epoch 141/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0365 - accuracy: 0.9844 - val_loss: 1.1564 - val_accuracy: 0.8604\n",
      "Epoch 142/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0364 - accuracy: 0.9843 - val_loss: 1.1762 - val_accuracy: 0.8569\n",
      "Epoch 143/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0372 - accuracy: 0.9841 - val_loss: 1.1618 - val_accuracy: 0.8564\n",
      "Epoch 144/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0350 - accuracy: 0.9849 - val_loss: 1.1895 - val_accuracy: 0.8582\n",
      "Epoch 145/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0361 - accuracy: 0.9843 - val_loss: 1.1519 - val_accuracy: 0.8585\n",
      "Epoch 146/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0355 - accuracy: 0.9848 - val_loss: 1.1927 - val_accuracy: 0.8568\n",
      "Epoch 147/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0351 - accuracy: 0.9852 - val_loss: 1.1920 - val_accuracy: 0.8570\n",
      "Epoch 148/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0355 - accuracy: 0.9847 - val_loss: 1.1720 - val_accuracy: 0.8531\n",
      "Epoch 149/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0356 - accuracy: 0.9847 - val_loss: 1.2155 - val_accuracy: 0.8565\n",
      "Epoch 150/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0353 - accuracy: 0.9849 - val_loss: 1.1979 - val_accuracy: 0.8529\n",
      "Adam: 3 / 4 ###################################################\n",
      "Epoch 1/50\n",
      "1260/1260 [==============================] - 3s 2ms/step - loss: 1.0171 - accuracy: 0.7308 - val_loss: 0.7060 - val_accuracy: 0.7907\n",
      "Epoch 2/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.5930 - accuracy: 0.8170 - val_loss: 0.7316 - val_accuracy: 0.8071\n",
      "Epoch 3/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.4894 - accuracy: 0.8434 - val_loss: 0.6268 - val_accuracy: 0.8169\n",
      "Epoch 4/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.4071 - accuracy: 0.8639 - val_loss: 0.6102 - val_accuracy: 0.8326\n",
      "Epoch 5/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3414 - accuracy: 0.8786 - val_loss: 0.6366 - val_accuracy: 0.8301\n",
      "Epoch 6/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3361 - accuracy: 0.8856 - val_loss: 0.6113 - val_accuracy: 0.8396\n",
      "Epoch 7/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2856 - accuracy: 0.8972 - val_loss: 0.5572 - val_accuracy: 0.8465\n",
      "Epoch 8/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2701 - accuracy: 0.9014 - val_loss: 0.7934 - val_accuracy: 0.8495\n",
      "Epoch 9/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3027 - accuracy: 0.9046 - val_loss: 0.7224 - val_accuracy: 0.8355\n",
      "Epoch 10/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2379 - accuracy: 0.9111 - val_loss: 0.6933 - val_accuracy: 0.8370\n",
      "Epoch 11/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2236 - accuracy: 0.9136 - val_loss: 0.6929 - val_accuracy: 0.8492\n",
      "Epoch 12/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2175 - accuracy: 0.9171 - val_loss: 0.6252 - val_accuracy: 0.8529\n",
      "Epoch 13/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2146 - accuracy: 0.9194 - val_loss: 0.6431 - val_accuracy: 0.8553\n",
      "Epoch 14/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2058 - accuracy: 0.9221 - val_loss: 0.6613 - val_accuracy: 0.8490\n",
      "Epoch 15/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2847 - accuracy: 0.9146 - val_loss: 0.8931 - val_accuracy: 0.8476\n",
      "Epoch 16/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2627 - accuracy: 0.9228 - val_loss: 1.1384 - val_accuracy: 0.8366\n",
      "Epoch 17/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2171 - accuracy: 0.9277 - val_loss: 0.7434 - val_accuracy: 0.8551\n",
      "Epoch 18/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2480 - accuracy: 0.9275 - val_loss: 0.8194 - val_accuracy: 0.8524\n",
      "Epoch 19/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1921 - accuracy: 0.9340 - val_loss: 0.8185 - val_accuracy: 0.8572\n",
      "Epoch 20/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1721 - accuracy: 0.9354 - val_loss: 0.8409 - val_accuracy: 0.8550\n",
      "Epoch 21/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1762 - accuracy: 0.9352 - val_loss: 0.8652 - val_accuracy: 0.8497\n",
      "Epoch 22/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2111 - accuracy: 0.9310 - val_loss: 1.0953 - val_accuracy: 0.8527\n",
      "Epoch 23/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1631 - accuracy: 0.9374 - val_loss: 0.9685 - val_accuracy: 0.8524\n",
      "Epoch 24/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1695 - accuracy: 0.9390 - val_loss: 1.1281 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 25/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2363 - accuracy: 0.9335 - val_loss: 1.0254 - val_accuracy: 0.8568\n",
      "Epoch 26/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1589 - accuracy: 0.9412 - val_loss: 0.9721 - val_accuracy: 0.8537\n",
      "Epoch 27/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1631 - accuracy: 0.9399 - val_loss: 1.0308 - val_accuracy: 0.8568\n",
      "Epoch 28/50\n",
      "1260/1260 [==============================] - 3s 2ms/step - loss: 0.1585 - accuracy: 0.9420 - val_loss: 1.0470 - val_accuracy: 0.8557\n",
      "Epoch 29/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1578 - accuracy: 0.9424 - val_loss: 0.9597 - val_accuracy: 0.8600\n",
      "Epoch 30/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1744 - accuracy: 0.9402 - val_loss: 1.0311 - val_accuracy: 0.8525\n",
      "Epoch 31/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1963 - accuracy: 0.9405 - val_loss: 1.0577 - val_accuracy: 0.8523\n",
      "Epoch 32/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2198 - accuracy: 0.9433 - val_loss: 1.2545 - val_accuracy: 0.8569\n",
      "Epoch 33/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1720 - accuracy: 0.9432 - val_loss: 1.6086 - val_accuracy: 0.8524\n",
      "Epoch 34/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2100 - accuracy: 0.9470 - val_loss: 1.4193 - val_accuracy: 0.8568\n",
      "Epoch 35/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1613 - accuracy: 0.9453 - val_loss: 1.1858 - val_accuracy: 0.8538\n",
      "Epoch 36/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1421 - accuracy: 0.9483 - val_loss: 1.3372 - val_accuracy: 0.8575\n",
      "Epoch 37/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1477 - accuracy: 0.9491 - val_loss: 1.0681 - val_accuracy: 0.8604\n",
      "Epoch 38/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1499 - accuracy: 0.9492 - val_loss: 1.2473 - val_accuracy: 0.8540\n",
      "Epoch 39/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1779 - accuracy: 0.9438 - val_loss: 1.0808 - val_accuracy: 0.8603\n",
      "Epoch 40/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1479 - accuracy: 0.9491 - val_loss: 1.4323 - val_accuracy: 0.8432\n",
      "Epoch 41/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1519 - accuracy: 0.9474 - val_loss: 1.2508 - val_accuracy: 0.8491\n",
      "Epoch 42/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1700 - accuracy: 0.9477 - val_loss: 1.1961 - val_accuracy: 0.8610\n",
      "Epoch 43/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1435 - accuracy: 0.9521 - val_loss: 1.1219 - val_accuracy: 0.8606\n",
      "Epoch 44/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1362 - accuracy: 0.9531 - val_loss: 1.2903 - val_accuracy: 0.8627\n",
      "Epoch 45/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1632 - accuracy: 0.9505 - val_loss: 1.2179 - val_accuracy: 0.8540\n",
      "Epoch 46/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2403 - accuracy: 0.9415 - val_loss: 1.8509 - val_accuracy: 0.8577\n",
      "Epoch 47/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1278 - accuracy: 0.9557 - val_loss: 1.3412 - val_accuracy: 0.8636\n",
      "Epoch 48/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1281 - accuracy: 0.9541 - val_loss: 1.3345 - val_accuracy: 0.8576\n",
      "Epoch 49/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1295 - accuracy: 0.9543 - val_loss: 1.3498 - val_accuracy: 0.8601\n",
      "Epoch 50/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1560 - accuracy: 0.9495 - val_loss: 1.4105 - val_accuracy: 0.8596\n",
      "Adam: 4 / 4 ###################################################\n",
      "Epoch 1/150\n",
      "1260/1260 [==============================] - 3s 2ms/step - loss: 1.0171 - accuracy: 0.7308 - val_loss: 0.7060 - val_accuracy: 0.7907\n",
      "Epoch 2/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.5930 - accuracy: 0.8170 - val_loss: 0.7316 - val_accuracy: 0.8071\n",
      "Epoch 3/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.4894 - accuracy: 0.8434 - val_loss: 0.6268 - val_accuracy: 0.8169\n",
      "Epoch 4/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.4071 - accuracy: 0.8639 - val_loss: 0.6102 - val_accuracy: 0.8326\n",
      "Epoch 5/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3414 - accuracy: 0.8786 - val_loss: 0.6366 - val_accuracy: 0.8301\n",
      "Epoch 6/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3361 - accuracy: 0.8856 - val_loss: 0.6113 - val_accuracy: 0.8396\n",
      "Epoch 7/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2856 - accuracy: 0.8972 - val_loss: 0.5572 - val_accuracy: 0.8465\n",
      "Epoch 8/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2701 - accuracy: 0.9014 - val_loss: 0.7934 - val_accuracy: 0.8495\n",
      "Epoch 9/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3027 - accuracy: 0.9046 - val_loss: 0.7224 - val_accuracy: 0.8355\n",
      "Epoch 10/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2379 - accuracy: 0.9111 - val_loss: 0.6933 - val_accuracy: 0.8370\n",
      "Epoch 11/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2236 - accuracy: 0.9136 - val_loss: 0.6929 - val_accuracy: 0.8492\n",
      "Epoch 12/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2175 - accuracy: 0.9171 - val_loss: 0.6252 - val_accuracy: 0.8529\n",
      "Epoch 13/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2146 - accuracy: 0.9194 - val_loss: 0.6431 - val_accuracy: 0.8553\n",
      "Epoch 14/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2058 - accuracy: 0.9221 - val_loss: 0.6613 - val_accuracy: 0.8490\n",
      "Epoch 15/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2847 - accuracy: 0.9146 - val_loss: 0.8931 - val_accuracy: 0.8476\n",
      "Epoch 16/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2627 - accuracy: 0.9228 - val_loss: 1.1384 - val_accuracy: 0.8366\n",
      "Epoch 17/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2171 - accuracy: 0.9277 - val_loss: 0.7434 - val_accuracy: 0.8551\n",
      "Epoch 18/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2480 - accuracy: 0.9275 - val_loss: 0.8194 - val_accuracy: 0.8524\n",
      "Epoch 19/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1921 - accuracy: 0.9340 - val_loss: 0.8185 - val_accuracy: 0.8572\n",
      "Epoch 20/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1721 - accuracy: 0.9354 - val_loss: 0.8409 - val_accuracy: 0.8550\n",
      "Epoch 21/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1762 - accuracy: 0.9352 - val_loss: 0.8652 - val_accuracy: 0.8497\n",
      "Epoch 22/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2111 - accuracy: 0.9310 - val_loss: 1.0953 - val_accuracy: 0.8527\n",
      "Epoch 23/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1631 - accuracy: 0.9374 - val_loss: 0.9685 - val_accuracy: 0.8524\n",
      "Epoch 24/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1695 - accuracy: 0.9390 - val_loss: 1.1281 - val_accuracy: 0.8500\n",
      "Epoch 25/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2363 - accuracy: 0.9335 - val_loss: 1.0254 - val_accuracy: 0.8568\n",
      "Epoch 26/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1589 - accuracy: 0.9412 - val_loss: 0.9721 - val_accuracy: 0.8537\n",
      "Epoch 27/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1631 - accuracy: 0.9399 - val_loss: 1.0308 - val_accuracy: 0.8568\n",
      "Epoch 28/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1585 - accuracy: 0.9420 - val_loss: 1.0470 - val_accuracy: 0.8557\n",
      "Epoch 29/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1578 - accuracy: 0.9424 - val_loss: 0.9597 - val_accuracy: 0.8600\n",
      "Epoch 30/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1744 - accuracy: 0.9402 - val_loss: 1.0311 - val_accuracy: 0.8525\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 31/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1963 - accuracy: 0.9405 - val_loss: 1.0577 - val_accuracy: 0.8523\n",
      "Epoch 32/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2198 - accuracy: 0.9433 - val_loss: 1.2545 - val_accuracy: 0.8569\n",
      "Epoch 33/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1720 - accuracy: 0.9432 - val_loss: 1.6086 - val_accuracy: 0.8524\n",
      "Epoch 34/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2100 - accuracy: 0.9470 - val_loss: 1.4193 - val_accuracy: 0.8568\n",
      "Epoch 35/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1613 - accuracy: 0.9453 - val_loss: 1.1858 - val_accuracy: 0.8538\n",
      "Epoch 36/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1421 - accuracy: 0.9483 - val_loss: 1.3372 - val_accuracy: 0.8575\n",
      "Epoch 37/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1477 - accuracy: 0.9491 - val_loss: 1.0681 - val_accuracy: 0.8604\n",
      "Epoch 38/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1499 - accuracy: 0.9492 - val_loss: 1.2473 - val_accuracy: 0.8540\n",
      "Epoch 39/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1779 - accuracy: 0.9438 - val_loss: 1.0808 - val_accuracy: 0.8603\n",
      "Epoch 40/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1479 - accuracy: 0.9491 - val_loss: 1.4323 - val_accuracy: 0.8432\n",
      "Epoch 41/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1519 - accuracy: 0.9474 - val_loss: 1.2508 - val_accuracy: 0.8491\n",
      "Epoch 42/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1700 - accuracy: 0.9477 - val_loss: 1.1961 - val_accuracy: 0.8610\n",
      "Epoch 43/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1435 - accuracy: 0.9521 - val_loss: 1.1219 - val_accuracy: 0.8606\n",
      "Epoch 44/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1362 - accuracy: 0.9531 - val_loss: 1.2903 - val_accuracy: 0.8627\n",
      "Epoch 45/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1632 - accuracy: 0.9505 - val_loss: 1.2179 - val_accuracy: 0.8540\n",
      "Epoch 46/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2403 - accuracy: 0.9415 - val_loss: 1.8509 - val_accuracy: 0.8577\n",
      "Epoch 47/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1278 - accuracy: 0.9557 - val_loss: 1.3412 - val_accuracy: 0.8636\n",
      "Epoch 48/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1281 - accuracy: 0.9541 - val_loss: 1.3345 - val_accuracy: 0.8576\n",
      "Epoch 49/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1295 - accuracy: 0.9543 - val_loss: 1.3498 - val_accuracy: 0.8601\n",
      "Epoch 50/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1560 - accuracy: 0.9495 - val_loss: 1.4105 - val_accuracy: 0.8596\n",
      "Epoch 51/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1862 - accuracy: 0.9501 - val_loss: 1.1411 - val_accuracy: 0.8598\n",
      "Epoch 52/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1920 - accuracy: 0.9499 - val_loss: 1.1599 - val_accuracy: 0.8548\n",
      "Epoch 53/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1295 - accuracy: 0.9543 - val_loss: 1.1949 - val_accuracy: 0.8579\n",
      "Epoch 54/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1252 - accuracy: 0.9570 - val_loss: 1.1633 - val_accuracy: 0.8576\n",
      "Epoch 55/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1449 - accuracy: 0.9538 - val_loss: 1.2780 - val_accuracy: 0.8545\n",
      "Epoch 56/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1311 - accuracy: 0.9553 - val_loss: 1.2929 - val_accuracy: 0.8470\n",
      "Epoch 57/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1442 - accuracy: 0.9546 - val_loss: 1.3742 - val_accuracy: 0.8594\n",
      "Epoch 58/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1312 - accuracy: 0.9556 - val_loss: 1.4769 - val_accuracy: 0.8518\n",
      "Epoch 59/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1872 - accuracy: 0.9539 - val_loss: 1.2362 - val_accuracy: 0.8590\n",
      "Epoch 60/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1271 - accuracy: 0.9581 - val_loss: 1.3029 - val_accuracy: 0.8562\n",
      "Epoch 61/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1247 - accuracy: 0.9580 - val_loss: 1.2942 - val_accuracy: 0.8566\n",
      "Epoch 62/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1482 - accuracy: 0.9563 - val_loss: 1.3168 - val_accuracy: 0.8471\n",
      "Epoch 63/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1567 - accuracy: 0.9525 - val_loss: 1.3823 - val_accuracy: 0.8567\n",
      "Epoch 64/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1290 - accuracy: 0.9593 - val_loss: 1.3064 - val_accuracy: 0.8575\n",
      "Epoch 65/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1451 - accuracy: 0.9556 - val_loss: 1.2024 - val_accuracy: 0.8577\n",
      "Epoch 66/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1221 - accuracy: 0.9588 - val_loss: 1.3871 - val_accuracy: 0.8575\n",
      "Epoch 67/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1209 - accuracy: 0.9593 - val_loss: 1.3779 - val_accuracy: 0.8633\n",
      "Epoch 68/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1388 - accuracy: 0.9572 - val_loss: 1.4081 - val_accuracy: 0.8576\n",
      "Epoch 69/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1448 - accuracy: 0.9567 - val_loss: 1.5690 - val_accuracy: 0.8512\n",
      "Epoch 70/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1321 - accuracy: 0.9578 - val_loss: 1.4064 - val_accuracy: 0.8588\n",
      "Epoch 71/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1203 - accuracy: 0.9598 - val_loss: 1.4215 - val_accuracy: 0.8598\n",
      "Epoch 72/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1291 - accuracy: 0.9585 - val_loss: 1.4081 - val_accuracy: 0.8565\n",
      "Epoch 73/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1245 - accuracy: 0.9589 - val_loss: 1.5377 - val_accuracy: 0.8621\n",
      "Epoch 74/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1226 - accuracy: 0.9610 - val_loss: 1.5683 - val_accuracy: 0.8566\n",
      "Epoch 75/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1392 - accuracy: 0.9575 - val_loss: 1.4389 - val_accuracy: 0.8552\n",
      "Epoch 76/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1254 - accuracy: 0.9597 - val_loss: 1.4878 - val_accuracy: 0.8610\n",
      "Epoch 77/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1345 - accuracy: 0.9576 - val_loss: 1.4982 - val_accuracy: 0.8575\n",
      "Epoch 78/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1248 - accuracy: 0.9596 - val_loss: 1.6802 - val_accuracy: 0.8593\n",
      "Epoch 79/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1364 - accuracy: 0.9591 - val_loss: 1.5080 - val_accuracy: 0.8524\n",
      "Epoch 80/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1245 - accuracy: 0.9604 - val_loss: 1.6329 - val_accuracy: 0.8596\n",
      "Epoch 81/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1464 - accuracy: 0.9591 - val_loss: 1.4687 - val_accuracy: 0.8552\n",
      "Epoch 82/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1143 - accuracy: 0.9624 - val_loss: 1.6923 - val_accuracy: 0.8593\n",
      "Epoch 83/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1213 - accuracy: 0.9610 - val_loss: 1.5755 - val_accuracy: 0.8542\n",
      "Epoch 84/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1295 - accuracy: 0.9602 - val_loss: 1.6313 - val_accuracy: 0.8566\n",
      "Epoch 85/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1340 - accuracy: 0.9595 - val_loss: 1.5901 - val_accuracy: 0.8592\n",
      "Epoch 86/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1279 - accuracy: 0.9606 - val_loss: 1.6278 - val_accuracy: 0.8586\n",
      "Epoch 87/150\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1115 - accuracy: 0.9630 - val_loss: 1.6938 - val_accuracy: 0.8633\n",
      "Epoch 88/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1388 - accuracy: 0.9603 - val_loss: 1.8102 - val_accuracy: 0.8573\n",
      "Epoch 89/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1409 - accuracy: 0.9606 - val_loss: 1.5614 - val_accuracy: 0.8597\n",
      "Epoch 90/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1184 - accuracy: 0.9638 - val_loss: 1.6847 - val_accuracy: 0.8607\n",
      "Epoch 91/150\n",
      "1260/1260 [==============================] - 3s 2ms/step - loss: 0.1176 - accuracy: 0.9633 - val_loss: 1.7653 - val_accuracy: 0.8605\n",
      "Epoch 92/150\n",
      "1260/1260 [==============================] - 3s 2ms/step - loss: 0.1241 - accuracy: 0.9633 - val_loss: 1.7617 - val_accuracy: 0.8592\n",
      "Epoch 93/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1352 - accuracy: 0.9607 - val_loss: 1.8378 - val_accuracy: 0.8580\n",
      "Epoch 94/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1356 - accuracy: 0.9611 - val_loss: 1.8705 - val_accuracy: 0.8604\n",
      "Epoch 95/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1187 - accuracy: 0.9648 - val_loss: 1.8637 - val_accuracy: 0.8583\n",
      "Epoch 96/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1291 - accuracy: 0.9620 - val_loss: 1.7798 - val_accuracy: 0.8611\n",
      "Epoch 97/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1200 - accuracy: 0.9639 - val_loss: 1.8708 - val_accuracy: 0.8584\n",
      "Epoch 98/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1238 - accuracy: 0.9632 - val_loss: 1.9043 - val_accuracy: 0.8584\n",
      "Epoch 99/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1165 - accuracy: 0.9629 - val_loss: 1.8386 - val_accuracy: 0.8605\n",
      "Epoch 100/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1078 - accuracy: 0.9652 - val_loss: 1.9619 - val_accuracy: 0.8645\n",
      "Epoch 101/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1194 - accuracy: 0.9637 - val_loss: 1.8682 - val_accuracy: 0.8580\n",
      "Epoch 102/150\n",
      "1260/1260 [==============================] - 3s 2ms/step - loss: 0.1422 - accuracy: 0.9607 - val_loss: 2.0109 - val_accuracy: 0.8595\n",
      "Epoch 103/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1491 - accuracy: 0.9603 - val_loss: 1.9917 - val_accuracy: 0.8599\n",
      "Epoch 104/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1163 - accuracy: 0.9658 - val_loss: 2.1045 - val_accuracy: 0.8701\n",
      "Epoch 105/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0981 - accuracy: 0.9666 - val_loss: 2.2008 - val_accuracy: 0.8596\n",
      "Epoch 106/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1403 - accuracy: 0.9595 - val_loss: 1.9887 - val_accuracy: 0.8635\n",
      "Epoch 107/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1359 - accuracy: 0.9638 - val_loss: 2.0436 - val_accuracy: 0.8658\n",
      "Epoch 108/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1080 - accuracy: 0.9675 - val_loss: 2.1067 - val_accuracy: 0.8575\n",
      "Epoch 109/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1385 - accuracy: 0.9612 - val_loss: 1.9435 - val_accuracy: 0.8591\n",
      "Epoch 110/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1170 - accuracy: 0.9652 - val_loss: 2.2623 - val_accuracy: 0.8590\n",
      "Epoch 111/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1330 - accuracy: 0.9627 - val_loss: 2.1735 - val_accuracy: 0.8617\n",
      "Epoch 112/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1161 - accuracy: 0.9655 - val_loss: 2.1733 - val_accuracy: 0.8625\n",
      "Epoch 113/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1316 - accuracy: 0.9636 - val_loss: 2.1656 - val_accuracy: 0.8601\n",
      "Epoch 114/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1276 - accuracy: 0.9644 - val_loss: 2.3607 - val_accuracy: 0.8591\n",
      "Epoch 115/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1252 - accuracy: 0.9646 - val_loss: 2.2842 - val_accuracy: 0.8602\n",
      "Epoch 116/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1392 - accuracy: 0.9629 - val_loss: 2.2017 - val_accuracy: 0.8646\n",
      "Epoch 117/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2075 - accuracy: 0.9637 - val_loss: 2.3478 - val_accuracy: 0.8517\n",
      "Epoch 118/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1611 - accuracy: 0.9613 - val_loss: 2.1640 - val_accuracy: 0.8594\n",
      "Epoch 119/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1058 - accuracy: 0.9670 - val_loss: 2.1991 - val_accuracy: 0.8588\n",
      "Epoch 120/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1252 - accuracy: 0.9639 - val_loss: 2.1950 - val_accuracy: 0.8588\n",
      "Epoch 121/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1269 - accuracy: 0.9640 - val_loss: 2.2422 - val_accuracy: 0.8613\n",
      "Epoch 122/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1153 - accuracy: 0.9662 - val_loss: 2.1089 - val_accuracy: 0.8653\n",
      "Epoch 123/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1127 - accuracy: 0.9672 - val_loss: 2.3539 - val_accuracy: 0.8588\n",
      "Epoch 124/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1187 - accuracy: 0.9659 - val_loss: 2.0509 - val_accuracy: 0.8605\n",
      "Epoch 125/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1253 - accuracy: 0.9632 - val_loss: 2.5376 - val_accuracy: 0.8598\n",
      "Epoch 126/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1410 - accuracy: 0.9635 - val_loss: 2.6166 - val_accuracy: 0.8613\n",
      "Epoch 127/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1339 - accuracy: 0.9662 - val_loss: 2.4088 - val_accuracy: 0.8642\n",
      "Epoch 128/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1154 - accuracy: 0.9668 - val_loss: 2.6944 - val_accuracy: 0.8629\n",
      "Epoch 129/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1188 - accuracy: 0.9658 - val_loss: 2.4031 - val_accuracy: 0.8571\n",
      "Epoch 130/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1294 - accuracy: 0.9634 - val_loss: 2.5444 - val_accuracy: 0.8583\n",
      "Epoch 131/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1323 - accuracy: 0.9646 - val_loss: 2.5520 - val_accuracy: 0.8624\n",
      "Epoch 132/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1289 - accuracy: 0.9667 - val_loss: 2.4211 - val_accuracy: 0.8598\n",
      "Epoch 133/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1439 - accuracy: 0.9648 - val_loss: 2.5185 - val_accuracy: 0.8554\n",
      "Epoch 134/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1138 - accuracy: 0.9672 - val_loss: 2.5825 - val_accuracy: 0.8661\n",
      "Epoch 135/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1214 - accuracy: 0.9680 - val_loss: 2.6212 - val_accuracy: 0.8569\n",
      "Epoch 136/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1402 - accuracy: 0.9654 - val_loss: 2.5736 - val_accuracy: 0.8548\n",
      "Epoch 137/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1067 - accuracy: 0.9667 - val_loss: 2.4664 - val_accuracy: 0.8617\n",
      "Epoch 138/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1012 - accuracy: 0.9699 - val_loss: 2.6690 - val_accuracy: 0.8607\n",
      "Epoch 139/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1380 - accuracy: 0.9640 - val_loss: 2.7691 - val_accuracy: 0.8574\n",
      "Epoch 140/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1350 - accuracy: 0.9656 - val_loss: 3.0445 - val_accuracy: 0.8603\n",
      "Epoch 141/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1230 - accuracy: 0.9680 - val_loss: 2.5283 - val_accuracy: 0.8573\n",
      "Epoch 142/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1324 - accuracy: 0.9668 - val_loss: 2.5588 - val_accuracy: 0.8590\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 143/150\n",
      "1260/1260 [==============================] - 3s 2ms/step - loss: 0.1147 - accuracy: 0.9686 - val_loss: 2.8979 - val_accuracy: 0.8656\n",
      "Epoch 144/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1265 - accuracy: 0.9661 - val_loss: 3.0724 - val_accuracy: 0.8608\n",
      "Epoch 145/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1448 - accuracy: 0.9666 - val_loss: 2.7651 - val_accuracy: 0.8636\n",
      "Epoch 146/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1046 - accuracy: 0.9675 - val_loss: 3.0371 - val_accuracy: 0.8668\n",
      "Epoch 147/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1107 - accuracy: 0.9693 - val_loss: 2.8665 - val_accuracy: 0.8630\n",
      "Epoch 148/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1376 - accuracy: 0.9662 - val_loss: 2.7624 - val_accuracy: 0.8679\n",
      "Epoch 149/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1132 - accuracy: 0.9705 - val_loss: 2.7934 - val_accuracy: 0.8642\n",
      "Epoch 150/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1334 - accuracy: 0.9654 - val_loss: 2.7046 - val_accuracy: 0.8625\n",
      " SGD: 5 / 4 ###################################################\n",
      "Epoch 1/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 2.8365 - accuracy: 0.3744 - val_loss: 1.6107 - val_accuracy: 0.6306\n",
      "Epoch 2/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 1.2173 - accuracy: 0.7003 - val_loss: 1.0672 - val_accuracy: 0.7301\n",
      "Epoch 3/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.9173 - accuracy: 0.7560 - val_loss: 0.8996 - val_accuracy: 0.7603\n",
      "Epoch 4/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.7894 - accuracy: 0.7824 - val_loss: 0.8065 - val_accuracy: 0.7823\n",
      "Epoch 5/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.7119 - accuracy: 0.8013 - val_loss: 0.7583 - val_accuracy: 0.7891\n",
      "Epoch 6/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.6549 - accuracy: 0.8159 - val_loss: 0.7201 - val_accuracy: 0.7987\n",
      "Epoch 7/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.6102 - accuracy: 0.8258 - val_loss: 0.6888 - val_accuracy: 0.8075\n",
      "Epoch 8/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.5731 - accuracy: 0.8349 - val_loss: 0.6630 - val_accuracy: 0.8124\n",
      "Epoch 9/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.5422 - accuracy: 0.8417 - val_loss: 0.6513 - val_accuracy: 0.8123\n",
      "Epoch 10/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.5147 - accuracy: 0.8497 - val_loss: 0.6325 - val_accuracy: 0.8188\n",
      "Epoch 11/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.4895 - accuracy: 0.8555 - val_loss: 0.6201 - val_accuracy: 0.8191\n",
      "Epoch 12/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.4683 - accuracy: 0.8623 - val_loss: 0.6042 - val_accuracy: 0.8232\n",
      "Epoch 13/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.4474 - accuracy: 0.8678 - val_loss: 0.5968 - val_accuracy: 0.8244\n",
      "Epoch 14/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.4287 - accuracy: 0.8727 - val_loss: 0.5815 - val_accuracy: 0.8333\n",
      "Epoch 15/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.4112 - accuracy: 0.8778 - val_loss: 0.5747 - val_accuracy: 0.8320\n",
      "Epoch 16/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3949 - accuracy: 0.8833 - val_loss: 0.5678 - val_accuracy: 0.8327\n",
      "Epoch 17/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3798 - accuracy: 0.8856 - val_loss: 0.5643 - val_accuracy: 0.8347\n",
      "Epoch 18/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3652 - accuracy: 0.8901 - val_loss: 0.5551 - val_accuracy: 0.8368\n",
      "Epoch 19/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3526 - accuracy: 0.8939 - val_loss: 0.5560 - val_accuracy: 0.8343\n",
      "Epoch 20/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3396 - accuracy: 0.8978 - val_loss: 0.5466 - val_accuracy: 0.8368\n",
      "Epoch 21/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3281 - accuracy: 0.9003 - val_loss: 0.5479 - val_accuracy: 0.8353\n",
      "Epoch 22/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3169 - accuracy: 0.9039 - val_loss: 0.5408 - val_accuracy: 0.8392\n",
      "Epoch 23/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3063 - accuracy: 0.9071 - val_loss: 0.5371 - val_accuracy: 0.8423\n",
      "Epoch 24/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2972 - accuracy: 0.9094 - val_loss: 0.5338 - val_accuracy: 0.8429\n",
      "Epoch 25/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2875 - accuracy: 0.9135 - val_loss: 0.5343 - val_accuracy: 0.8383\n",
      "Epoch 26/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2784 - accuracy: 0.9143 - val_loss: 0.5272 - val_accuracy: 0.8418\n",
      "Epoch 27/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2702 - accuracy: 0.9174 - val_loss: 0.5234 - val_accuracy: 0.8467\n",
      "Epoch 28/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2623 - accuracy: 0.9207 - val_loss: 0.5257 - val_accuracy: 0.8427\n",
      "Epoch 29/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2550 - accuracy: 0.9231 - val_loss: 0.5208 - val_accuracy: 0.8464\n",
      "Epoch 30/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2472 - accuracy: 0.9240 - val_loss: 0.5211 - val_accuracy: 0.8456\n",
      "Epoch 31/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2401 - accuracy: 0.9273 - val_loss: 0.5188 - val_accuracy: 0.8485\n",
      "Epoch 32/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2338 - accuracy: 0.9285 - val_loss: 0.5145 - val_accuracy: 0.8491\n",
      "Epoch 33/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2269 - accuracy: 0.9323 - val_loss: 0.5163 - val_accuracy: 0.8482\n",
      "Epoch 34/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2208 - accuracy: 0.9332 - val_loss: 0.5127 - val_accuracy: 0.8481\n",
      "Epoch 35/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2153 - accuracy: 0.9353 - val_loss: 0.5147 - val_accuracy: 0.8466\n",
      "Epoch 36/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2098 - accuracy: 0.9367 - val_loss: 0.5125 - val_accuracy: 0.8521\n",
      "Epoch 37/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2047 - accuracy: 0.9386 - val_loss: 0.5137 - val_accuracy: 0.8497\n",
      "Epoch 38/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1996 - accuracy: 0.9402 - val_loss: 0.5115 - val_accuracy: 0.8493\n",
      "Epoch 39/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1948 - accuracy: 0.9413 - val_loss: 0.5071 - val_accuracy: 0.8522\n",
      "Epoch 40/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1903 - accuracy: 0.9427 - val_loss: 0.5112 - val_accuracy: 0.8496\n",
      "Epoch 41/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1852 - accuracy: 0.9442 - val_loss: 0.5125 - val_accuracy: 0.8511\n",
      "Epoch 42/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1813 - accuracy: 0.9464 - val_loss: 0.5135 - val_accuracy: 0.8510\n",
      "Epoch 43/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1769 - accuracy: 0.9476 - val_loss: 0.5130 - val_accuracy: 0.8511\n",
      "Epoch 44/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1732 - accuracy: 0.9480 - val_loss: 0.5092 - val_accuracy: 0.8535\n",
      "Epoch 45/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1693 - accuracy: 0.9489 - val_loss: 0.5134 - val_accuracy: 0.8511\n",
      "Epoch 46/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1648 - accuracy: 0.9509 - val_loss: 0.5142 - val_accuracy: 0.8506\n",
      "Epoch 47/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1624 - accuracy: 0.9512 - val_loss: 0.5131 - val_accuracy: 0.8526\n",
      "Epoch 48/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1588 - accuracy: 0.9527 - val_loss: 0.5150 - val_accuracy: 0.8480\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1553 - accuracy: 0.9535 - val_loss: 0.5191 - val_accuracy: 0.8503\n",
      "Epoch 50/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1524 - accuracy: 0.9540 - val_loss: 0.5169 - val_accuracy: 0.8516\n",
      " SGD: 6 / 4 ###################################################\n",
      "Epoch 1/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 2.8305 - accuracy: 0.3755 - val_loss: 1.6015 - val_accuracy: 0.6323\n",
      "Epoch 2/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 1.2098 - accuracy: 0.7016 - val_loss: 1.0601 - val_accuracy: 0.7300\n",
      "Epoch 3/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.9104 - accuracy: 0.7568 - val_loss: 0.8928 - val_accuracy: 0.7608\n",
      "Epoch 4/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.7825 - accuracy: 0.7840 - val_loss: 0.7982 - val_accuracy: 0.7849\n",
      "Epoch 5/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.7020 - accuracy: 0.8030 - val_loss: 0.7499 - val_accuracy: 0.7907\n",
      "Epoch 6/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.6451 - accuracy: 0.8175 - val_loss: 0.7113 - val_accuracy: 0.8002\n",
      "Epoch 7/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.5989 - accuracy: 0.8284 - val_loss: 0.6789 - val_accuracy: 0.8097\n",
      "Epoch 8/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.5607 - accuracy: 0.8375 - val_loss: 0.6521 - val_accuracy: 0.8151\n",
      "Epoch 9/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.5285 - accuracy: 0.8448 - val_loss: 0.6406 - val_accuracy: 0.8145\n",
      "Epoch 10/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.4995 - accuracy: 0.8531 - val_loss: 0.6229 - val_accuracy: 0.8195\n",
      "Epoch 11/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.4731 - accuracy: 0.8592 - val_loss: 0.6117 - val_accuracy: 0.8191\n",
      "Epoch 12/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.4501 - accuracy: 0.8663 - val_loss: 0.5944 - val_accuracy: 0.8263\n",
      "Epoch 13/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.4277 - accuracy: 0.8724 - val_loss: 0.5867 - val_accuracy: 0.8264\n",
      "Epoch 14/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.4076 - accuracy: 0.8781 - val_loss: 0.5702 - val_accuracy: 0.8353\n",
      "Epoch 15/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3888 - accuracy: 0.8829 - val_loss: 0.5639 - val_accuracy: 0.8354\n",
      "Epoch 16/150\n",
      "1260/1260 [==============================] - 3s 2ms/step - loss: 0.3708 - accuracy: 0.8889 - val_loss: 0.5565 - val_accuracy: 0.8360\n",
      "Epoch 17/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3545 - accuracy: 0.8929 - val_loss: 0.5535 - val_accuracy: 0.8362\n",
      "Epoch 18/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3383 - accuracy: 0.8967 - val_loss: 0.5452 - val_accuracy: 0.8380\n",
      "Epoch 19/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3247 - accuracy: 0.9007 - val_loss: 0.5450 - val_accuracy: 0.8360\n",
      "Epoch 20/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3105 - accuracy: 0.9056 - val_loss: 0.5344 - val_accuracy: 0.8400\n",
      "Epoch 21/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2978 - accuracy: 0.9079 - val_loss: 0.5381 - val_accuracy: 0.8380\n",
      "Epoch 22/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2856 - accuracy: 0.9114 - val_loss: 0.5300 - val_accuracy: 0.8430\n",
      "Epoch 23/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2737 - accuracy: 0.9155 - val_loss: 0.5279 - val_accuracy: 0.8449\n",
      "Epoch 24/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2638 - accuracy: 0.9185 - val_loss: 0.5238 - val_accuracy: 0.8444\n",
      "Epoch 25/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2533 - accuracy: 0.9208 - val_loss: 0.5255 - val_accuracy: 0.8428\n",
      "Epoch 26/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2432 - accuracy: 0.9242 - val_loss: 0.5182 - val_accuracy: 0.8452\n",
      "Epoch 27/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2343 - accuracy: 0.9277 - val_loss: 0.5189 - val_accuracy: 0.8479\n",
      "Epoch 28/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2258 - accuracy: 0.9317 - val_loss: 0.5183 - val_accuracy: 0.8455\n",
      "Epoch 29/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2175 - accuracy: 0.9334 - val_loss: 0.5171 - val_accuracy: 0.8475\n",
      "Epoch 30/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2094 - accuracy: 0.9344 - val_loss: 0.5194 - val_accuracy: 0.8465\n",
      "Epoch 31/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2018 - accuracy: 0.9374 - val_loss: 0.5165 - val_accuracy: 0.8494\n",
      "Epoch 32/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1956 - accuracy: 0.9399 - val_loss: 0.5127 - val_accuracy: 0.8503\n",
      "Epoch 33/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1879 - accuracy: 0.9425 - val_loss: 0.5162 - val_accuracy: 0.8500\n",
      "Epoch 34/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1815 - accuracy: 0.9444 - val_loss: 0.5128 - val_accuracy: 0.8496\n",
      "Epoch 35/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1758 - accuracy: 0.9463 - val_loss: 0.5166 - val_accuracy: 0.8482\n",
      "Epoch 36/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1699 - accuracy: 0.9478 - val_loss: 0.5127 - val_accuracy: 0.8529\n",
      "Epoch 37/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1650 - accuracy: 0.9490 - val_loss: 0.5166 - val_accuracy: 0.8524\n",
      "Epoch 38/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1597 - accuracy: 0.9511 - val_loss: 0.5165 - val_accuracy: 0.8523\n",
      "Epoch 39/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1550 - accuracy: 0.9512 - val_loss: 0.5112 - val_accuracy: 0.8547\n",
      "Epoch 40/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1503 - accuracy: 0.9536 - val_loss: 0.5169 - val_accuracy: 0.8504\n",
      "Epoch 41/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1454 - accuracy: 0.9552 - val_loss: 0.5204 - val_accuracy: 0.8525\n",
      "Epoch 42/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1413 - accuracy: 0.9569 - val_loss: 0.5237 - val_accuracy: 0.8523\n",
      "Epoch 43/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1367 - accuracy: 0.9591 - val_loss: 0.5256 - val_accuracy: 0.8506\n",
      "Epoch 44/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1334 - accuracy: 0.9582 - val_loss: 0.5206 - val_accuracy: 0.8559\n",
      "Epoch 45/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1293 - accuracy: 0.9594 - val_loss: 0.5269 - val_accuracy: 0.8544\n",
      "Epoch 46/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1249 - accuracy: 0.9619 - val_loss: 0.5305 - val_accuracy: 0.8518\n",
      "Epoch 47/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1231 - accuracy: 0.9618 - val_loss: 0.5302 - val_accuracy: 0.8532\n",
      "Epoch 48/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1192 - accuracy: 0.9630 - val_loss: 0.5318 - val_accuracy: 0.8517\n",
      "Epoch 49/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1159 - accuracy: 0.9644 - val_loss: 0.5382 - val_accuracy: 0.8524\n",
      "Epoch 50/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1133 - accuracy: 0.9645 - val_loss: 0.5396 - val_accuracy: 0.8525\n",
      "Epoch 51/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1101 - accuracy: 0.9652 - val_loss: 0.5354 - val_accuracy: 0.8561\n",
      "Epoch 52/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1079 - accuracy: 0.9658 - val_loss: 0.5419 - val_accuracy: 0.8547\n",
      "Epoch 53/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1050 - accuracy: 0.9675 - val_loss: 0.5439 - val_accuracy: 0.8524\n",
      "Epoch 54/150\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1026 - accuracy: 0.9680 - val_loss: 0.5434 - val_accuracy: 0.8544\n",
      "Epoch 55/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0993 - accuracy: 0.9693 - val_loss: 0.5444 - val_accuracy: 0.8562\n",
      "Epoch 56/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0979 - accuracy: 0.9690 - val_loss: 0.5489 - val_accuracy: 0.8566\n",
      "Epoch 57/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0956 - accuracy: 0.9693 - val_loss: 0.5474 - val_accuracy: 0.8575\n",
      "Epoch 58/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0938 - accuracy: 0.9706 - val_loss: 0.5510 - val_accuracy: 0.8540\n",
      "Epoch 59/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0913 - accuracy: 0.9715 - val_loss: 0.5590 - val_accuracy: 0.8530\n",
      "Epoch 60/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0899 - accuracy: 0.9712 - val_loss: 0.5555 - val_accuracy: 0.8564\n",
      "Epoch 61/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0876 - accuracy: 0.9721 - val_loss: 0.5645 - val_accuracy: 0.8544\n",
      "Epoch 62/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0864 - accuracy: 0.9727 - val_loss: 0.5670 - val_accuracy: 0.8540\n",
      "Epoch 63/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0839 - accuracy: 0.9740 - val_loss: 0.5639 - val_accuracy: 0.8542\n",
      "Epoch 64/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0827 - accuracy: 0.9734 - val_loss: 0.5702 - val_accuracy: 0.8550\n",
      "Epoch 65/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0809 - accuracy: 0.9742 - val_loss: 0.5712 - val_accuracy: 0.8554\n",
      "Epoch 66/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0799 - accuracy: 0.9741 - val_loss: 0.5782 - val_accuracy: 0.8530\n",
      "Epoch 67/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0780 - accuracy: 0.9747 - val_loss: 0.5805 - val_accuracy: 0.8546\n",
      "Epoch 68/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0764 - accuracy: 0.9760 - val_loss: 0.5800 - val_accuracy: 0.8560\n",
      "Epoch 69/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0751 - accuracy: 0.9758 - val_loss: 0.5827 - val_accuracy: 0.8551\n",
      "Epoch 70/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0739 - accuracy: 0.9765 - val_loss: 0.5908 - val_accuracy: 0.8555\n",
      "Epoch 71/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0726 - accuracy: 0.9769 - val_loss: 0.5846 - val_accuracy: 0.8539\n",
      "Epoch 72/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0714 - accuracy: 0.9772 - val_loss: 0.5890 - val_accuracy: 0.8548\n",
      "Epoch 73/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0698 - accuracy: 0.9770 - val_loss: 0.5907 - val_accuracy: 0.8544\n",
      "Epoch 74/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0687 - accuracy: 0.9776 - val_loss: 0.5875 - val_accuracy: 0.8563\n",
      "Epoch 75/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0675 - accuracy: 0.9779 - val_loss: 0.5978 - val_accuracy: 0.8550\n",
      "Epoch 76/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0664 - accuracy: 0.9781 - val_loss: 0.5987 - val_accuracy: 0.8543\n",
      "Epoch 77/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0660 - accuracy: 0.9785 - val_loss: 0.6010 - val_accuracy: 0.8556\n",
      "Epoch 78/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0647 - accuracy: 0.9786 - val_loss: 0.5973 - val_accuracy: 0.8561\n",
      "Epoch 79/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0635 - accuracy: 0.9794 - val_loss: 0.6052 - val_accuracy: 0.8542\n",
      "Epoch 80/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0626 - accuracy: 0.9790 - val_loss: 0.6040 - val_accuracy: 0.8555\n",
      "Epoch 81/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0617 - accuracy: 0.9792 - val_loss: 0.6113 - val_accuracy: 0.8546\n",
      "Epoch 82/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0608 - accuracy: 0.9800 - val_loss: 0.6125 - val_accuracy: 0.8561\n",
      "Epoch 83/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0605 - accuracy: 0.9798 - val_loss: 0.6154 - val_accuracy: 0.8550\n",
      "Epoch 84/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0597 - accuracy: 0.9803 - val_loss: 0.6121 - val_accuracy: 0.8556\n",
      "Epoch 85/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0589 - accuracy: 0.9802 - val_loss: 0.6169 - val_accuracy: 0.8558\n",
      "Epoch 86/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0577 - accuracy: 0.9806 - val_loss: 0.6144 - val_accuracy: 0.8561\n",
      "Epoch 87/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0573 - accuracy: 0.9806 - val_loss: 0.6155 - val_accuracy: 0.8581\n",
      "Epoch 88/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0560 - accuracy: 0.9811 - val_loss: 0.6268 - val_accuracy: 0.8574\n",
      "Epoch 89/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0559 - accuracy: 0.9816 - val_loss: 0.6193 - val_accuracy: 0.8578\n",
      "Epoch 90/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0548 - accuracy: 0.9811 - val_loss: 0.6235 - val_accuracy: 0.8582\n",
      "Epoch 91/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0547 - accuracy: 0.9811 - val_loss: 0.6279 - val_accuracy: 0.8573\n",
      "Epoch 92/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0536 - accuracy: 0.9816 - val_loss: 0.6395 - val_accuracy: 0.8548\n",
      "Epoch 93/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0531 - accuracy: 0.9818 - val_loss: 0.6336 - val_accuracy: 0.8550\n",
      "Epoch 94/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0530 - accuracy: 0.9818 - val_loss: 0.6395 - val_accuracy: 0.8570\n",
      "Epoch 95/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0518 - accuracy: 0.9824 - val_loss: 0.6397 - val_accuracy: 0.8558\n",
      "Epoch 96/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0511 - accuracy: 0.9824 - val_loss: 0.6340 - val_accuracy: 0.8579\n",
      "Epoch 97/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0511 - accuracy: 0.9825 - val_loss: 0.6440 - val_accuracy: 0.8557\n",
      "Epoch 98/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0501 - accuracy: 0.9829 - val_loss: 0.6436 - val_accuracy: 0.8577\n",
      "Epoch 99/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0496 - accuracy: 0.9835 - val_loss: 0.6520 - val_accuracy: 0.8542\n",
      "Epoch 100/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0492 - accuracy: 0.9831 - val_loss: 0.6481 - val_accuracy: 0.8571\n",
      "Epoch 101/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0487 - accuracy: 0.9832 - val_loss: 0.6498 - val_accuracy: 0.8576\n",
      "Epoch 102/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0489 - accuracy: 0.9827 - val_loss: 0.6496 - val_accuracy: 0.8566\n",
      "Epoch 103/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0478 - accuracy: 0.9833 - val_loss: 0.6588 - val_accuracy: 0.8573\n",
      "Epoch 104/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0476 - accuracy: 0.9829 - val_loss: 0.6555 - val_accuracy: 0.8564\n",
      "Epoch 105/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0474 - accuracy: 0.9834 - val_loss: 0.6546 - val_accuracy: 0.8580\n",
      "Epoch 106/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0464 - accuracy: 0.9835 - val_loss: 0.6572 - val_accuracy: 0.8575\n",
      "Epoch 107/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0468 - accuracy: 0.9829 - val_loss: 0.6598 - val_accuracy: 0.8572\n",
      "Epoch 108/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0457 - accuracy: 0.9840 - val_loss: 0.6676 - val_accuracy: 0.8567\n",
      "Epoch 109/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0458 - accuracy: 0.9832 - val_loss: 0.6621 - val_accuracy: 0.8564\n",
      "Epoch 110/150\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0453 - accuracy: 0.9835 - val_loss: 0.6634 - val_accuracy: 0.8572\n",
      "Epoch 111/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0448 - accuracy: 0.9837 - val_loss: 0.6681 - val_accuracy: 0.8579\n",
      "Epoch 112/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0442 - accuracy: 0.9836 - val_loss: 0.6711 - val_accuracy: 0.8551\n",
      "Epoch 113/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0440 - accuracy: 0.9840 - val_loss: 0.6676 - val_accuracy: 0.8577\n",
      "Epoch 114/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0435 - accuracy: 0.9846 - val_loss: 0.6717 - val_accuracy: 0.8578\n",
      "Epoch 115/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0436 - accuracy: 0.9840 - val_loss: 0.6794 - val_accuracy: 0.8569\n",
      "Epoch 116/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0436 - accuracy: 0.9836 - val_loss: 0.6805 - val_accuracy: 0.8565\n",
      "Epoch 117/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0430 - accuracy: 0.9843 - val_loss: 0.6737 - val_accuracy: 0.8562\n",
      "Epoch 118/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0421 - accuracy: 0.9847 - val_loss: 0.6750 - val_accuracy: 0.8576\n",
      "Epoch 119/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0417 - accuracy: 0.9850 - val_loss: 0.6874 - val_accuracy: 0.8543\n",
      "Epoch 120/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0420 - accuracy: 0.9846 - val_loss: 0.6841 - val_accuracy: 0.8576\n",
      "Epoch 121/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0416 - accuracy: 0.9847 - val_loss: 0.6824 - val_accuracy: 0.8575\n",
      "Epoch 122/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0409 - accuracy: 0.9848 - val_loss: 0.6834 - val_accuracy: 0.8575\n",
      "Epoch 123/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0413 - accuracy: 0.9841 - val_loss: 0.6874 - val_accuracy: 0.8562\n",
      "Epoch 124/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0410 - accuracy: 0.9848 - val_loss: 0.6893 - val_accuracy: 0.8552\n",
      "Epoch 125/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0412 - accuracy: 0.9840 - val_loss: 0.6926 - val_accuracy: 0.8572\n",
      "Epoch 126/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0404 - accuracy: 0.9843 - val_loss: 0.6935 - val_accuracy: 0.8552\n",
      "Epoch 127/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0400 - accuracy: 0.9845 - val_loss: 0.6858 - val_accuracy: 0.8574\n",
      "Epoch 128/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0398 - accuracy: 0.9848 - val_loss: 0.6886 - val_accuracy: 0.8577\n",
      "Epoch 129/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0395 - accuracy: 0.9847 - val_loss: 0.6945 - val_accuracy: 0.8579\n",
      "Epoch 130/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0403 - accuracy: 0.9841 - val_loss: 0.6930 - val_accuracy: 0.8570\n",
      "Epoch 131/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0391 - accuracy: 0.9849 - val_loss: 0.6993 - val_accuracy: 0.8570\n",
      "Epoch 132/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0392 - accuracy: 0.9850 - val_loss: 0.7035 - val_accuracy: 0.8567\n",
      "Epoch 133/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0385 - accuracy: 0.9853 - val_loss: 0.7025 - val_accuracy: 0.8551\n",
      "Epoch 134/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0382 - accuracy: 0.9848 - val_loss: 0.7020 - val_accuracy: 0.8579\n",
      "Epoch 135/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0386 - accuracy: 0.9851 - val_loss: 0.7018 - val_accuracy: 0.8580\n",
      "Epoch 136/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0381 - accuracy: 0.9853 - val_loss: 0.7039 - val_accuracy: 0.8578\n",
      "Epoch 137/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0385 - accuracy: 0.9847 - val_loss: 0.7041 - val_accuracy: 0.8581\n",
      "Epoch 138/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0377 - accuracy: 0.9855 - val_loss: 0.7042 - val_accuracy: 0.8589\n",
      "Epoch 139/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0381 - accuracy: 0.9849 - val_loss: 0.7160 - val_accuracy: 0.8548\n",
      "Epoch 140/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0378 - accuracy: 0.9851 - val_loss: 0.7062 - val_accuracy: 0.8571\n",
      "Epoch 141/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0372 - accuracy: 0.9855 - val_loss: 0.7050 - val_accuracy: 0.8572\n",
      "Epoch 142/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0373 - accuracy: 0.9854 - val_loss: 0.7105 - val_accuracy: 0.8550\n",
      "Epoch 143/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0373 - accuracy: 0.9849 - val_loss: 0.7117 - val_accuracy: 0.8575\n",
      "Epoch 144/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0370 - accuracy: 0.9853 - val_loss: 0.7151 - val_accuracy: 0.8579\n",
      "Epoch 145/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0366 - accuracy: 0.9853 - val_loss: 0.7184 - val_accuracy: 0.8561\n",
      "Epoch 146/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0362 - accuracy: 0.9858 - val_loss: 0.7219 - val_accuracy: 0.8573\n",
      "Epoch 147/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0355 - accuracy: 0.9857 - val_loss: 0.7125 - val_accuracy: 0.8576\n",
      "Epoch 148/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0360 - accuracy: 0.9852 - val_loss: 0.7232 - val_accuracy: 0.8579\n",
      "Epoch 149/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0361 - accuracy: 0.9856 - val_loss: 0.7189 - val_accuracy: 0.8559\n",
      "Epoch 150/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0357 - accuracy: 0.9852 - val_loss: 0.7171 - val_accuracy: 0.8554\n",
      " SGD: 7 / 4 ###################################################\n",
      "Epoch 1/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 1.2012 - accuracy: 0.6895 - val_loss: 0.7787 - val_accuracy: 0.7843\n",
      "Epoch 2/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.6752 - accuracy: 0.8071 - val_loss: 0.7717 - val_accuracy: 0.7942\n",
      "Epoch 3/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.5407 - accuracy: 0.8433 - val_loss: 0.6033 - val_accuracy: 0.8193\n",
      "Epoch 4/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3986 - accuracy: 0.8692 - val_loss: 0.5369 - val_accuracy: 0.8403\n",
      "Epoch 5/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3224 - accuracy: 0.8895 - val_loss: 0.5132 - val_accuracy: 0.8450\n",
      "Epoch 6/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2741 - accuracy: 0.9066 - val_loss: 0.5051 - val_accuracy: 0.8499\n",
      "Epoch 7/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2396 - accuracy: 0.9169 - val_loss: 0.4928 - val_accuracy: 0.8543\n",
      "Epoch 8/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2118 - accuracy: 0.9268 - val_loss: 0.4879 - val_accuracy: 0.8559\n",
      "Epoch 9/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1911 - accuracy: 0.9325 - val_loss: 0.4955 - val_accuracy: 0.8577\n",
      "Epoch 10/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1734 - accuracy: 0.9387 - val_loss: 0.4992 - val_accuracy: 0.8573\n",
      "Epoch 11/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1591 - accuracy: 0.9443 - val_loss: 0.4992 - val_accuracy: 0.8550\n",
      "Epoch 12/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1477 - accuracy: 0.9478 - val_loss: 0.4969 - val_accuracy: 0.8601\n",
      "Epoch 13/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1375 - accuracy: 0.9522 - val_loss: 0.5016 - val_accuracy: 0.8569\n",
      "Epoch 14/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1280 - accuracy: 0.9547 - val_loss: 0.4983 - val_accuracy: 0.8624\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1204 - accuracy: 0.9574 - val_loss: 0.5026 - val_accuracy: 0.8617\n",
      "Epoch 16/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1130 - accuracy: 0.9601 - val_loss: 0.5071 - val_accuracy: 0.8621\n",
      "Epoch 17/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1078 - accuracy: 0.9619 - val_loss: 0.5149 - val_accuracy: 0.8593\n",
      "Epoch 18/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1016 - accuracy: 0.9642 - val_loss: 0.5090 - val_accuracy: 0.8642\n",
      "Epoch 19/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0970 - accuracy: 0.9661 - val_loss: 0.5173 - val_accuracy: 0.8607\n",
      "Epoch 20/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0925 - accuracy: 0.9673 - val_loss: 0.5225 - val_accuracy: 0.8636\n",
      "Epoch 21/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0881 - accuracy: 0.9694 - val_loss: 0.5256 - val_accuracy: 0.8622\n",
      "Epoch 22/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0853 - accuracy: 0.9697 - val_loss: 0.5309 - val_accuracy: 0.8632\n",
      "Epoch 23/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0812 - accuracy: 0.9717 - val_loss: 0.5353 - val_accuracy: 0.8645\n",
      "Epoch 24/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0786 - accuracy: 0.9725 - val_loss: 0.5384 - val_accuracy: 0.8636\n",
      "Epoch 25/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0759 - accuracy: 0.9729 - val_loss: 0.5388 - val_accuracy: 0.8631\n",
      "Epoch 26/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0732 - accuracy: 0.9740 - val_loss: 0.5392 - val_accuracy: 0.8652\n",
      "Epoch 27/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0711 - accuracy: 0.9745 - val_loss: 0.5505 - val_accuracy: 0.8662\n",
      "Epoch 28/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0690 - accuracy: 0.9755 - val_loss: 0.5548 - val_accuracy: 0.8634\n",
      "Epoch 29/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0669 - accuracy: 0.9759 - val_loss: 0.5514 - val_accuracy: 0.8637\n",
      "Epoch 30/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0647 - accuracy: 0.9777 - val_loss: 0.5585 - val_accuracy: 0.8643\n",
      "Epoch 31/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0630 - accuracy: 0.9775 - val_loss: 0.5601 - val_accuracy: 0.8641\n",
      "Epoch 32/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0615 - accuracy: 0.9786 - val_loss: 0.5612 - val_accuracy: 0.8667\n",
      "Epoch 33/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0598 - accuracy: 0.9782 - val_loss: 0.5638 - val_accuracy: 0.8634\n",
      "Epoch 34/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0585 - accuracy: 0.9789 - val_loss: 0.5674 - val_accuracy: 0.8631\n",
      "Epoch 35/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0572 - accuracy: 0.9796 - val_loss: 0.5694 - val_accuracy: 0.8651\n",
      "Epoch 36/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0558 - accuracy: 0.9795 - val_loss: 0.5712 - val_accuracy: 0.8639\n",
      "Epoch 37/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0547 - accuracy: 0.9806 - val_loss: 0.5788 - val_accuracy: 0.8652\n",
      "Epoch 38/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0538 - accuracy: 0.9805 - val_loss: 0.5779 - val_accuracy: 0.8654\n",
      "Epoch 39/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0528 - accuracy: 0.9811 - val_loss: 0.5797 - val_accuracy: 0.8646\n",
      "Epoch 40/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0517 - accuracy: 0.9810 - val_loss: 0.5803 - val_accuracy: 0.8646\n",
      "Epoch 41/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0506 - accuracy: 0.9819 - val_loss: 0.5866 - val_accuracy: 0.8642\n",
      "Epoch 42/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0500 - accuracy: 0.9821 - val_loss: 0.5876 - val_accuracy: 0.8637\n",
      "Epoch 43/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0486 - accuracy: 0.9820 - val_loss: 0.5922 - val_accuracy: 0.8648\n",
      "Epoch 44/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0482 - accuracy: 0.9821 - val_loss: 0.5904 - val_accuracy: 0.8652\n",
      "Epoch 45/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0472 - accuracy: 0.9831 - val_loss: 0.5933 - val_accuracy: 0.8648\n",
      "Epoch 46/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0463 - accuracy: 0.9827 - val_loss: 0.6010 - val_accuracy: 0.8631\n",
      "Epoch 47/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0461 - accuracy: 0.9829 - val_loss: 0.5988 - val_accuracy: 0.8643\n",
      "Epoch 48/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0454 - accuracy: 0.9831 - val_loss: 0.5998 - val_accuracy: 0.8650\n",
      "Epoch 49/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0447 - accuracy: 0.9827 - val_loss: 0.6042 - val_accuracy: 0.8658\n",
      "Epoch 50/50\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0442 - accuracy: 0.9833 - val_loss: 0.6063 - val_accuracy: 0.8660\n",
      " SGD: 8 / 4 ###################################################\n",
      "Epoch 1/150\n",
      "1260/1260 [==============================] - 3s 2ms/step - loss: 1.2074 - accuracy: 0.6889 - val_loss: 0.8385 - val_accuracy: 0.7799\n",
      "Epoch 2/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.6866 - accuracy: 0.8101 - val_loss: 0.7026 - val_accuracy: 0.7962\n",
      "Epoch 3/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.5330 - accuracy: 0.8373 - val_loss: 0.5641 - val_accuracy: 0.8242\n",
      "Epoch 4/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3931 - accuracy: 0.8677 - val_loss: 0.5166 - val_accuracy: 0.8374\n",
      "Epoch 5/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3130 - accuracy: 0.8896 - val_loss: 0.5014 - val_accuracy: 0.8401\n",
      "Epoch 6/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2602 - accuracy: 0.9073 - val_loss: 0.4926 - val_accuracy: 0.8504\n",
      "Epoch 7/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2413 - accuracy: 0.9158 - val_loss: 0.4798 - val_accuracy: 0.8520\n",
      "Epoch 8/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1946 - accuracy: 0.9300 - val_loss: 0.4660 - val_accuracy: 0.8555\n",
      "Epoch 9/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1726 - accuracy: 0.9362 - val_loss: 0.4759 - val_accuracy: 0.8587\n",
      "Epoch 10/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1550 - accuracy: 0.9432 - val_loss: 0.4879 - val_accuracy: 0.8549\n",
      "Epoch 11/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1395 - accuracy: 0.9484 - val_loss: 0.4892 - val_accuracy: 0.8574\n",
      "Epoch 12/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1285 - accuracy: 0.9510 - val_loss: 0.4929 - val_accuracy: 0.8601\n",
      "Epoch 13/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1183 - accuracy: 0.9561 - val_loss: 0.4875 - val_accuracy: 0.8560\n",
      "Epoch 14/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1089 - accuracy: 0.9591 - val_loss: 0.4921 - val_accuracy: 0.8634\n",
      "Epoch 15/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1021 - accuracy: 0.9608 - val_loss: 0.5043 - val_accuracy: 0.8603\n",
      "Epoch 16/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0947 - accuracy: 0.9651 - val_loss: 0.5099 - val_accuracy: 0.8616\n",
      "Epoch 17/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0895 - accuracy: 0.9666 - val_loss: 0.5211 - val_accuracy: 0.8582\n",
      "Epoch 18/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0838 - accuracy: 0.9681 - val_loss: 0.5180 - val_accuracy: 0.8619\n",
      "Epoch 19/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0788 - accuracy: 0.9709 - val_loss: 0.5256 - val_accuracy: 0.8600\n",
      "Epoch 20/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0747 - accuracy: 0.9720 - val_loss: 0.5349 - val_accuracy: 0.8617\n",
      "Epoch 21/150\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0708 - accuracy: 0.9729 - val_loss: 0.5335 - val_accuracy: 0.8622\n",
      "Epoch 22/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0687 - accuracy: 0.9734 - val_loss: 0.5450 - val_accuracy: 0.8613\n",
      "Epoch 23/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0641 - accuracy: 0.9753 - val_loss: 0.5531 - val_accuracy: 0.8622\n",
      "Epoch 24/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0618 - accuracy: 0.9766 - val_loss: 0.5566 - val_accuracy: 0.8615\n",
      "Epoch 25/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0596 - accuracy: 0.9770 - val_loss: 0.5657 - val_accuracy: 0.8588\n",
      "Epoch 26/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0562 - accuracy: 0.9787 - val_loss: 0.5663 - val_accuracy: 0.8632\n",
      "Epoch 27/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0556 - accuracy: 0.9777 - val_loss: 0.5788 - val_accuracy: 0.8623\n",
      "Epoch 28/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0533 - accuracy: 0.9795 - val_loss: 0.5777 - val_accuracy: 0.8620\n",
      "Epoch 29/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0511 - accuracy: 0.9801 - val_loss: 0.5843 - val_accuracy: 0.8622\n",
      "Epoch 30/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0487 - accuracy: 0.9816 - val_loss: 0.5907 - val_accuracy: 0.8630\n",
      "Epoch 31/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0484 - accuracy: 0.9809 - val_loss: 0.5882 - val_accuracy: 0.8630\n",
      "Epoch 32/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0460 - accuracy: 0.9825 - val_loss: 0.5953 - val_accuracy: 0.8633\n",
      "Epoch 33/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0451 - accuracy: 0.9821 - val_loss: 0.5982 - val_accuracy: 0.8650\n",
      "Epoch 34/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0439 - accuracy: 0.9822 - val_loss: 0.6050 - val_accuracy: 0.8629\n",
      "Epoch 35/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0434 - accuracy: 0.9824 - val_loss: 0.6034 - val_accuracy: 0.8620\n",
      "Epoch 36/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0420 - accuracy: 0.9827 - val_loss: 0.6049 - val_accuracy: 0.8636\n",
      "Epoch 37/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0416 - accuracy: 0.9827 - val_loss: 0.6162 - val_accuracy: 0.8630\n",
      "Epoch 38/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0407 - accuracy: 0.9829 - val_loss: 0.6184 - val_accuracy: 0.8629\n",
      "Epoch 39/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0396 - accuracy: 0.9837 - val_loss: 0.6183 - val_accuracy: 0.8641\n",
      "Epoch 40/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0386 - accuracy: 0.9840 - val_loss: 0.6179 - val_accuracy: 0.8659\n",
      "Epoch 41/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0379 - accuracy: 0.9845 - val_loss: 0.6323 - val_accuracy: 0.8630\n",
      "Epoch 42/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0374 - accuracy: 0.9841 - val_loss: 0.6259 - val_accuracy: 0.8644\n",
      "Epoch 43/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0363 - accuracy: 0.9845 - val_loss: 0.6385 - val_accuracy: 0.8617\n",
      "Epoch 44/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0359 - accuracy: 0.9850 - val_loss: 0.6326 - val_accuracy: 0.8651\n",
      "Epoch 45/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0349 - accuracy: 0.9854 - val_loss: 0.6381 - val_accuracy: 0.8640\n",
      "Epoch 46/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0348 - accuracy: 0.9849 - val_loss: 0.6470 - val_accuracy: 0.8621\n",
      "Epoch 47/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0349 - accuracy: 0.9846 - val_loss: 0.6419 - val_accuracy: 0.8651\n",
      "Epoch 48/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0342 - accuracy: 0.9848 - val_loss: 0.6404 - val_accuracy: 0.8648\n",
      "Epoch 49/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0336 - accuracy: 0.9845 - val_loss: 0.6548 - val_accuracy: 0.8646\n",
      "Epoch 50/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0334 - accuracy: 0.9850 - val_loss: 0.6499 - val_accuracy: 0.8655\n",
      "Epoch 51/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0328 - accuracy: 0.9852 - val_loss: 0.6495 - val_accuracy: 0.8655\n",
      "Epoch 52/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0326 - accuracy: 0.9850 - val_loss: 0.6539 - val_accuracy: 0.8647\n",
      "Epoch 53/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0316 - accuracy: 0.9854 - val_loss: 0.6549 - val_accuracy: 0.8624\n",
      "Epoch 54/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0317 - accuracy: 0.9847 - val_loss: 0.6526 - val_accuracy: 0.8638\n",
      "Epoch 55/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0305 - accuracy: 0.9861 - val_loss: 0.6649 - val_accuracy: 0.8608\n",
      "Epoch 56/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0312 - accuracy: 0.9855 - val_loss: 0.6644 - val_accuracy: 0.8648\n",
      "Epoch 57/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0304 - accuracy: 0.9864 - val_loss: 0.6577 - val_accuracy: 0.8656\n",
      "Epoch 58/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0300 - accuracy: 0.9860 - val_loss: 0.6650 - val_accuracy: 0.8642\n",
      "Epoch 59/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0296 - accuracy: 0.9858 - val_loss: 0.6734 - val_accuracy: 0.8620\n",
      "Epoch 60/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0300 - accuracy: 0.9858 - val_loss: 0.6673 - val_accuracy: 0.8650\n",
      "Epoch 61/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0301 - accuracy: 0.9853 - val_loss: 0.6660 - val_accuracy: 0.8643\n",
      "Epoch 62/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0295 - accuracy: 0.9854 - val_loss: 0.6738 - val_accuracy: 0.8634\n",
      "Epoch 63/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0291 - accuracy: 0.9858 - val_loss: 0.6768 - val_accuracy: 0.8647\n",
      "Epoch 64/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0287 - accuracy: 0.9856 - val_loss: 0.6808 - val_accuracy: 0.8618\n",
      "Epoch 65/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0286 - accuracy: 0.9863 - val_loss: 0.6744 - val_accuracy: 0.8658\n",
      "Epoch 66/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0282 - accuracy: 0.9863 - val_loss: 0.6881 - val_accuracy: 0.8639\n",
      "Epoch 67/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0280 - accuracy: 0.9867 - val_loss: 0.6806 - val_accuracy: 0.8627\n",
      "Epoch 68/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0278 - accuracy: 0.9863 - val_loss: 0.6849 - val_accuracy: 0.8634\n",
      "Epoch 69/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0274 - accuracy: 0.9869 - val_loss: 0.6895 - val_accuracy: 0.8633\n",
      "Epoch 70/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0278 - accuracy: 0.9861 - val_loss: 0.6892 - val_accuracy: 0.8639\n",
      "Epoch 71/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0276 - accuracy: 0.9861 - val_loss: 0.6814 - val_accuracy: 0.8649\n",
      "Epoch 72/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0274 - accuracy: 0.9862 - val_loss: 0.6870 - val_accuracy: 0.8630\n",
      "Epoch 73/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0269 - accuracy: 0.9864 - val_loss: 0.6864 - val_accuracy: 0.8640\n",
      "Epoch 74/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0268 - accuracy: 0.9861 - val_loss: 0.6900 - val_accuracy: 0.8650\n",
      "Epoch 75/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0267 - accuracy: 0.9861 - val_loss: 0.6941 - val_accuracy: 0.8627\n",
      "Epoch 76/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0268 - accuracy: 0.9862 - val_loss: 0.6941 - val_accuracy: 0.8653\n",
      "Epoch 77/150\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0266 - accuracy: 0.9861 - val_loss: 0.6973 - val_accuracy: 0.8641\n",
      "Epoch 78/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0261 - accuracy: 0.9863 - val_loss: 0.6960 - val_accuracy: 0.8666\n",
      "Epoch 79/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0261 - accuracy: 0.9865 - val_loss: 0.6940 - val_accuracy: 0.8637\n",
      "Epoch 80/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0259 - accuracy: 0.9862 - val_loss: 0.6909 - val_accuracy: 0.8657\n",
      "Epoch 81/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0260 - accuracy: 0.9862 - val_loss: 0.6967 - val_accuracy: 0.8638\n",
      "Epoch 82/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0255 - accuracy: 0.9864 - val_loss: 0.7077 - val_accuracy: 0.8634\n",
      "Epoch 83/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0257 - accuracy: 0.9861 - val_loss: 0.6962 - val_accuracy: 0.8638\n",
      "Epoch 84/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0255 - accuracy: 0.9862 - val_loss: 0.7050 - val_accuracy: 0.8630\n",
      "Epoch 85/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0256 - accuracy: 0.9858 - val_loss: 0.6992 - val_accuracy: 0.8644\n",
      "Epoch 86/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0251 - accuracy: 0.9867 - val_loss: 0.6990 - val_accuracy: 0.8649\n",
      "Epoch 87/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0252 - accuracy: 0.9863 - val_loss: 0.6976 - val_accuracy: 0.8661\n",
      "Epoch 88/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0250 - accuracy: 0.9866 - val_loss: 0.7094 - val_accuracy: 0.8635\n",
      "Epoch 89/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0246 - accuracy: 0.9868 - val_loss: 0.7093 - val_accuracy: 0.8646\n",
      "Epoch 90/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0248 - accuracy: 0.9860 - val_loss: 0.7084 - val_accuracy: 0.8632\n",
      "Epoch 91/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0248 - accuracy: 0.9862 - val_loss: 0.7082 - val_accuracy: 0.8643\n",
      "Epoch 92/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0249 - accuracy: 0.9862 - val_loss: 0.7070 - val_accuracy: 0.8647\n",
      "Epoch 93/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0246 - accuracy: 0.9863 - val_loss: 0.7076 - val_accuracy: 0.8633\n",
      "Epoch 94/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0244 - accuracy: 0.9864 - val_loss: 0.7144 - val_accuracy: 0.8642\n",
      "Epoch 95/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0244 - accuracy: 0.9864 - val_loss: 0.7184 - val_accuracy: 0.8637\n",
      "Epoch 96/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0242 - accuracy: 0.9864 - val_loss: 0.7153 - val_accuracy: 0.8649\n",
      "Epoch 97/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0242 - accuracy: 0.9865 - val_loss: 0.7075 - val_accuracy: 0.8640\n",
      "Epoch 98/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0238 - accuracy: 0.9866 - val_loss: 0.7176 - val_accuracy: 0.8629\n",
      "Epoch 99/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0240 - accuracy: 0.9865 - val_loss: 0.7217 - val_accuracy: 0.8642\n",
      "Epoch 100/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0237 - accuracy: 0.9868 - val_loss: 0.7207 - val_accuracy: 0.8642\n",
      "Epoch 101/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0238 - accuracy: 0.9866 - val_loss: 0.7186 - val_accuracy: 0.8634\n",
      "Epoch 102/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0236 - accuracy: 0.9866 - val_loss: 0.7182 - val_accuracy: 0.8647\n",
      "Epoch 103/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0232 - accuracy: 0.9871 - val_loss: 0.7251 - val_accuracy: 0.8651\n",
      "Epoch 104/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0236 - accuracy: 0.9861 - val_loss: 0.7184 - val_accuracy: 0.8656\n",
      "Epoch 105/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0233 - accuracy: 0.9868 - val_loss: 0.7230 - val_accuracy: 0.8636\n",
      "Epoch 106/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0234 - accuracy: 0.9867 - val_loss: 0.7198 - val_accuracy: 0.8655\n",
      "Epoch 107/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0235 - accuracy: 0.9866 - val_loss: 0.7197 - val_accuracy: 0.8657\n",
      "Epoch 108/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0230 - accuracy: 0.9867 - val_loss: 0.7316 - val_accuracy: 0.8629\n",
      "Epoch 109/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0234 - accuracy: 0.9869 - val_loss: 0.7201 - val_accuracy: 0.8639\n",
      "Epoch 110/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0231 - accuracy: 0.9865 - val_loss: 0.7208 - val_accuracy: 0.8638\n",
      "Epoch 111/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0231 - accuracy: 0.9870 - val_loss: 0.7289 - val_accuracy: 0.8641\n",
      "Epoch 112/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0228 - accuracy: 0.9867 - val_loss: 0.7272 - val_accuracy: 0.8651\n",
      "Epoch 113/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0228 - accuracy: 0.9869 - val_loss: 0.7268 - val_accuracy: 0.8652\n",
      "Epoch 114/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0227 - accuracy: 0.9867 - val_loss: 0.7295 - val_accuracy: 0.8636\n",
      "Epoch 115/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0229 - accuracy: 0.9868 - val_loss: 0.7327 - val_accuracy: 0.8639\n",
      "Epoch 116/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0229 - accuracy: 0.9866 - val_loss: 0.7273 - val_accuracy: 0.8634\n",
      "Epoch 117/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0227 - accuracy: 0.9862 - val_loss: 0.7285 - val_accuracy: 0.8653\n",
      "Epoch 118/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0223 - accuracy: 0.9870 - val_loss: 0.7285 - val_accuracy: 0.8645\n",
      "Epoch 119/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0224 - accuracy: 0.9872 - val_loss: 0.7354 - val_accuracy: 0.8636\n",
      "Epoch 120/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0224 - accuracy: 0.9872 - val_loss: 0.7328 - val_accuracy: 0.8643\n",
      "Epoch 121/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0223 - accuracy: 0.9874 - val_loss: 0.7334 - val_accuracy: 0.8637\n",
      "Epoch 122/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0223 - accuracy: 0.9873 - val_loss: 0.7340 - val_accuracy: 0.8638\n",
      "Epoch 123/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0226 - accuracy: 0.9868 - val_loss: 0.7320 - val_accuracy: 0.8636\n",
      "Epoch 124/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0221 - accuracy: 0.9870 - val_loss: 0.7355 - val_accuracy: 0.8641\n",
      "Epoch 125/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0222 - accuracy: 0.9865 - val_loss: 0.7370 - val_accuracy: 0.8639\n",
      "Epoch 126/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0221 - accuracy: 0.9867 - val_loss: 0.7395 - val_accuracy: 0.8640\n",
      "Epoch 127/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0219 - accuracy: 0.9872 - val_loss: 0.7356 - val_accuracy: 0.8646\n",
      "Epoch 128/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0220 - accuracy: 0.9869 - val_loss: 0.7383 - val_accuracy: 0.8645\n",
      "Epoch 129/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0219 - accuracy: 0.9868 - val_loss: 0.7365 - val_accuracy: 0.8651\n",
      "Epoch 130/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0221 - accuracy: 0.9861 - val_loss: 0.7380 - val_accuracy: 0.8627\n",
      "Epoch 131/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0218 - accuracy: 0.9868 - val_loss: 0.7394 - val_accuracy: 0.8658\n",
      "Epoch 132/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0218 - accuracy: 0.9863 - val_loss: 0.7403 - val_accuracy: 0.8657\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 133/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0218 - accuracy: 0.9867 - val_loss: 0.7428 - val_accuracy: 0.8634\n",
      "Epoch 134/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0216 - accuracy: 0.9870 - val_loss: 0.7464 - val_accuracy: 0.8645\n",
      "Epoch 135/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0218 - accuracy: 0.9865 - val_loss: 0.7386 - val_accuracy: 0.8646\n",
      "Epoch 136/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0217 - accuracy: 0.9869 - val_loss: 0.7395 - val_accuracy: 0.8642\n",
      "Epoch 137/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0216 - accuracy: 0.9872 - val_loss: 0.7416 - val_accuracy: 0.8646\n",
      "Epoch 138/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0215 - accuracy: 0.9872 - val_loss: 0.7458 - val_accuracy: 0.8635\n",
      "Epoch 139/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0218 - accuracy: 0.9867 - val_loss: 0.7411 - val_accuracy: 0.8641\n",
      "Epoch 140/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0215 - accuracy: 0.9866 - val_loss: 0.7433 - val_accuracy: 0.8637\n",
      "Epoch 141/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0215 - accuracy: 0.9868 - val_loss: 0.7417 - val_accuracy: 0.8651\n",
      "Epoch 142/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0214 - accuracy: 0.9866 - val_loss: 0.7452 - val_accuracy: 0.8639\n",
      "Epoch 143/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0216 - accuracy: 0.9863 - val_loss: 0.7434 - val_accuracy: 0.8648\n",
      "Epoch 144/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0212 - accuracy: 0.9866 - val_loss: 0.7474 - val_accuracy: 0.8650\n",
      "Epoch 145/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0213 - accuracy: 0.9868 - val_loss: 0.7462 - val_accuracy: 0.8649\n",
      "Epoch 146/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0213 - accuracy: 0.9868 - val_loss: 0.7501 - val_accuracy: 0.8632\n",
      "Epoch 147/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0208 - accuracy: 0.9873 - val_loss: 0.7496 - val_accuracy: 0.8628\n",
      "Epoch 148/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0213 - accuracy: 0.9870 - val_loss: 0.7481 - val_accuracy: 0.8645\n",
      "Epoch 149/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0210 - accuracy: 0.9872 - val_loss: 0.7476 - val_accuracy: 0.8656\n",
      "Epoch 150/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0209 - accuracy: 0.9868 - val_loss: 0.7470 - val_accuracy: 0.8636\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# print result\r\n",
    "new_mlp_res = pd.DataFrame(mlp_res)\r\n",
    "new_mlp_res"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   tech      lr  epoch  accuracy_score  precision_score  recall_score  \\\n",
       "0  Adam  0.0001     50        0.855147         0.856422      0.854501   \n",
       "1  Adam  0.0001    150        0.855385         0.858622      0.855343   \n",
       "2  Adam  0.0010     50        0.853004         0.855207      0.852915   \n",
       "3  Adam  0.0010    150        0.856497         0.857484      0.856461   \n",
       "4   SGD  0.0010     50        0.849036         0.850419      0.848542   \n",
       "5   SGD  0.0010    150        0.854115         0.854951      0.853697   \n",
       "6   SGD  0.0100     50        0.859195         0.859238      0.858730   \n",
       "7   SGD  0.0100    150        0.863402         0.863466      0.863336   \n",
       "\n",
       "   f1_score  \n",
       "0  0.854316  \n",
       "1  0.854669  \n",
       "2  0.851792  \n",
       "3  0.855428  \n",
       "4  0.848234  \n",
       "5  0.853511  \n",
       "6  0.858608  \n",
       "7  0.863026  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tech</th>\n",
       "      <th>lr</th>\n",
       "      <th>epoch</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>0.855147</td>\n",
       "      <td>0.856422</td>\n",
       "      <td>0.854501</td>\n",
       "      <td>0.854316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>150</td>\n",
       "      <td>0.855385</td>\n",
       "      <td>0.858622</td>\n",
       "      <td>0.855343</td>\n",
       "      <td>0.854669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>50</td>\n",
       "      <td>0.853004</td>\n",
       "      <td>0.855207</td>\n",
       "      <td>0.852915</td>\n",
       "      <td>0.851792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>150</td>\n",
       "      <td>0.856497</td>\n",
       "      <td>0.857484</td>\n",
       "      <td>0.856461</td>\n",
       "      <td>0.855428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>50</td>\n",
       "      <td>0.849036</td>\n",
       "      <td>0.850419</td>\n",
       "      <td>0.848542</td>\n",
       "      <td>0.848234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>150</td>\n",
       "      <td>0.854115</td>\n",
       "      <td>0.854951</td>\n",
       "      <td>0.853697</td>\n",
       "      <td>0.853511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.859195</td>\n",
       "      <td>0.859238</td>\n",
       "      <td>0.858730</td>\n",
       "      <td>0.858608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.863402</td>\n",
       "      <td>0.863466</td>\n",
       "      <td>0.863336</td>\n",
       "      <td>0.863026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# find the best model and save the result to out final result list\r\n",
    "all_res['accuracy_score'].append(mlp_res['accuracy_score'][7])\r\n",
    "all_res['precision_score'].append(mlp_res['precision_score'][7])\r\n",
    "all_res['recall_score'].append(mlp_res['recall_score'][7])\r\n",
    "all_res['f1_score'].append(mlp_res['f1_score'][7])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# pd.DataFrame(history.history).plot(figsize=(8,5))\r\n",
    "# plt.grid(True)\r\n",
    "# plt.gca().set_ylim(0,1)\r\n",
    "# plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3. CNN<a id='3.3'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Clear any existing TensorFlow graph from memory and set random seeds.\r\n",
    "keras.backend.clear_session()\r\n",
    "np.random.seed(42)\r\n",
    "tf.random.set_seed(42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "X_train_keras = X_train_std.reshape(X_train_std.shape[0], 28, 28)\r\n",
    "X_test_keras = X_test_std.reshape(X_test_std.shape[0], 28, 28)\r\n",
    "\r\n",
    "X_train_keras = np.expand_dims(X_train_keras, axis=3)\r\n",
    "X_test_keras = np.expand_dims(X_test_keras, axis=3)\r\n",
    "\r\n",
    "y_train_keras = keras.utils.to_categorical(y_train, 62).astype('int32')\r\n",
    "y_test_keras = keras.utils.to_categorical(y_test, 62).astype('int32')\r\n",
    "\r\n",
    "# print shape of data and label\r\n",
    "print(\"The shape of train data: \", X_train_keras.shape)\r\n",
    "print(\"The shape of test data: \", X_test_keras.shape)\r\n",
    "print(\"The shape of train label: \", y_train_keras.shape)\r\n",
    "print(\"The shape of test label: \", y_test_keras.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The shape of train data:  (50393, 28, 28, 1)\n",
      "The shape of test data:  (12599, 28, 28, 1)\n",
      "The shape of train label:  (50393, 62)\n",
      "The shape of test label:  (12599, 62)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "model = load_model(\"best_algorithm.h5\")\r\n",
    "print(model.summary())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 64)        3200      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 13, 13, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 6, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 6, 128)         295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 62)                7998      \n",
      "=================================================================\n",
      "Total params: 1,138,238\n",
      "Trainable params: 1,136,318\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Check pretrained model performance on test set\r\n",
    "y_prob = model.predict(X_test_keras)\r\n",
    "y_pred = np.argmax(y_prob,axis=1)\r\n",
    "ground_truth = np.argmax(y_test_keras,axis=1)\r\n",
    "\r\n",
    "print(\"CNN - accuracy score on test set: {:.3f}\".format(accuracy_score(ground_truth, y_pred)))\r\n",
    "print(\"CNN - precision score on test set: {:.3f}\".format(precision_score(ground_truth, y_pred, average='macro')))\r\n",
    "print(\"CNN - recall score on test set: {:.3f}\".format(recall_score(ground_truth, y_pred, average='macro')))\r\n",
    "print(\"CNN - f1 score on test set: {:.3f}\".format(f1_score(ground_truth, y_pred, average='macro')))\r\n",
    "print(\"CNN - confusion matrix on test set: \\n\", confusion_matrix(ground_truth, y_pred))\r\n",
    "all_res['accuracy_score'].append(accuracy_score(ground_truth, y_pred))\r\n",
    "all_res['precision_score'].append(precision_score(ground_truth, y_pred, average='macro'))\r\n",
    "all_res['recall_score'].append(recall_score(ground_truth, y_pred, average='macro'))\r\n",
    "all_res['f1_score'].append(f1_score(ground_truth, y_pred, average='macro'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CNN - accuracy score on test set: 0.902\n",
      "CNN - precision score on test set: 0.902\n",
      "CNN - recall score on test set: 0.901\n",
      "CNN - f1 score on test set: 0.900\n",
      "CNN - confusion matrix on test set: \n",
      " [[170   0   0 ...   0   0   0]\n",
      " [  0 179   0 ...   0   0   0]\n",
      " [  0   0 211 ...   0   1   0]\n",
      " ...\n",
      " [  0   0   0 ... 173   0   0]\n",
      " [  0   1   0 ...   0 191   0]\n",
      " [  0   0   0 ...   0   0 138]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# pd.DataFrame(history.history).plot(figsize=(8,5))\r\n",
    "# plt.grid(True)\r\n",
    "# plt.gca().set_ylim(0,1)\r\n",
    "# plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Classifier comparisons<a id='4'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "all_res_n = pd.DataFrame(all_res)\r\n",
    "all_res_n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Computer details<a id='5'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Hardware\n",
    "    - OS System: Windows 10 64-bit operating system\n",
    "    - CPU: Intel(R) Core(TM) i7-9700KF\n",
    "    - GPU: NVIDIA GeForce RTX 2070\n",
    "    - RAM: 16.0 GB\n",
    "    \n",
    "- Software\n",
    "    - Python 3.8.3\n",
    "    - notebook 6.0.3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Easy to use<a id='6'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "import sklearn\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "from keras import layers\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import os\r\n",
    "import time\r\n",
    "import cv2\r\n",
    "\r\n",
    "%matplotlib inline\r\n",
    "import matplotlib as mpl\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "# used to compare result of all models\r\n",
    "all_res = {'algorithms': ['knn', 'MLP', 'cnn'],\r\n",
    "           'accuracy_score':[],\r\n",
    "           'accuracy_score':[],\r\n",
    "           'precision_score':[],\r\n",
    "           'recall_score':[], \r\n",
    "           'f1_score':[]}\r\n",
    "\r\n",
    "# read image and resize image\r\n",
    "def img_resizing(i_path):\r\n",
    "    img = cv2.imread(i_path, cv2.IMREAD_GRAYSCALE)\r\n",
    "    data = cv2.resize(img, (28, 28), interpolation=cv2.INTER_CUBIC)\r\n",
    "    return data\r\n",
    "\r\n",
    "# converting the images into sets of data\r\n",
    "data = []\r\n",
    "label = []\r\n",
    "\r\n",
    "print(\"############### Data Path Input ############### \\n\")\r\n",
    "print(\"Default path is: 'English/Fnt/'\")\r\n",
    "print(\"*** DO NOT ENTER anything if using the above path ***\")\r\n",
    "print(\"Windows Path Example: C:/Users/xxx/Downloads/5318/English/Fnt/\")\r\n",
    "print(\"MacOS Path Example: /Users/xxx/Downloads/5318/English/Fnt/\")\r\n",
    "\r\n",
    "data_path = input(\"Please input the data path (before Samplexxx folders) end with '/'\")\r\n",
    "if data_path == '':\r\n",
    "    data_path = 'English/Fnt/'\r\n",
    "\r\n",
    "for i in range(62):\r\n",
    "    path = data_path + 'Sample%03d/' % (i+1)\r\n",
    "    for filename in os.listdir(path):\r\n",
    "        try:\r\n",
    "            img = img_resizing(path+filename)\r\n",
    "            tmp = img.reshape([1, img.shape[0]*img.shape[1]])\r\n",
    "            data.append(np.asarray(tmp, dtype = \"int32\"))\r\n",
    "            label.append(i)\r\n",
    "        except:\r\n",
    "            error_message = path + filename\r\n",
    "            print(\"failed: \", error_message)\r\n",
    "            pass\r\n",
    "print(\"############### Data Loaded ############### \\n \")\r\n",
    "# convert data type\r\n",
    "data_array = np.asarray(data)\r\n",
    "new_data = np.asarray(data_array).reshape(data_array.shape[0],-1)\r\n",
    "new_label = np.asarray(label)\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "X = new_data\r\n",
    "y = new_label\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=500)\r\n",
    "print(\"############### Train/Test Splited ############### \\n \")\r\n",
    "\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "scaler = StandardScaler()#creating an object\r\n",
    "scaler.fit(X_train)#calculate min and max value of the training data\r\n",
    "X_train_std = scaler.transform(X_train) #apply normalisation to the training set\r\n",
    "X_test_std = scaler.transform(X_test) #apply normalization to the test set\r\n",
    "print(\"############### Standardise Data ############### \\n \")\r\n",
    "\r\n",
    "from sklearn.decomposition import PCA\r\n",
    "pca=PCA(n_components=0.9)\r\n",
    "X_train_reduced = pca.fit_transform(X_train_std)\r\n",
    "X_test_reduced = pca.transform(X_test_std)\r\n",
    "print(\"############### PCA Done ############### \\n \")\r\n",
    "\r\n",
    "# knn\r\n",
    "print(\"############### KNN Model Loading ############### \\n \")\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "knn = KNeighborsClassifier(n_neighbors=1,p=1)\r\n",
    "knn.fit(X_train_reduced, y_train)\r\n",
    "print(\"############### KNN Model Loaded ############### \\n \")\r\n",
    "y_pred = knn.predict(X_test_reduced)\r\n",
    "\r\n",
    "print(\"Knn - accuracy score on test set: {:.3f}\".format(accuracy_score(y_test, y_pred)))\r\n",
    "print(\"Knn - precision score on test set: {:.3f}\".format(precision_score(y_test, y_pred, average='macro')))\r\n",
    "print(\"Knn - recall score on test set: {:.3f}\".format(recall_score(y_test, y_pred, average='macro')))\r\n",
    "print(\"Knn - f1 score on test set: {:.3f}\".format(f1_score(y_test, y_pred, average='macro')))\r\n",
    "print(\"Knn - confusion matrix on test set: \\n\", confusion_matrix(y_test, y_pred))\r\n",
    "all_res['accuracy_score'].append(accuracy_score(y_test, y_pred))\r\n",
    "all_res['precision_score'].append(precision_score(y_test, y_pred, average='macro'))\r\n",
    "all_res['recall_score'].append(recall_score(y_test, y_pred, average='macro'))\r\n",
    "all_res['f1_score'].append(f1_score(y_test, y_pred, average='macro'))\r\n",
    "\r\n",
    "# MLP\r\n",
    "from tensorflow.keras.models import Sequential, load_model\r\n",
    "from tensorflow.keras import layers\r\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
    "print(\"############### MLP Model Loading ############### \\n \")\r\n",
    "# Clear any existing TensorFlow graph from memory and set random seeds.\r\n",
    "keras.backend.clear_session()\r\n",
    "np.random.seed(42)\r\n",
    "tf.random.set_seed(42)\r\n",
    "\r\n",
    "model= keras.models.Sequential([\r\n",
    "    keras.layers.Flatten(input_shape=X_train_std.shape[1:]),\r\n",
    "    keras.layers.Dense(400, activation=\"relu\"),\r\n",
    "    keras.layers.Dense(200, activation=\"relu\"),\r\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\r\n",
    "    keras.layers.Dense(62, activation=\"softmax\")\r\n",
    "])\r\n",
    "\r\n",
    "sgd = keras.optimizers.SGD(learning_rate=0.01, momentum=0.8, decay=0.01/150, nesterov=False)\r\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \r\n",
    "                optimizer=sgd, \r\n",
    "                metrics=[\"accuracy\"])\r\n",
    "model.fit(X_train_std, y_train, epochs=150,\r\n",
    "                    validation_split=0.2) # set 20% as validation seet\r\n",
    "print(\"############### MLP Model Loaded ###############\")\r\n",
    "# Check pretrained model performance on test set\r\n",
    "y_prob = model.predict(X_test_std)\r\n",
    "y_pred = np.argmax(y_prob,axis=1)\r\n",
    "\r\n",
    "print(\"MLP - accuracy score on test set: {:.3f}\".format(accuracy_score(y_test, y_pred)))\r\n",
    "print(\"MLP - precision score on test set: {:.3f}\".format(precision_score(y_test, y_pred, average='macro')))\r\n",
    "print(\"MLP - recall score on test set: {:.3f}\".format(recall_score(y_test, y_pred, average='macro')))\r\n",
    "print(\"MLP - f1 score on test set: {:.3f}\".format(f1_score(y_test, y_pred, average='macro')))\r\n",
    "print(\"MLP - confusion matrix on test set: \\n\", confusion_matrix(y_test, y_pred))\r\n",
    "all_res['accuracy_score'].append(accuracy_score(y_test, y_pred))\r\n",
    "all_res['precision_score'].append(precision_score(y_test, y_pred, average='macro'))\r\n",
    "all_res['recall_score'].append(recall_score(y_test, y_pred, average='macro'))\r\n",
    "all_res['f1_score'].append(f1_score(y_test, y_pred, average='macro'))\r\n",
    "\r\n",
    "# cnn\r\n",
    "# Clear any existing TensorFlow graph from memory and set random seeds.\r\n",
    "keras.backend.clear_session()\r\n",
    "np.random.seed(42)\r\n",
    "tf.random.set_seed(42)\r\n",
    "\r\n",
    "X_train_keras = X_train_std.reshape(X_train_std.shape[0], 28, 28)\r\n",
    "X_test_keras = X_test_std.reshape(X_test_std.shape[0], 28, 28)\r\n",
    "\r\n",
    "X_train_keras = np.expand_dims(X_train_keras, axis=3)\r\n",
    "X_test_keras = np.expand_dims(X_test_keras, axis=3)\r\n",
    "\r\n",
    "y_train_keras = keras.utils.to_categorical(y_train, 62).astype('int32')\r\n",
    "y_test_keras = keras.utils.to_categorical(y_test, 62).astype('int32')\r\n",
    "\r\n",
    "# load model\r\n",
    "print(\"############### CNN Model Path Input ###############\")\r\n",
    "model_path = 'best_algorithm.h5'\r\n",
    "model = load_model(model_path)\r\n",
    "print(\"############### CNN model loaded ###############\")\r\n",
    "# Check pretrained model performance on test set\r\n",
    "y_prob = model.predict(X_test_keras)\r\n",
    "y_pred = np.argmax(y_prob,axis=1)\r\n",
    "ground_truth = np.argmax(y_test_keras,axis=1)\r\n",
    "\r\n",
    "print(\"CNN - accuracy score on test set: {:.3f}\".format(accuracy_score(ground_truth, y_pred)))\r\n",
    "print(\"CNN - precision score on test set: {:.3f}\".format(precision_score(ground_truth, y_pred, average='macro')))\r\n",
    "print(\"CNN - recall score on test set: {:.3f}\".format(recall_score(ground_truth, y_pred, average='macro')))\r\n",
    "print(\"CNN - f1 score on test set: {:.3f}\".format(f1_score(ground_truth, y_pred, average='macro')))\r\n",
    "print(\"CNN - confusion matrix on test set: \\n\", confusion_matrix(ground_truth, y_pred))\r\n",
    "all_res['accuracy_score'].append(accuracy_score(ground_truth, y_pred))\r\n",
    "all_res['precision_score'].append(precision_score(ground_truth, y_pred, average='macro'))\r\n",
    "all_res['recall_score'].append(recall_score(ground_truth, y_pred, average='macro'))\r\n",
    "all_res['f1_score'].append(f1_score(ground_truth, y_pred, average='macro'))\r\n",
    "\r\n",
    "print(\"############### Model Comparison ############### \\n \")\r\n",
    "all_res_n = pd.DataFrame(all_res)\r\n",
    "print(all_res_n)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "############### Data Path Input ############### \n",
      "\n",
      "Default path is: 'English/Fnt/'\n",
      "*** DO NOT ENTER anything if using the above path ***\n",
      "Windows Path Example: C:/Users/xxx/Downloads/5318/English/Fnt/\n",
      "MacOS Path Example: /Users/xxx/Downloads/5318/English/Fnt/\n",
      "Please input the data path (before Samplexxx folders) end with '/'C:/Users/95839/Desktop/English/Fnt/\n",
      "############### Data Loaded ############### \n",
      " \n",
      "############### Train/Test Splited ############### \n",
      " \n",
      "############### Standardise Data ############### \n",
      " \n",
      "############### PCA Done ############### \n",
      " \n",
      "############### KNN Model Loading ############### \n",
      " \n",
      "############### KNN Model Loaded ############### \n",
      " \n",
      "Knn - accuracy score on test set: 0.872\n",
      "Knn - precision score on test set: 0.873\n",
      "Knn - recall score on test set: 0.872\n",
      "Knn - f1 score on test set: 0.872\n",
      "Knn - confusion matrix on test set: \n",
      " [[154   0   0 ...   0   0   0]\n",
      " [  0 172   0 ...   0   0   0]\n",
      " [  0   0 211 ...   0   0   0]\n",
      " ...\n",
      " [  0   1   0 ... 153   0   1]\n",
      " [  0   0   0 ...   0 183   0]\n",
      " [  0   0   0 ...   0   0 155]]\n",
      "############### MLP Model Loading ############### \n",
      " \n",
      "Epoch 1/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 1.2074 - accuracy: 0.6889 - val_loss: 0.8385 - val_accuracy: 0.7799\n",
      "Epoch 2/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.6866 - accuracy: 0.8101 - val_loss: 0.7026 - val_accuracy: 0.7962\n",
      "Epoch 3/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.5330 - accuracy: 0.8373 - val_loss: 0.5641 - val_accuracy: 0.8242\n",
      "Epoch 4/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3931 - accuracy: 0.8677 - val_loss: 0.5166 - val_accuracy: 0.8374\n",
      "Epoch 5/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.3130 - accuracy: 0.8896 - val_loss: 0.5014 - val_accuracy: 0.8401\n",
      "Epoch 6/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2602 - accuracy: 0.9073 - val_loss: 0.4926 - val_accuracy: 0.8504\n",
      "Epoch 7/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.2413 - accuracy: 0.9158 - val_loss: 0.4798 - val_accuracy: 0.8520\n",
      "Epoch 8/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1946 - accuracy: 0.9300 - val_loss: 0.4660 - val_accuracy: 0.8555\n",
      "Epoch 9/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1726 - accuracy: 0.9362 - val_loss: 0.4759 - val_accuracy: 0.8587\n",
      "Epoch 10/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1550 - accuracy: 0.9432 - val_loss: 0.4879 - val_accuracy: 0.8549\n",
      "Epoch 11/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1395 - accuracy: 0.9484 - val_loss: 0.4892 - val_accuracy: 0.8574\n",
      "Epoch 12/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1285 - accuracy: 0.9510 - val_loss: 0.4929 - val_accuracy: 0.8601\n",
      "Epoch 13/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1183 - accuracy: 0.9561 - val_loss: 0.4875 - val_accuracy: 0.8560\n",
      "Epoch 14/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1089 - accuracy: 0.9591 - val_loss: 0.4921 - val_accuracy: 0.8634\n",
      "Epoch 15/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.1021 - accuracy: 0.9608 - val_loss: 0.5043 - val_accuracy: 0.8603\n",
      "Epoch 16/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0947 - accuracy: 0.9651 - val_loss: 0.5099 - val_accuracy: 0.8616\n",
      "Epoch 17/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0895 - accuracy: 0.9666 - val_loss: 0.5211 - val_accuracy: 0.8582\n",
      "Epoch 18/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0838 - accuracy: 0.9681 - val_loss: 0.5180 - val_accuracy: 0.8619\n",
      "Epoch 19/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0788 - accuracy: 0.9709 - val_loss: 0.5256 - val_accuracy: 0.8600\n",
      "Epoch 20/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0747 - accuracy: 0.9720 - val_loss: 0.5349 - val_accuracy: 0.8617\n",
      "Epoch 21/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0708 - accuracy: 0.9729 - val_loss: 0.5335 - val_accuracy: 0.8622\n",
      "Epoch 22/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0687 - accuracy: 0.9734 - val_loss: 0.5450 - val_accuracy: 0.8613\n",
      "Epoch 23/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0641 - accuracy: 0.9753 - val_loss: 0.5531 - val_accuracy: 0.8622\n",
      "Epoch 24/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0618 - accuracy: 0.9766 - val_loss: 0.5566 - val_accuracy: 0.8615\n",
      "Epoch 25/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0596 - accuracy: 0.9770 - val_loss: 0.5657 - val_accuracy: 0.8588\n",
      "Epoch 26/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0562 - accuracy: 0.9787 - val_loss: 0.5663 - val_accuracy: 0.8632\n",
      "Epoch 27/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0556 - accuracy: 0.9777 - val_loss: 0.5788 - val_accuracy: 0.8623\n",
      "Epoch 28/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0533 - accuracy: 0.9795 - val_loss: 0.5777 - val_accuracy: 0.8620\n",
      "Epoch 29/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0511 - accuracy: 0.9801 - val_loss: 0.5843 - val_accuracy: 0.8622\n",
      "Epoch 30/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0487 - accuracy: 0.9816 - val_loss: 0.5907 - val_accuracy: 0.8630\n",
      "Epoch 31/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0484 - accuracy: 0.9809 - val_loss: 0.5882 - val_accuracy: 0.8630\n",
      "Epoch 32/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0460 - accuracy: 0.9825 - val_loss: 0.5953 - val_accuracy: 0.8633\n",
      "Epoch 33/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0451 - accuracy: 0.9821 - val_loss: 0.5982 - val_accuracy: 0.8650\n",
      "Epoch 34/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0439 - accuracy: 0.9822 - val_loss: 0.6050 - val_accuracy: 0.8629\n",
      "Epoch 35/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0434 - accuracy: 0.9824 - val_loss: 0.6034 - val_accuracy: 0.8620\n",
      "Epoch 36/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0420 - accuracy: 0.9827 - val_loss: 0.6049 - val_accuracy: 0.8636\n",
      "Epoch 37/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0416 - accuracy: 0.9827 - val_loss: 0.6162 - val_accuracy: 0.8630\n",
      "Epoch 38/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0407 - accuracy: 0.9829 - val_loss: 0.6184 - val_accuracy: 0.8629\n",
      "Epoch 39/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0396 - accuracy: 0.9837 - val_loss: 0.6183 - val_accuracy: 0.8641\n",
      "Epoch 40/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0386 - accuracy: 0.9840 - val_loss: 0.6179 - val_accuracy: 0.8659\n",
      "Epoch 41/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0379 - accuracy: 0.9845 - val_loss: 0.6323 - val_accuracy: 0.8630\n",
      "Epoch 42/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0374 - accuracy: 0.9841 - val_loss: 0.6259 - val_accuracy: 0.8644\n",
      "Epoch 43/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0363 - accuracy: 0.9845 - val_loss: 0.6385 - val_accuracy: 0.8617\n",
      "Epoch 44/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0359 - accuracy: 0.9850 - val_loss: 0.6326 - val_accuracy: 0.8651\n",
      "Epoch 45/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0349 - accuracy: 0.9854 - val_loss: 0.6381 - val_accuracy: 0.8640\n",
      "Epoch 46/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0348 - accuracy: 0.9849 - val_loss: 0.6470 - val_accuracy: 0.8621\n",
      "Epoch 47/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0349 - accuracy: 0.9846 - val_loss: 0.6419 - val_accuracy: 0.8651\n",
      "Epoch 48/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0342 - accuracy: 0.9848 - val_loss: 0.6404 - val_accuracy: 0.8648\n",
      "Epoch 49/150\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0336 - accuracy: 0.9845 - val_loss: 0.6548 - val_accuracy: 0.8646\n",
      "Epoch 50/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0334 - accuracy: 0.9850 - val_loss: 0.6499 - val_accuracy: 0.8655\n",
      "Epoch 51/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0328 - accuracy: 0.9852 - val_loss: 0.6495 - val_accuracy: 0.8655\n",
      "Epoch 52/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0326 - accuracy: 0.9850 - val_loss: 0.6539 - val_accuracy: 0.8647\n",
      "Epoch 53/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0316 - accuracy: 0.9854 - val_loss: 0.6549 - val_accuracy: 0.8624\n",
      "Epoch 54/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0317 - accuracy: 0.9847 - val_loss: 0.6526 - val_accuracy: 0.8638\n",
      "Epoch 55/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0305 - accuracy: 0.9861 - val_loss: 0.6649 - val_accuracy: 0.8608\n",
      "Epoch 56/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0312 - accuracy: 0.9855 - val_loss: 0.6644 - val_accuracy: 0.8648\n",
      "Epoch 57/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0304 - accuracy: 0.9864 - val_loss: 0.6577 - val_accuracy: 0.8656\n",
      "Epoch 58/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0300 - accuracy: 0.9860 - val_loss: 0.6650 - val_accuracy: 0.8642\n",
      "Epoch 59/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0296 - accuracy: 0.9858 - val_loss: 0.6734 - val_accuracy: 0.8620\n",
      "Epoch 60/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0300 - accuracy: 0.9858 - val_loss: 0.6673 - val_accuracy: 0.8650\n",
      "Epoch 61/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0301 - accuracy: 0.9853 - val_loss: 0.6660 - val_accuracy: 0.8643\n",
      "Epoch 62/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0295 - accuracy: 0.9854 - val_loss: 0.6738 - val_accuracy: 0.8634\n",
      "Epoch 63/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0291 - accuracy: 0.9858 - val_loss: 0.6768 - val_accuracy: 0.8647\n",
      "Epoch 64/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0287 - accuracy: 0.9856 - val_loss: 0.6808 - val_accuracy: 0.8618\n",
      "Epoch 65/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0286 - accuracy: 0.9863 - val_loss: 0.6744 - val_accuracy: 0.8658\n",
      "Epoch 66/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0282 - accuracy: 0.9863 - val_loss: 0.6881 - val_accuracy: 0.8639\n",
      "Epoch 67/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0280 - accuracy: 0.9867 - val_loss: 0.6806 - val_accuracy: 0.8627\n",
      "Epoch 68/150\n",
      "1260/1260 [==============================] - 3s 2ms/step - loss: 0.0278 - accuracy: 0.9863 - val_loss: 0.6849 - val_accuracy: 0.8634\n",
      "Epoch 69/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0274 - accuracy: 0.9869 - val_loss: 0.6895 - val_accuracy: 0.8633\n",
      "Epoch 70/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0278 - accuracy: 0.9861 - val_loss: 0.6892 - val_accuracy: 0.8639\n",
      "Epoch 71/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0276 - accuracy: 0.9861 - val_loss: 0.6814 - val_accuracy: 0.8649\n",
      "Epoch 72/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0274 - accuracy: 0.9862 - val_loss: 0.6870 - val_accuracy: 0.8630\n",
      "Epoch 73/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0269 - accuracy: 0.9864 - val_loss: 0.6864 - val_accuracy: 0.8640\n",
      "Epoch 74/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0268 - accuracy: 0.9861 - val_loss: 0.6900 - val_accuracy: 0.8650\n",
      "Epoch 75/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0267 - accuracy: 0.9861 - val_loss: 0.6941 - val_accuracy: 0.8627\n",
      "Epoch 76/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0268 - accuracy: 0.9862 - val_loss: 0.6941 - val_accuracy: 0.8653\n",
      "Epoch 77/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0266 - accuracy: 0.9861 - val_loss: 0.6973 - val_accuracy: 0.8641\n",
      "Epoch 78/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0261 - accuracy: 0.9863 - val_loss: 0.6960 - val_accuracy: 0.8666\n",
      "Epoch 79/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0261 - accuracy: 0.9865 - val_loss: 0.6940 - val_accuracy: 0.8637\n",
      "Epoch 80/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0259 - accuracy: 0.9862 - val_loss: 0.6909 - val_accuracy: 0.8657\n",
      "Epoch 81/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0260 - accuracy: 0.9862 - val_loss: 0.6967 - val_accuracy: 0.8638\n",
      "Epoch 82/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0255 - accuracy: 0.9864 - val_loss: 0.7077 - val_accuracy: 0.8634\n",
      "Epoch 83/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0257 - accuracy: 0.9861 - val_loss: 0.6962 - val_accuracy: 0.8638\n",
      "Epoch 84/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0255 - accuracy: 0.9862 - val_loss: 0.7050 - val_accuracy: 0.8630\n",
      "Epoch 85/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0256 - accuracy: 0.9858 - val_loss: 0.6992 - val_accuracy: 0.8644\n",
      "Epoch 86/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0251 - accuracy: 0.9867 - val_loss: 0.6990 - val_accuracy: 0.8649\n",
      "Epoch 87/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0252 - accuracy: 0.9863 - val_loss: 0.6976 - val_accuracy: 0.8661\n",
      "Epoch 88/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0250 - accuracy: 0.9866 - val_loss: 0.7094 - val_accuracy: 0.8635\n",
      "Epoch 89/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0246 - accuracy: 0.9868 - val_loss: 0.7093 - val_accuracy: 0.8646\n",
      "Epoch 90/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0248 - accuracy: 0.9860 - val_loss: 0.7084 - val_accuracy: 0.8632\n",
      "Epoch 91/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0248 - accuracy: 0.9862 - val_loss: 0.7082 - val_accuracy: 0.8643\n",
      "Epoch 92/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0249 - accuracy: 0.9862 - val_loss: 0.7070 - val_accuracy: 0.8647\n",
      "Epoch 93/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0246 - accuracy: 0.9863 - val_loss: 0.7076 - val_accuracy: 0.8633\n",
      "Epoch 94/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0244 - accuracy: 0.9864 - val_loss: 0.7144 - val_accuracy: 0.8642\n",
      "Epoch 95/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0244 - accuracy: 0.9864 - val_loss: 0.7184 - val_accuracy: 0.8637\n",
      "Epoch 96/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0242 - accuracy: 0.9864 - val_loss: 0.7153 - val_accuracy: 0.8649\n",
      "Epoch 97/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0242 - accuracy: 0.9865 - val_loss: 0.7075 - val_accuracy: 0.8640\n",
      "Epoch 98/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0238 - accuracy: 0.9866 - val_loss: 0.7176 - val_accuracy: 0.8629\n",
      "Epoch 99/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0240 - accuracy: 0.9865 - val_loss: 0.7217 - val_accuracy: 0.8642\n",
      "Epoch 100/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0237 - accuracy: 0.9868 - val_loss: 0.7207 - val_accuracy: 0.8642\n",
      "Epoch 101/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0238 - accuracy: 0.9866 - val_loss: 0.7186 - val_accuracy: 0.8634\n",
      "Epoch 102/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0236 - accuracy: 0.9866 - val_loss: 0.7182 - val_accuracy: 0.8647\n",
      "Epoch 103/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0232 - accuracy: 0.9871 - val_loss: 0.7251 - val_accuracy: 0.8651\n",
      "Epoch 104/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0236 - accuracy: 0.9861 - val_loss: 0.7184 - val_accuracy: 0.8656\n",
      "Epoch 105/150\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0233 - accuracy: 0.9868 - val_loss: 0.7230 - val_accuracy: 0.8636\n",
      "Epoch 106/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0234 - accuracy: 0.9867 - val_loss: 0.7198 - val_accuracy: 0.8655\n",
      "Epoch 107/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0235 - accuracy: 0.9866 - val_loss: 0.7197 - val_accuracy: 0.8657\n",
      "Epoch 108/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0230 - accuracy: 0.9867 - val_loss: 0.7316 - val_accuracy: 0.8629\n",
      "Epoch 109/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0234 - accuracy: 0.9869 - val_loss: 0.7201 - val_accuracy: 0.8639\n",
      "Epoch 110/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0231 - accuracy: 0.9865 - val_loss: 0.7208 - val_accuracy: 0.8638\n",
      "Epoch 111/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0231 - accuracy: 0.9870 - val_loss: 0.7289 - val_accuracy: 0.8641\n",
      "Epoch 112/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0228 - accuracy: 0.9867 - val_loss: 0.7272 - val_accuracy: 0.8651\n",
      "Epoch 113/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0228 - accuracy: 0.9869 - val_loss: 0.7268 - val_accuracy: 0.8652\n",
      "Epoch 114/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0227 - accuracy: 0.9867 - val_loss: 0.7295 - val_accuracy: 0.8636\n",
      "Epoch 115/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0229 - accuracy: 0.9868 - val_loss: 0.7327 - val_accuracy: 0.8639\n",
      "Epoch 116/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0229 - accuracy: 0.9866 - val_loss: 0.7273 - val_accuracy: 0.8634\n",
      "Epoch 117/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0227 - accuracy: 0.9862 - val_loss: 0.7285 - val_accuracy: 0.8653\n",
      "Epoch 118/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0223 - accuracy: 0.9870 - val_loss: 0.7285 - val_accuracy: 0.8645\n",
      "Epoch 119/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0224 - accuracy: 0.9872 - val_loss: 0.7354 - val_accuracy: 0.8636\n",
      "Epoch 120/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0224 - accuracy: 0.9872 - val_loss: 0.7328 - val_accuracy: 0.8643\n",
      "Epoch 121/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0223 - accuracy: 0.9874 - val_loss: 0.7334 - val_accuracy: 0.8637\n",
      "Epoch 122/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0223 - accuracy: 0.9873 - val_loss: 0.7340 - val_accuracy: 0.8638\n",
      "Epoch 123/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0226 - accuracy: 0.9868 - val_loss: 0.7320 - val_accuracy: 0.8636\n",
      "Epoch 124/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0221 - accuracy: 0.9870 - val_loss: 0.7355 - val_accuracy: 0.8641\n",
      "Epoch 125/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0222 - accuracy: 0.9865 - val_loss: 0.7370 - val_accuracy: 0.8639\n",
      "Epoch 126/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0221 - accuracy: 0.9867 - val_loss: 0.7395 - val_accuracy: 0.8640\n",
      "Epoch 127/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0219 - accuracy: 0.9872 - val_loss: 0.7356 - val_accuracy: 0.8646\n",
      "Epoch 128/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0220 - accuracy: 0.9869 - val_loss: 0.7383 - val_accuracy: 0.8645\n",
      "Epoch 129/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0219 - accuracy: 0.9868 - val_loss: 0.7365 - val_accuracy: 0.8651\n",
      "Epoch 130/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0221 - accuracy: 0.9861 - val_loss: 0.7380 - val_accuracy: 0.8627\n",
      "Epoch 131/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0218 - accuracy: 0.9868 - val_loss: 0.7394 - val_accuracy: 0.8658\n",
      "Epoch 132/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0218 - accuracy: 0.9863 - val_loss: 0.7403 - val_accuracy: 0.8657\n",
      "Epoch 133/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0218 - accuracy: 0.9867 - val_loss: 0.7428 - val_accuracy: 0.8634\n",
      "Epoch 134/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0216 - accuracy: 0.9870 - val_loss: 0.7464 - val_accuracy: 0.8645\n",
      "Epoch 135/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0218 - accuracy: 0.9865 - val_loss: 0.7386 - val_accuracy: 0.8646\n",
      "Epoch 136/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0217 - accuracy: 0.9869 - val_loss: 0.7395 - val_accuracy: 0.8642\n",
      "Epoch 137/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0216 - accuracy: 0.9872 - val_loss: 0.7416 - val_accuracy: 0.8646\n",
      "Epoch 138/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0215 - accuracy: 0.9872 - val_loss: 0.7458 - val_accuracy: 0.8635\n",
      "Epoch 139/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0218 - accuracy: 0.9867 - val_loss: 0.7411 - val_accuracy: 0.8641\n",
      "Epoch 140/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0215 - accuracy: 0.9866 - val_loss: 0.7433 - val_accuracy: 0.8637\n",
      "Epoch 141/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0215 - accuracy: 0.9868 - val_loss: 0.7417 - val_accuracy: 0.8651\n",
      "Epoch 142/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0214 - accuracy: 0.9866 - val_loss: 0.7452 - val_accuracy: 0.8639\n",
      "Epoch 143/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0216 - accuracy: 0.9863 - val_loss: 0.7434 - val_accuracy: 0.8648\n",
      "Epoch 144/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0212 - accuracy: 0.9866 - val_loss: 0.7474 - val_accuracy: 0.8650\n",
      "Epoch 145/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0213 - accuracy: 0.9868 - val_loss: 0.7462 - val_accuracy: 0.8649\n",
      "Epoch 146/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0213 - accuracy: 0.9868 - val_loss: 0.7501 - val_accuracy: 0.8632\n",
      "Epoch 147/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0208 - accuracy: 0.9873 - val_loss: 0.7496 - val_accuracy: 0.8628\n",
      "Epoch 148/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0213 - accuracy: 0.9870 - val_loss: 0.7481 - val_accuracy: 0.8645\n",
      "Epoch 149/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0210 - accuracy: 0.9872 - val_loss: 0.7476 - val_accuracy: 0.8656\n",
      "Epoch 150/150\n",
      "1260/1260 [==============================] - 2s 2ms/step - loss: 0.0209 - accuracy: 0.9868 - val_loss: 0.7470 - val_accuracy: 0.8636\n",
      "############### MLP Model Loaded ###############\n",
      "MLP - accuracy score on test set: 0.863\n",
      "MLP - precision score on test set: 0.863\n",
      "MLP - recall score on test set: 0.863\n",
      "MLP - f1 score on test set: 0.863\n",
      "MLP - confusion matrix on test set: \n",
      " [[160   0   0 ...   0   0   0]\n",
      " [  0 174   0 ...   0   0   0]\n",
      " [  0   1 205 ...   0   0   1]\n",
      " ...\n",
      " [  0   0   0 ... 149   0   2]\n",
      " [  0   1   0 ...   0 180   0]\n",
      " [  0   1   0 ...   1   1 144]]\n",
      "############### CNN Model Path Input ###############\n",
      "############### CNN model loaded ###############\n",
      "CNN - accuracy score on test set: 0.904\n",
      "CNN - precision score on test set: 0.905\n",
      "CNN - recall score on test set: 0.903\n",
      "CNN - f1 score on test set: 0.903\n",
      "CNN - confusion matrix on test set: \n",
      " [[164   0   0 ...   0   0   0]\n",
      " [  0 173   0 ...   0   0   0]\n",
      " [  0   0 211 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ... 162   0   0]\n",
      " [  0   0   0 ...   0 191   0]\n",
      " [  0   0   0 ...   0   0 142]]\n",
      "############### Model Comparison ############### \n",
      " \n",
      "  algorithms  accuracy_score  precision_score  recall_score  f1_score\n",
      "0        knn        0.871974         0.872908      0.871602  0.871856\n",
      "1        MLP        0.863402         0.863466      0.863336  0.863026\n",
      "2        cnn        0.903961         0.904746      0.903306  0.903392\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}